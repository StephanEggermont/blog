<?xml version="1.0" encoding="utf-8"?> 
<rss version="2.0">
 <channel>
  <title>Konrad Hinsen's Blog: Posts tagged 'scientific computing'</title>
  <description>Konrad Hinsen's Blog: Posts tagged 'scientific computing'</description>
  <link>http://blog.khinsen.net/tags/scientific-computing.html</link>
  <lastBuildDate>Fri, 20 Nov 2020 16:57:22 UT</lastBuildDate>
  <pubDate>Fri, 20 Nov 2020 16:57:22 UT</pubDate>
  <ttl>1800</ttl>
  <item>
   <title>The four possibilities of reproducible scientific computations</title>
   <link>http://blog.khinsen.net/posts/2020/11/20/the-four-possibilities-of-reproducible-scientific-computations/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-11-20-the-four-possibilities-of-reproducible-scientific-computations</guid>
   <pubDate>Fri, 20 Nov 2020 16:57:22 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Computational reproducibility has become a topic of much debate in recent years. Often that debate is fueled by misunderstandings between scientists from different disciplines, each having different needs and priorities. Moreover, the debate is often framed in terms of specific tools and techniques, in spite of the fact that tools and techniques in computing are often short-lived. In the following, I propose to approach the question from the scientists&amp;rsquo; point of view rather than from the engineering point of view. My hope is that this point of view will lead to a more constructive discussion, and ultimately to better computational reproducibility.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The format of my proposal is inspired by the well-known &lt;a href="https://www.gnu.org/philosophy/free-sw.en.html"&gt;&amp;ldquo;four freedoms&amp;rdquo; that define Free Software&lt;/a&gt;. The focus of reproducibility is not on legal aspects, but on technical ones, and therefore my proposal is framed in terms of &lt;em&gt;possibilities&lt;/em&gt; rather than freedoms.&lt;/p&gt;

&lt;h2 id="the-four-essential-possibilities"&gt;The four essential possibilities&lt;/h2&gt;

&lt;p&gt;A computation is reproducible if it offers the four essential possibilities:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;The possibility to inspect all the input data and all the source code that can possibly have an impact on the results.&lt;/li&gt;
 &lt;li&gt;The possibility to run the code on a suitable computer of one&amp;rsquo;s own choice in order to verify that it indeed produces the claimed results.&lt;/li&gt;
 &lt;li&gt;The possibility to explore the behavior of the code, by inspecting intermediate results, by running the code with small modifications, or by subjecting it to code analysis tools.&lt;/li&gt;
 &lt;li&gt;The possibility to verify that published executable versions of the computation, proposed as binary files or as services, do indeed correspond to the available source code.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;All of these possibilities come in degrees, measured in terms of the effort required to actually do what is supposed to be possible. For example, inspecting the source code of a computation is much easier for a notebook containing the top-level code, with links to repositories of all dependencies, than for a script available from the authors on request. Moreover, the degree to which each possibility exists can strongly vary over time. A piece of software made available on an institutional Web site is easily inspectable while that site exists, but inspectability drops to zero if the Web site closes down.&lt;/p&gt;

&lt;p&gt;The reproducibility profile of a computation therefore consists of four time series, each representing one of the possibilities expressed on a suitable scale with its estimated time evolution. The minimum requirement for the label &amp;ldquo;reproducible&amp;rdquo; is a non-zero degree for all four possibilities for an estimated duration of a few months, the time it takes for new work to be carefully examined by peers.&lt;/p&gt;

&lt;h2 id="rationale"&gt;Rationale&lt;/h2&gt;

&lt;p&gt;The possibility to inspect all the source code is required to allow independent verification of the software&amp;rsquo;s correctness, and in particular to check that it does what its documentation claims it does.&lt;/p&gt;

&lt;p&gt;The possibility to run the code is required to allow independent verification of the results.&lt;/p&gt;

&lt;p&gt;The possibility to explore the behavior of the code is a &lt;em&gt;de facto&lt;/em&gt; requirement to fully accomplish the goals of the first possibility. For all but the most trivial pieces of software, inspection of the source code is not enough to convince oneself that it does what it is claimed to do.&lt;/p&gt;

&lt;p&gt;The possibility of verifying the correspondence of source code and executable versions is motivated by the complexity of today&amp;rsquo;s software build procedures. Mistakes can as easily be introduced in the build process as in the source code itself. This point is well made by Ken Thompson&amp;rsquo;s Turing Award speech &lt;a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf"&gt;Reflections on Trusting Trust&lt;/a&gt;, if you replace mischief by mistake in his arguments.&lt;/p&gt;

&lt;h2 id="discussion-in-the-context-of-the-state-of-the-art"&gt;Discussion in the context of the state of the art&lt;/h2&gt;

&lt;p&gt;The possibility to inspect all the source code is a criterion that is in principle widely accepted, although many people fail to realize its wide-ranging consequences. &amp;ldquo;All the source code that can possibly have an impact on the results&amp;rdquo; actually means a &lt;em&gt;lot&lt;/em&gt; of software. It includes many libraries, but also language implementations such as compilers and interpreters. Moreover, inspecting a dependency first of all requires precisely identifying it. This remains a difficult task today, and therefore most published computations today do not offer the first essential possibility, no matter how much effort a reader is willing to invest.&lt;/p&gt;

&lt;p&gt;It is tempting to introduce another degree of compliance by requiring that only the most relevant parts of the total source code be inspectable. However, that defies the whole purpose of independent verification. Who decides what it relevant? Usually the author of the computation. But if the code declared to be irrelevant by the author is not inspectable, we have to take the author&amp;rsquo;s word for its irrelevance.&lt;/p&gt;

&lt;p&gt;The possibility to run the code is also a widely accepted criterion, though not everyone accepts the additional requirement of executability &amp;ldquo;on a suitable computer of one&amp;rsquo;s own choice&amp;rdquo;. Software made available as a service (e.g. in the cloud) is considered sufficient for reproducibility by some researchers. Executability is much more susceptible to decay over time than inspectability of the source code, and this is one of the main topics of debate today. Is long-term reproducibility needed? Is it achievable? The answers vary across disciplines. There is unfortunately a strong tendency to auto-censoring here: many scientists believe that long-term reproducibility is not realistic and &lt;em&gt;therefore&lt;/em&gt; should not be asked for. This is definitely not true and it is better to frame the question as a trade-off: what is a reasonable price to pay for long-term reproducibility, in a given discipline?&lt;/p&gt;

&lt;p&gt;The possibility to explore the behavior of the code is rarely mentioned in discussions of reproducibility. And in fact, exploring the behavior of non-trivial code written by someone else is such a difficult task that many scientists prefer not to require anyone to do it. I am not aware of any scientific journal that expects reviewers of submitted work to check the code of any computation for correctness or at least plausible correctness, which in practice requires examining its behavior. And yet, the scientific method requires &lt;em&gt;everything&lt;/em&gt; to be inquirable. It may not be a realistic expectation today, but it should at least be a goal for the future.&lt;/p&gt;

&lt;p&gt;Since code explorability is rarely required or even discussed, there is no clear profile of practical implementations either. It&amp;rsquo;s a criterion that requires expert judgement, the expert being a fellow researcher from the same discipline as the author of a computation. It is the software analog of a &amp;ldquo;well-written&amp;rdquo; paper, which is a paper that a reader can easily &amp;ldquo;get into&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The possibility of verifying the correspondence of source code and executable versions is also rarely mentioned. It is also the least fundamental one of the four essential possibilities, because in principle it can be abandoned if a computation is fully reproducible from source code. In practice, however, that is rarely a realistic option. The size and complexity of today&amp;rsquo;s software assemblies makes it impractical to re-build everything from source code, a process that can take many hours. Nearly all software assemblies we run in scientific computing contain some components obtained in pre-built binary form. While it is perfectly OK for most people, most of the time, to use such pre-built binaries, inquirability requires the possibility to check that these binaries really correspond to the source code that the authors of a computation claim to have used. This is a possibility where a low degree can be quite acceptable.&lt;/p&gt;

&lt;h2 id="please-comment"&gt;Please comment!&lt;/h2&gt;

&lt;p&gt;As I said, the goal of this blog post is to start a discussion. Your comments are valuable, possibly more so than the post itself. How important are the four possibilities in your own discipline? How well can they be realized within the current state of the art? Are there additional possibilities you consider important for reproducibility?&lt;/p&gt;

&lt;p&gt;Check also the comments on Twitter by exploring the replies to &lt;a href="https://twitter.com/khinsen/status/1329832546474061824"&gt;this tweet&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="notes-added-after-publication"&gt;Notes added after publication&lt;/h2&gt;

&lt;h3 id="20201122"&gt;2020&amp;ndash;11&amp;ndash;22&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jermdemo/status/1329866889867059200"&gt;Jeremy Leipzig&lt;/a&gt; points out  &lt;a href="https://icerm.brown.edu/topical_workshops/tw12-5-rcem/icerm_report.pdf"&gt;the 2012 ICERM workshop document&lt;/a&gt;, whose appendix A discusses several levels of reproducibility. Its last level (&amp;ldquo;open or reproducible research&amp;rdquo;) covers in a general way the four possibilities I discuss above. The lower levels describe research output in which at least one of the four possibilities is not provided.&lt;/p&gt;

&lt;h3 id="20201123"&gt;2020&amp;ndash;11&amp;ndash;23&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/ivotron/status/1329873600472621057"&gt;Ivo Jimenez&lt;/a&gt; refers to &lt;a href="https://www.niso.org/standards-committees/reproducibility-badging"&gt;ongoing work&lt;/a&gt; at NISO (National Information Standards Organization, USA) to define recommended practices, and &lt;a href="https://twitter.com/npch/status/1330453823568171008"&gt;Neil Chue Hong&lt;/a&gt; says they will be out soon.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/ivotron/status/1330612647763570690"&gt;Ivo Jimenez&lt;/a&gt; also mentions an interesting collection of &lt;a href="https://sysartifacts.github.io/"&gt;resources on artifact evaluation for computer systems conferences&lt;/a&gt;.&lt;/p&gt;</description></item>
  <item>
   <title>Stability in the SciPy ecosystem: a summary of the discussion</title>
   <link>http://blog.khinsen.net/posts/2017/11/22/stability-in-the-scipy-ecosystem-a-summary-of-the-discussion/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2017-11-22-stability-in-the-scipy-ecosystem-a-summary-of-the-discussion</guid>
   <pubDate>Wed, 22 Nov 2017 16:56:59 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;The &lt;a href="http://blog.khinsen.net/posts/2017/11/16/a-plea-for-stability-in-the-scipy-ecosystem/#comment-3627775108"&gt;plea for stability in the SciPy ecosystem&lt;/a&gt; that I posted last week on this blog has generated a lot of feedback, both as comments and in a lengthy &lt;a href="https://twitter.com/khinsen/status/931192953636315137"&gt;Twitter thread&lt;/a&gt;. For the benefit of people discovering it late, here is a summary of the main arguments and my reply to them.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;h2 id="just-freeze-your-code-and-it-will-be-reproducible-forever"&gt;Just freeze your code and it will be reproducible forever&lt;/h2&gt;

&lt;p&gt;By far the most frequent argument against my claim that we need more stability in the SciPy ecosystem was that people can simply archive their code with all the dependencies (down to the Python language itself) in a way that lets others re-run it later for reproducibility. The most frequently proposed technical approaches were the &lt;a href="https://conda.io/docs/"&gt;conda&lt;/a&gt; package manager and &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; containers.&lt;/p&gt;

&lt;p&gt;There are three main reasons why this is not a sufficient solution:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;
  &lt;p&gt;Freezing code is fine for archival reproducibility, as I mentioned in my original post. It is not sufficient for living code bases that people work on over decades. Computational biologist Luis Pedro Coelho has &lt;a href="https://metarabbit.wordpress.com/2017/11/18/numpy-scipy-backwards-stability-debate-and-why-freezing-versions-is-not-the-solution/"&gt;explained&lt;/a&gt; this very well and I recommend everyone to read his short writeup. My situation is very much the same as his. On Twitter, astronomer Tuan Do has chimed in with a &lt;a href="https://twitter.com/quantumpenguin/status/933123060822978560"&gt;similar comment&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;The technical solutions proposed all depend on yet more infrastructure whose longevity is uncertain. For how long will a Docker container image produced in 2017 remain usable? For how long will conda and its repositories be supported, and for how long will the binaries in these repositories function on current platforms?&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;None of today&amp;rsquo;s code freezing approaches comes with easy-to-use tooling and clear documentation that make it accessible to the average computational scientist. The technologies are today in a &amp;ldquo;good for early adopters&amp;rdquo; state. This means we cannot rely on them to preserve &lt;em&gt;today&amp;rsquo;s&lt;/em&gt; research even though they may well take on this role in the future.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;To illustrate point 3, let me introduce Alice and Bob, who are real scientists I know, except that I have changed the names. Alice is a chemist with a decent knowledge of Python and basic software engineering techniques (Software Carpentry level), which she eagerly applies because she cares about the quality of her work. Alice considers herself an experimentalist. She develops and maintains a Python codebase for interpreting certain types of experimental data, but software development is not the focus of her work. The code she writes is not public, because her boss doesn&amp;rsquo;t want it to be. Worse, her code depends on a small library developed by a collaborator who doesn&amp;rsquo;t even hand out source code. What Alice gets is pre-compiled shared libraries for the three platforms that matter to herself and to her users.&lt;/p&gt;

&lt;p&gt;Bob is an experimental biologist who uses the same instruments as Alice and is happy that Alice has written nice software for interpreting the results. He gets that software, including the binary-only dependencies, by personal arrangements with the various people involved. Bob doesn&amp;rsquo;t know much about Python, nor does he care. His software installation was mostly done by Alice during a one-afternoon meeting in which they worked together to reach a state he could work with. Ideally, he would like to never touch it again, but he also wants the new features that Alice adds from time to time.&lt;/p&gt;

&lt;p&gt;To all those who replied &amp;ldquo;just use conda&amp;rdquo; or &amp;ldquo;just use Docker&amp;rdquo;, I recommend considering the situation of Alice and Bob. Do you really believe that conda or Docker are the right solution for them today? Could you point them to suitable documentation written at the right level? Both for building and for re-using frozen environments?&lt;/p&gt;

&lt;p&gt;To prevent another round of misunderstanding, I am not saying that the situation of Alice and Bob would be perfect if only they could have a stable Python infrastructure. Research code should be open, for example, for many reasons including the possibility to upload it to various repositories. Fortunately, the attitudes towards software use in science are changing in the right direction, but this will take a lot of time, like all social change.&lt;/p&gt;

&lt;p&gt;I also fully understand the point of view that the SciPy ecosystem is for advanced users who value methodological innovation, and that it cannot cater for the needs of Alice and Bob because of conflicting requirements and insufficient resources to deal with them. But then, as I said in my original post, please have the courage to say so openly and clearly. Every beginner-level tutorial for scientists should state during the first five minutes that you cannot expect stability and that you should either use Python only for throw-away code or else be sure you can assume maintenance. In other words, make sure that people like Alice have no false expectations. They can then look for other technology, or team up with like-minded people to maintain long-time-stable branches of SciPy, or try whatever else.&lt;/p&gt;

&lt;h2 id="stability-is-an-unrealistic-expectation"&gt;Stability is an unrealistic expectation&lt;/h2&gt;

&lt;p&gt;Another frequently expressed opinion was that it is unrealistic to expect the kind of stability I advocated in a modern software environment. This is a self-fulfilling prophecy: if you consider the goal impossible, you won&amp;rsquo;t even try to achieve it. As I have pointed out, long-time stability is a reality in other ecosystems, built around languages such as Fortran or Java. A few people said that Fortran or Java are unfair comparisons, because they encourage very different approaches to dependency management. This is actually my point: you can have stability, but only if it&amp;rsquo;s an explicit goal and if some effort is made to reach that goal. This includes finding suitable approaches to dependency management.&lt;/p&gt;

&lt;p&gt;David Cournape made the &lt;a href="https://twitter.com/cournape/status/849918989165842434"&gt;interesting observation&lt;/a&gt; that no technology less than 20 years old is better than Python in terms of stability. That rings true, in the sense that I cannot find a counterexample. But I see this as a statement about dominant attitudes in software engineering (way beyond scientific computing), not as a statement about technological constraints that would make stability fundamentally incompatible with other requirements. Software development today is dominated by short-lived technologies but also by short-lived applications. The application domains where stability is valued probably represent a much smaller part of the pie than 20 years ago. But then, this is just another illustration for what I wrote about recently: &lt;a href="http://blog.khinsen.net/posts/2017/11/09/there-is-no-such-thing-as-software-development/"&gt;There is no such thing as software development&lt;/a&gt; in the abstract, there is only domain-specific software development. The needs of scientific computing are clearly different from the needs of Silicon Valley startups. The conclusion is that the software development tools and practices should be different as well.&lt;/p&gt;

&lt;p&gt;Finally, even within the somewhat tumultuous SciPy ecosystem, stability is not impossible. My own &lt;a href="http://dirac.cnrs-orleans.fr/MMTK/"&gt;MMTK&lt;/a&gt; library has been around for 20 years, but in spite of continuous extensions and one API redesign (from version 1.x to version 2.x), I have never knowingly broken anyone&amp;rsquo;s application code. With the end of support Python 2, I can unfortunately no longer maintain that policy.&lt;/p&gt;

&lt;h2 id="everybody-lacks-resources-for-maintenance"&gt;Everybody lacks resources for maintenance&lt;/h2&gt;

&lt;p&gt;Many comments addressed the lack of human resources for developing and maintaining scientific software, and in particular infrastructure software like the core of the SciPy ecosystem. In combination with the fact that new developments are more attractive to most people than boring maintenance, and also more valued by the community, this leads to a culture favoring innovation over stability when most of the work is done by volunteers. This was best expressed by Peter Wang in a &lt;a href="https://twitter.com/pwang/status/931386237193211904"&gt;short sequence of tweets&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This is indeed an important factor, and one whose importance transcends scientific computing and even science itself. If you look back at the history of civilization, or even at the history of life on earth, you can&amp;rsquo;t fail to notice that all living organisms have invested the lion&amp;rsquo;s share of their efforts into maintaining the &lt;em&gt;status quo&lt;/em&gt;: staying alive, staying safe, maintaining an environment that ensures a certain quality of life, etc. In modern societies whose very survival depends on technology, infrastructure maintenance (roads, power grid, &amp;hellip;) has always been a priority of state administrations - until recently, that is. Today, we hear politicians and even intellectuals proclaim the importance of innovation and disruption, while basic infrastructure starts to rot for lack of maintenance.&lt;/p&gt;

&lt;p&gt;I can only hope that the innovation and disruption fashion will die out before the societies that have fallen victim to this fashion will do so by natural selection. In the meantime, I propose that scientists try to resist as best as possible. The fact that infrastructure software such as NumPy does get funding is a good sign in my opinion. I believe we can also get funding for stability, if only we clearly state that we need it.&lt;/p&gt;

&lt;h2 id="data-supremacy"&gt;Data supremacy&lt;/h2&gt;

&lt;p&gt;Pierre de Buyl &lt;a href="http://disq.us/p/1nveqdc"&gt;reminded me&lt;/a&gt; of an &lt;a href="http://ieeexplore.ieee.org/abstract/document/6341744/"&gt;article&lt;/a&gt; I wrote five years ago, in which I proposed that data rather than software tools should be the focus of scientific computing because data is of longer-lasting scientific importance. As I have &lt;a href="https://f1000research.com/articles/3-101/v2"&gt;pointed out two years later&lt;/a&gt;, that data includes scientific models (equations etc.), even though for technical reasons they are mostly embedded into software tools today (see &lt;a href="http://sjscience.org/article?id=527"&gt;here&lt;/a&gt; for an idea for doing things differently).&lt;/p&gt;

&lt;p&gt;In a world where all scientifically relevant information is stored in stable and well-defined open file formats, software tools can evolve much more freely without disturbing ongoing work or harming reproducibility. New versions of software tools would merely have to maintain the functionality of their predecessors, but not their implementation details. However, this is at best a promise for the future. We don&amp;rsquo;t even have the basic technology to make this happen, nor a consensus that it would be a good idea, which would open up the possibility of getting funding towards that goal. We will therefore need stable software environments for many more years to come.&lt;/p&gt;</description></item>
  <item>
   <title>A plea for stability in the SciPy ecosystem</title>
   <link>http://blog.khinsen.net/posts/2017/11/16/a-plea-for-stability-in-the-scipy-ecosystem/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2017-11-16-a-plea-for-stability-in-the-scipy-ecosystem</guid>
   <pubDate>Thu, 16 Nov 2017 15:56:49 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Two NumPy-related news items appeared on my Twitter feed yesterday, just a few days after I had accidentally started a &lt;a href="https://twitter.com/khinsen/status/929014170749632513"&gt;somewhat heated debate&lt;/a&gt; myself concerning the poor reproducibility of Python-based computer-aided research. The first was the announcement &lt;a href="https://github.com/numpy/numpy/blob/master/doc/neps/dropping-python2.7-proposal.rst"&gt;of a plan for dropping support for Python 2&lt;/a&gt;. The second was a pointer to a &lt;a href="https://www.youtube.com/watch?v=fowHwlpGb34"&gt;recent presentation by Nathaniel Smith&lt;/a&gt; entitled &amp;ldquo;Inside NumPy&amp;rdquo; and dealing mainly with the NumPy team&amp;rsquo;s plans for the near future. Lots of material to think about&amp;hellip; and comment on.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The end of Python 2 support for NumPy didn&amp;rsquo;t come as a surprise to anyone in the Python community. With Python 2 itself not being supported after 2020, it doesn&amp;rsquo;t make any sense for Python-dependent software to continue support beyond that date. The detailed plan for the transition of NumPy to a Python&amp;ndash;3-only package looks quite reasonable. Which doesn&amp;rsquo;t mean that everything is fine. The disappearance of Python 2 will leave much scientific software orphaned, and many published results irreproducible. Yes, the big well-known packages of the SciPy ecosystem all work with Python 3 by now, but the same cannot be said for many domain-specific libraries that have a much smaller user and developer base, and much more limited resources. As an example, my own &lt;a href="http://dirac.cnrs-orleans.fr/MMTK/"&gt;Molecular Modelling Toolkit&lt;/a&gt; (MMTK), which might well be the oldest domain-specific library of the SciPy ecosystem, will probably go away after 2020. Porting it to Python 3 is possible, of course, but an enormous effort (some details are in this &lt;a href="https://twitter.com/khinsen/status/930749714567434240"&gt;Twitter thread&lt;/a&gt;) for which resources (funding plus competent staff) are very difficult to find.&lt;/p&gt;

&lt;p&gt;Speaking purely from a computational science point of view, the Python 2-&amp;gt;3 transition was a big mistake. While Python 3 does have some interesting new features for scientists, most of them could have been implemented in Python 2 as well, without breaking backward compatibility. There are, of course, good reasons for the modernization of the language. I am not saying that Guido van Rossum is an idiot - far from it. As popular as Python may be in today&amp;rsquo;s scientific research, scientific users make up for a very small part of the total Python user base. Unfortunately, the need for long-term stability is rather specific to scientific users, and not even all of them require it (see e.g. &lt;a href="https://twitter.com/ctitusbrown/status/929044554598137856"&gt;these&lt;/a&gt; &lt;a href="https://twitter.com/ctitusbrown/status/929044751633936384"&gt;two&lt;/a&gt; tweets by Titus Brown). So while Python 3 is probably a step forward for most Python users, it&amp;rsquo;s mostly a calamity for computational science.&lt;/p&gt;

&lt;p&gt;Apart from the major earthquake caused by this change in the Python language itself, whose victims we will be able to count starting from 2020, the SciPy ecosystem has been subject to regular minor seismic activities by breaking changes in its foundational libraries, such as NumPy or matplotlib. I am not aware of any systematic study of their impact, but my personal anecdotal evidence (see e.g. this &lt;a href="http://blog.khinsen.net/posts/2017/04/06/reproducible-research-in-the-python-ecosystem-a-reality-check/"&gt;report&lt;/a&gt;) suggests that a Python script can be expected to work for two to three years, but not for five or more. Older scripts will either crash, which is a nuisance, or produce different results, which is much worse because the problem may well go unnoticed.&lt;/p&gt;

&lt;p&gt;In my corner of science, biomolecular simulation, the time scale of methodological progress is decades. This doesn&amp;rsquo;t mean that nothing exciting happens in shorter time spans. It just means that methods and techniques, including software, remain relevant for one to three decades. It isn&amp;rsquo;t even uncommon for a single research project to extend over several years. As an example, I just edited a script whose last modification date was December 2015. It&amp;rsquo;s part of collaborative project involving methodological development and application work in both experiment and theory. The back-and-forth exchanges between experimentalists and theoreticians take a lot of time. In the course of such projects, I update software and even change computers. If infrastructure updates break my code in progress, that&amp;rsquo;s a major productivity loss.&lt;/p&gt;

&lt;p&gt;Beyond personal productivity considerations, breaking changes are a threat to the reproducibility of scientific studies, an aspect that has been gaining more and more attention recently because so many published results were found to be non-reproducible or erroneous (note that these are very different things, but that&amp;rsquo;s not my topic for today), with software taking a big share of the responsibility. The two main issues are: (1) non-reproducible results cannot be trusted, because nobody really knows how they were obtained and (2) code whose results are non-reproducible is not a reliable basis for further work (Newton&amp;rsquo;s famous &amp;ldquo;standing on the shoulders of giants&amp;rdquo;). Many researchers, myself included, are advocating better practices to ensure computational reproducibility. In view of the seismic activities outlined above, I have been wondering for a while whether I should add &amp;ldquo;don&amp;rsquo;t use Python&amp;rdquo; to my list of recommendations. What&amp;rsquo;s holding me back is mainly the lack of any decent alternative to today&amp;rsquo;s SciPy ecosystem.&lt;/p&gt;

&lt;p&gt;Watching &lt;a href="https://www.youtube.com/watch?v=fowHwlpGb34"&gt;Nathaniel&amp;rsquo;s BIDS talk&lt;/a&gt;, I was rather disappointed that these issues were not treated at all. There is a general discussion of &amp;ldquo;change&amp;rdquo;, including a short reference to breaking changes and their impact on downstream projects, which suggests that there has been some debate of these questions in the NumPy community (note that I am no longer following the &lt;a href="https://mail.scipy.org/mailman/listinfo/numpy-discussion"&gt;NumPy discussion&lt;/a&gt; mailing list for lack of time). However, assuming that Nathaniel&amp;rsquo;s summary is representative of that debate, neither reproducibility nor the requirements of the different software layers in scientific computing seem to have received the attention they deserve.&lt;/p&gt;

&lt;p&gt;I have written before about &lt;a href="http://blog.khinsen.net/posts/2017/01/13/sustainable-software-and-reproducible-research-dealing-with-software-collapse/"&gt;software layers&lt;/a&gt; and the &lt;a href="http://blog.khinsen.net/posts/2015/11/09/the-lifecycle-of-digital-scientific-knowledge/"&gt;lifecycle of digital scientific knowledge&lt;/a&gt;, so I will just give a summary here. A scientific software stack looks like this:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Layer 4: project-specific code&lt;/li&gt;
 &lt;li&gt;Layer 3: domain-specific libraries&lt;/li&gt;
 &lt;li&gt;Layer 2: scientific infrastructure&lt;/li&gt;
 &lt;li&gt;Layer 1: non-scientific infrastructure&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;In the SciPy universe, we have Python in layer 1, NumPy and friends in layer 2, lots of lesser-known libraries (including my &lt;a href="http://dirac.cnrs-orleans.fr/MMTK/"&gt;MMTK&lt;/a&gt; mentioned above) in layer 3, and application scripts and notebooks in layer 4.&lt;/p&gt;

&lt;p&gt;A breaking change in any layer affects everything in the layers above. The authors of the affected higher-level code have three options:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;adapt their code (maintenance)&lt;/li&gt;
 &lt;li&gt;freeze their code (describe the stack they actually used)&lt;/li&gt;
 &lt;li&gt;do nothing&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;The first choice is of course the ideal case but it requires serious development resources. With the second one, archival reproducibility is guaranteed, i.e. a reader knows under which conditions the code can be used and trusted, and how these conditions can be recreated. But frozen code is not a good basis for further work. Using it requires much work for re-creating an outdated environment. Worse, using two or more of such packages together is in general impossible because each one has different dependency version requirements. Finally, the third option leaves the code in a limbo state where it isn&amp;rsquo;t even clear under which conditions it can be expected to work. In a research context, this ought to be considered unacceptable.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s consider now how these three choices are applied in practice, for each layer in the software stack. Software in layers 1 and 2 must obviously be maintained, otherwise people would quickly abandon it. Fortunately these layers also suffer the least from collapse, because there is less code below them. Layer 3 code gets more or less well maintained, depending on the size of the communities supporting it, and on the development resources available. Quite often, maintenance is sub-optimal for lack of resources, with the maintainers aware of the problem but unable to do a better job. That&amp;rsquo;s my situation with MMTK.&lt;/p&gt;

&lt;p&gt;Layer 4 code is the focus of the reproducible research movement. Today, most of this code is still not published, and of the small part that does get out, a large part is neither maintained nor frozen but simply dumped to a repository. In fact, the best practices recommended for reproducible research can be summarized as &amp;ldquo;freeze and publish layer 4 code&amp;rdquo;. Maintaining layer 4 code has been proposed (see e.g. &lt;a href="https://www.biorxiv.org/content/early/2016/08/11/056473"&gt;continuous analysis&lt;/a&gt; ), but it is unclear if the idea will find acceptance. The obvious open question is who should do the maintenance. Considering that most research is done by people who spend a few years in a lab and then move on, it&amp;rsquo;s difficult to assign the responsibility for maintenance to the original authors of the code. But anyone else is less competent, less motivated, and would likely expect to be payed for doing a service job.&lt;/p&gt;

&lt;p&gt;An argument I hear frequently in the SciPy community (and elsewhere) is that scientific code that is not actively used and maintained isn&amp;rsquo;t worth bothering with (see e.g. &lt;a href="https://twitter.com/ctitusbrown/status/929045580789161984"&gt;this tweet by Titus Brown&lt;/a&gt;). The implication is that breaking changes in the infrastructure layers are OK and must be absorbed by the maintainers of layers 3 and 4. In view of what I just said about layer 4, it should be obvious that I don&amp;rsquo;t agree at all with this point of view. But even concerning layer 3, I find it a bit arrogant. The message to research communities with weaker code development traditions, and thus fewer resources, is that their work doesn&amp;rsquo;t matter.&lt;/p&gt;

&lt;p&gt;I would like to see the SciPy community define its point of view on these issues openly and clearly. We all know that development resources are scarce, that not everything that&amp;rsquo;s desirable can be done. The real world requires compromises and priorities. But these compromises and priorities need to be discussed and communicated openly. It&amp;rsquo;s OK to say that the community&amp;rsquo;s priority is developing new features and that this leaves no resources for considering stability. But then please say openly and clearly that SciPy is a community for coding-intensive research and that people who don&amp;rsquo;t have the resources to adapt to breaking changes should look elsewhere. Say openly and clearly that reproducibility beyond a two-year timescale is not the SciPy community&amp;rsquo;s business, and that those who have such needs should look elsewhere. Or else, decide that SciPy is inclusive and caters for all computer-aided research - and draw the conclusion that stability must take a larger weight in future development decisions.&lt;/p&gt;

&lt;p&gt;What is not OK is what I perceive as the dominant attitude today: sell SciPy as a great easy-to-use tool for all scientists, and then, when people get bitten by breaking changes, tell them that it&amp;rsquo;s their fault for not having a solid maintenance plan for their code.&lt;/p&gt;

&lt;p&gt;Finally, in anticipation of an argument that I expect to see, let me stress that this is not a technical issue. Computing technology moves at a fast pace, but that doesn&amp;rsquo;t mean that lack of stability is a fatality. My &lt;a href="https://github.com/khinsen/hydrolib"&gt;last Fortran code&lt;/a&gt;, published in 1994, still works without changing a single line. Banks have been running Cobol code unchanged for decades. Today&amp;rsquo;s Java implementations will run the very first Java code from 1995 without changes, and even much faster thanks to JIT technology. This last example also shows that stability is not in contradiction with progress. You can have both if that&amp;rsquo;s a design goal. It&amp;rsquo;s all a matter of policy, not technology.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note added 2017&amp;ndash;11&amp;ndash;22:&lt;/strong&gt; see also my &lt;a href="http://blog.khinsen.net/posts/2017/11/22/stability-in-the-scipy-ecosystem-a-summary-of-the-discussion/"&gt;summary of the discussion&lt;/a&gt; in reaction to this post.&lt;/p&gt;</description></item>
  <item>
   <title>Why Python does so well in scientific computing</title>
   <link>http://blog.khinsen.net/posts/2017/09/12/why-python-does-so-well-in-scientific-computing/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2017-09-12-why-python-does-so-well-in-scientific-computing</guid>
   <pubDate>Tue, 12 Sep 2017 10:11:29 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;A few days ago, I noticed this tweet in my timeline:&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;
 &lt;p lang="en" dir="ltr"&gt;I &amp;#39;still&amp;#39; program in C. Why? Hint: it&amp;#39;s not about performance. I wrote an essay to elaborate... appearing at Onward! &lt;a href="https://t.co/pzxjfvUs5B"&gt;https://t.co/pzxjfvUs5B&lt;/a&gt;&lt;/p&gt;&amp;mdash; Stephen Kell (@stephenrkell) &lt;a href="https://twitter.com/stephenrkell/status/905126286762356736"&gt;September 5, 2017&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async="async" src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;That sounded like a good read for the weekend, which it was. The main argument the author makes is that C remains unsurpassed as a system integration language, because it permits interfacing with &amp;ldquo;alien&amp;rdquo; code, i.e. code written independently and perhaps even in different languages, down to assembly. In fact, C is one of the few programming languages that lets you deal with whatever data at the byte level. Most more &amp;ldquo;modern&amp;rdquo; languages prohibit such interfacing in the name of safety - the only memory you can access is memory allocated through your safe language&amp;rsquo;s runtime system. As a consequence, you are stuck in the closed universe of your language.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;System integration is indeed an important and often overlooked aspect of working with software. And this is particularly true for scientific computing, where application software with a fixed set of functionality is rare. Solving a scientific problem typically involves combining many pieces of software into a very problem-specific whole, which may well be run only a few times (see also my &lt;a href="http://blog.khinsen.net/posts/2017/01/13/sustainable-software-and-reproducible-research-dealing-with-software-collapse/"&gt;earlier post&lt;/a&gt; on this topic). This is exactly the task of system integration: assembling pieces into a whole using glue code where necessary. In computational science, this glue code takes the form of scripts, workflows, or more recently notebooks. This is technically quite different from the OS-level system integration that Stephen Kell refers to, but functionally it is the same.&lt;/p&gt;

&lt;p&gt;Stephen&amp;rsquo;s post reminded me of my long-standing plan to write a blog post about why Python has been so successful in scientific computing, in spite of having a reputation for bad performance. So&amp;hellip; here it is.&lt;/p&gt;

&lt;p&gt;There are of course many reasons for Python&amp;rsquo;s success, but one of them is that it does a pretty good job at system integration. There are two Python features that I consider important for this, which are not shared by many other languages. One is data types explicitly designed for interfacing, the other is &lt;a href="https://en.wikipedia.org/wiki/Duck_typing"&gt;duck typing&lt;/a&gt; in combination with a small but versatile set of standard interfaces.&lt;/p&gt;

&lt;p&gt;The first Python data type designed for interfacing in a scientific computing context is the good old &lt;a href="http://www.numpy.org/"&gt;NumPy&lt;/a&gt; array - which is in fact older than NumPy, having been introduced in 1995 by NumPy&amp;rsquo;s predecessor, Numeric. Arrays are one of the bread-and-butter data types in scientific computing, to the point of being the only one available in languages like Fortran 77 or APL. The implementation of arrays in Numeric was designed to use the same data layout as Fortran and C, in order to allow interfacing to the Fortran and C libraries that dominated scientific computing in 1995 (and still do, though to a somewhat lesser extent). The idea behind Numeric and later NumPy was always to use Python as a glue language for Fortran and C libraries, and achieve speed by delegating time-critical operations to code written in these languages.&lt;/p&gt;

&lt;p&gt;The second Python data type designed for interfacing is &lt;a href="https://docs.python.org/3/library/stdtypes.html#memoryview"&gt;memoryview&lt;/a&gt;, related to the &lt;a href="https://docs.python.org/3/c-api/buffer.html"&gt;buffer protocol&lt;/a&gt;. This is as close as Python gets to C-style memory access. The buffer protocol lets different Python data types access each other&amp;rsquo;s internal memory at the byte level. A typical use case would be an image data type (e.g. from &lt;a href="https://python-pillow.org/"&gt;Pillow&lt;/a&gt;) allowing access to the in-memory representation of an image through an array type (e.g. from NumPy), permitting the implementation of image manipulation algorithms in terms of array operations.&lt;/p&gt;

&lt;p&gt;The third and least known Python data type for interfacing is the &lt;a href="https://docs.python.org/3/c-api/capsule.html"&gt;capsule&lt;/a&gt; that replaces the earlier &lt;a href="https://docs.python.org/2/c-api/cobject.html"&gt;CObject&lt;/a&gt;. Capsules exist solely for the benefit of Python modules written in C, which can exchange opaque data with one another via glue code written in Python, even though the glue code itself cannot inspect or manipulate the data in any way. A typical use is to wrap C function pointers in a Python object such that Python glue code, e.g. a script, can pass a C function from one module to a to C code from another module.&lt;/p&gt;

&lt;p&gt;All these interfacing data types mediate between Python and C code, although quite often the Python system integrator is hardly aware of using C code at all. The other Python feature for system integration, duck typing with standard interfaces, is what facilitates glueing together independently written Python modules. By &amp;ldquo;standard interfaces&amp;rdquo;, I mean the sequence and dictionary interfaces, but also the standard method names for operator overloading.&lt;/p&gt;

&lt;p&gt;To see why this is an important feature, let us look at statically typed languages that by design do not have it. As a concrete example, consider multidimensional arrays in Java. They are not part of the language or its standard library, but they can be implemented on top of it with reasonable effort. In fact, there are several Java implementations you can choose from. And that&amp;rsquo;s the problem. Suppose you want to use an FFT library based on array implementation A together with a linear algebra library based on array implementation B. Bad luck - the arrays from A and B have different types, so you cannot use the output of an FFT as the input to a linear equation solver. It doesn&amp;rsquo;t matter that the underlying abstraction is the same, and that even the implementations have much in common. For a Java compiler, tje types don&amp;rsquo;t match, period.&lt;/p&gt;

&lt;p&gt;Python is not completely immune to this problem. It is perfectly possible to write Python code, or C code in a C module, that expects a precise type of data as input, and will raise an exception otherwise. But in Python code that would be considered bad style, and in C modules for Python as well except where required for performance or for compatibility with the C code. Wherever possible, Python programmers are expected to use the standard interfaces for working with data. Iteration and indexing work the same way for arrays as for the built-in lists, for example. For operations that are not covered by the standard interfaces, Python programmers are supposed to use Python methods, which are subject to duck typing as well. In practice, independently implemented Python types are much more interoperable than independently implemented Java types. For the specific case of n-dimensional arrays, Python has had the chance of overwhelming acceptance of a single implementation, which is due more to social and historical than to technical issues.&lt;/p&gt;

&lt;p&gt;Finally, even though Python is a pretty good choice for system integration in scientific computing, there are of course limits, which are exactly of the kind that Stephen Kell explains in his essay: combining Python code with code in other managed languages, say R or Julia, requires a lot of work and even then is fragile, because the required hacks depend on undocumented implementation details. I suspect that the only solution would be to have language-neutral garbage-collected data objects proposed as an OS-level service that maintains an option for non-managed byte-level access Ã  la C. The closest existing technology I am aware of is Microsoft&amp;rsquo;s &lt;a href="https://en.wikipedia.org/wiki/Common_Language_Runtime"&gt;CLR&lt;/a&gt;, better known by its commercial name .NET. Its implementation is now Open Source and runs on multiple platforms, but its Windows-only origins and strong ties to a huge Microsoft-y library have been an obstacle to adoption by the traditionally Unix-centric scientific computing communty.&lt;/p&gt;</description></item>
  <item>
   <title>Composition is the root of all evil</title>
   <link>http://blog.khinsen.net/posts/2016/03/04/composition-is-the-root-of-all-evil/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2016-03-04-composition-is-the-root-of-all-evil</guid>
   <pubDate>Fri, 04 Mar 2016 10:14:03 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Think of all the things you hate about using computers in doing research. Software installation. Getting your colleagues&amp;rsquo; scripts to work on your machine. System updates that break your computational code. The multitude of file formats and the eternal need for conversion. That great library that&amp;rsquo;s unfortunately written in the wrong language for you. Dependency and provenance tracking. Irreproducible computations. They all have something in common: they are consequences of the difficulty of composing digital information. In the following, I will explain the root causes of these problem. That won&amp;rsquo;t make them go away, but understanding the issues will perhaps help you to deal with them more efficiently, and to avoid them as much as possible in the future.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;Composing information is something we all do every day, mostly without thinking of it. A shopping list is the composition of names of things you need to buy. An e-mail message is the composition of the recipients&amp;rsquo; addresses, a subject line, and the body of the message. An address book is a composition of addresses, which in turn are compositions of various pieces of information related to some person.&lt;/p&gt;

&lt;p&gt;Science has its own information items and associated compositions. Measurements are composed into tables. Mathematical equations are composed into more complex equations. Datasets are composed to make a database. Hypotheses are composed to make a model.&lt;/p&gt;

&lt;p&gt;Writing computer programs means composing expressions and statements into procedures or functions, composing procedures to make modules, and composing modules to make programs. Reading data from a file means composing your algorithms with the data they work on into a complete computation. Configuring a new computer and installing software are about composing an operating system, various libraries, and application software into a functioning whole.&lt;/p&gt;

&lt;p&gt;When you look at these examples more closely, you might notice that some of these acts of composition are so trivial that we don&amp;rsquo;t even think about them, whereas others are a real pain. In that second category, we find most of the composition work related to computers. So what is the difference?&lt;/p&gt;

&lt;h3 id="human-and-computational-information-processing"&gt;Human and computational information processing&lt;/h3&gt;

&lt;p&gt;Humans process information in terms of concepts. We all have accumulated a vast amount of conceptual knowledge over our lifetime, starting with the most basic concepts that we learned in infancy. This knowledge includes the definitions of all the concepts, but also the relations between them. Our knowledge of concepts helps us to &amp;ldquo;make sense&amp;rdquo; of information, which includes the detection of probable mistakes and sometimes even their correction. Humans are very tolerant to mistakes and variations in how some piece of information is expressed. We don&amp;rsquo;t care if the items in a shopping list are arranged vertically or horizontally, for example.&lt;/p&gt;

&lt;p&gt;When composing information, we read the individual items, translate them into concepts, and then write out the composition. I use the vocabulary of processing written language here, but the same holds for oral or visual communication. Variations in notation may be an inconvenience, but not a real problem. As long as the information refers to familiar concepts, we can deal with it.&lt;/p&gt;

&lt;p&gt;Computers process information by applying precise mechanical rules. They don&amp;rsquo;t care about concepts, nor about context. If you ask a computer to do something stupid, it will happily do so. This may look like a criticism of how computers work, but it&amp;rsquo;s also exactly why they are so useful in research: they have different strengths and weaknesses compared to humans, and are therefore complementary &amp;ldquo;partners&amp;rdquo; in solving problems.&lt;/p&gt;

&lt;h3 id="formal-languages"&gt;Formal languages&lt;/h3&gt;

&lt;p&gt;At the hardware level of a digital computer, a computation is a multi-step process that transforms an input bit sequence into an output bit sequence under the control of a program that is stored as a bit sequence as well. Information processing by computers thus requires all data to be expressed as bit sequences. Dealing with bit sequences is, however, very inconvenient for humans. We therefore use data representations that are more suitable for human brains, but still exactly convertible from and to the bit sequences that are stored in a computer&amp;rsquo;s memory. These representations are called &lt;a href="http://en.wikipedia.org/wiki/Template:Formal_languages_and_grammars"&gt;&lt;em&gt;formal languages&lt;/em&gt;&lt;/a&gt;. The definition of a formal language specifies precisely how some piece of information is encoded as sequences of bits. Many formal languages are defined in terms of sequences of text characters instead of sequences of bits, for another level of human convenience. Since the mapping from text characters to bits is straightforward, this makes little difference in practice. The term &amp;ldquo;formal language&amp;rdquo; is commonly used in computer science, but in computational science we usually speak of &amp;ldquo;data formats&amp;rdquo;, &amp;ldquo;file formats&amp;rdquo;, and &amp;ldquo;programming languages&amp;rdquo;, all of which are specific kinds of formal languages. The use of formal languages, rather the the informal languages of human communication, is the defining characteristic of digital information.&lt;/p&gt;

&lt;p&gt;The definition of a formal language consists of two parts, syntax and semantics. Syntax defines which bit patterns or text strings are valid data items in the language. Syntax rules can be verified by a suitable program called a parser. Semantics define the &lt;em&gt;meaning&lt;/em&gt; of syntactically correct data items. With one important exception, semantics are mere conventions for the interpretation of digital data. Meaning refers to conceptual knowledge that a computer neither has nor needs: all it does is process bit sequences. The exception concerns formal languages for expressing algorithms, i.e. rules for the transformation of data. The semantics of an algorithmic language defines how each operation transforms input data into output data. Writing down such transformation rules obviously requires a notation for the data is being worked on. For that reason, a formal language that can express algorithms also defines the syntax and semantics of the input and output data for these algorithms. Your favorite programming language, whichever it is, provides a good illustration.&lt;/p&gt;

&lt;p&gt;There is a huge number of formal languages today, which can be organized into a hierarchy of abstraction layers, such that languages at a higher level incorporate languages from lower levels. As a simple example, a programming language such as Fortran incorporates formal languages defining individual data elements - integers, floating-point numbers, etc. At the lowest level of this hierarchy, close to the bit level at which computing hardware operates, we have formal languages such as &lt;a href="http://unicode.org/"&gt;Unicode&lt;/a&gt; for text characters or the floating-point number formats of &lt;a href="http://dx.doi.org/10.1109%2FIEEESTD.2008.4610935"&gt;IEEE standard 754&lt;/a&gt;. One level up we find the memory layout of Fortran arrays, the layout of &lt;a href="https://en.wikipedia.org/wiki/UTF-8"&gt;UTF&amp;ndash;8&lt;/a&gt; encoded text files, and many other basic data structures and file formats. Structured file formats such as XML or HDF5 are defined on the next higher level, as they incorporate basic data structures such as arrays or text strings. Programming languages such as Python or C reside on that level as well.&lt;/p&gt;

&lt;p&gt;Different formal languages that encode the same information at the semantic level can be converted into each other. The two best-known translations of this kind in the daily life of a computational scientist are file-format conversion and the compilation of software source code into processor instructions. However, if you take into account that the in-memory data layout of any program is a formal language as well, all I/O operations can be considered conversions between two formal languages.&lt;/p&gt;

&lt;h3 id="composition-of-digital-information"&gt;Composition of digital information&lt;/h3&gt;

&lt;p&gt;Digital information is, by definition, information expressed in a formal language. Composition of digital information produces a new, more complex, digital information item, which is of course expressed in a formal language as well. And since the ingredients remain accessible as parts of the whole, everything must be expressed in one and the same formal language. And that&amp;rsquo;s where all our trouble comes from.&lt;/p&gt;

&lt;p&gt;If we start from ingredients expressed in different languages, we have basically two options: translate everything to a common language, or define a new formal superlanguage that incorporates all the languages used for expressing the various ingredients. We can of course choose a mixture of these two extreme approaches. But both of them imply a lot of overhead and add considerable complexity to the composed assembly. Translation requires either tedious and error-prone manual labor, or writing a program to do the job. Defining a superlanguage requires implementing software tools for processing this new superlanguage.&lt;/p&gt;

&lt;p&gt;As an illustration, consider a frequent situation in computational science: a data processing program that reads a specific file format, and a dataset stored in a different format. The translation option means writing a file format converter. The superlanguage option means extending the data processing program to read a second file format. In both cases, the use of multiple formal languages adds complexity to the composition that is unrelated to the real problem to be solved, which is the data analysis. In software engineering, this is known as "&lt;a href="https://en.wikipedia.org/wiki/No_Silver_Bullet"&gt;accidental complexity&lt;/a&gt;", as opposed to the &amp;ldquo;essential complexity&amp;rdquo; inherent in the problem.&lt;/p&gt;

&lt;p&gt;As a second example, consider writing a program that is supposed to call a procedure written in language A and another procedure written in language B. The translation option means writing a compiler from A to B or vice-versa. The superlanguage option means writing an interpreter or compiler that accepts both languages A and B. A mixed approach could use two compilers, one for A and one for B, that share a common target language. The latter solution seems easy at first sight, because compilers from A and B to processor instructions probably already exist. However, the target language of a compiler is not &amp;ldquo;processor instruction set&amp;rdquo; but &amp;ldquo;processor instruction set plus specific representations of data structures and conventions for memory management&amp;rdquo;. It is unlikely that two unrelated compilers for A and B are compatible at that level. Practice has shown that combining code written in different programming languages is always a source of trouble, except when using tools that were explicitly designed for implementing the superlanguage from the start.&lt;/p&gt;

&lt;p&gt;In the last paragraph, I have adopted a somewhat unusual point of view which I will continue to use in the following. We usually think of a language as something named and documented, such as C or Unicode. The point of view I adopt here is that the language in which a piece of digital information is expressed consists of all the rules and constraints that must be satisfied, &lt;em&gt;including the rules and constraints due to composition&lt;/em&gt;. To illustrate the difference, consider the &lt;a href="https://www.python.org/"&gt;Python language&lt;/a&gt; and the Python language with the &lt;a href="http://www.numpy.org/"&gt;NumPy extension&lt;/a&gt;. According to the standard point of view, Python is the language and NumPy is a library written in Python. In my point of view, Python+NumPy is a language &lt;em&gt;different&lt;/em&gt; from plain Python. To see that libraries modify their underlying languages, consider the Python statement &lt;code&gt;import numpy&lt;/code&gt;. It fails in plain Python, so it is not a valid statement in the Python language, whereas it is valid in the Python+NumPy language. Moreover, in the Python+NumPy language you are not allowed to write a module called &lt;code&gt;numpy&lt;/code&gt;. The addition of NumPy to plain Python makes some formerly invalid programs valid and vice versa, which justifies speaking of different, though certainly similar, languages.&lt;/p&gt;

&lt;h3 id="lots-of-languages-lots-of-problems"&gt;Lots of languages, lots of problems&lt;/h3&gt;

&lt;p&gt;The above discussion suggests that to keep our lives simple, we should use as few different formal languages as possible. Unfortunately, an inventory of what we have to deal with shows that we are very far from that optimum.&lt;/p&gt;

&lt;p&gt;Data formats are the easiest part. Even the number of &amp;ldquo;standard&amp;rdquo; formats is enormous, and many of them aren&amp;rsquo;t that well standardized, leading to different dialects. Worse, many scientific programs make up their own &lt;em&gt;ad-hoc&lt;/em&gt; data formats that are scarcely documented. That&amp;rsquo;s why file conversion takes up so much of our time. Moreover, we usually have different on-disk and in-memory data formats for the same data, which is why we need to write I/O routines for our software.&lt;/p&gt;

&lt;p&gt;But the complexity of formal languages used to define programs completely dwarfs the complexity of data formats. Let&amp;rsquo;s start at the bottom level: the processor&amp;rsquo;s instruction set. If you write an operating system (OS), that&amp;rsquo;s the level you work at. Otherwise, your program is a plug-in to be composed with an operating system, and the operating system defines the formal language in which you need to provide your program. The &amp;ldquo;OS language&amp;rdquo; includes the processor&amp;rsquo;s instruction set, but also adds constraints (memory use, relocatability, &amp;hellip;) and access to OS functions. The OS language can be as simple as the &lt;a href="https://en.wikipedia.org/wiki/COM_file"&gt;COM file format&lt;/a&gt; from CP/M and DOS days but also as complex as Linux&amp;rsquo; &lt;a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format"&gt;ELF format&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The ELF format introduces the next level of composition: object files and dynamic libraries, in addition to executable files. In a modern OS, a program is composed from several ingredients immediately before execution. The motivation for introducing this last-minute composition was the possibility to share frequently used program building blocks among the hundreds of processes running in parallel, thus reducing their memory footprint. But this comes at the price of considerable accidental complexity. The OS language that your program must be written in now includes note only the processor instruction set and the ELF format specification, but also conventions about where certain shared libraries are stored in the file system. That&amp;rsquo;s why it is no longer possible to prepare a generic program for the Linux platform. Different Linux distributions have different conventions for arranging the shared libraries in the file system, and moreover these conventions change over time. They have different OS languages.&lt;/p&gt;

&lt;p&gt;Upon closer inspection, the situation is actually even worse. The OS language for a given piece of software includes &lt;em&gt;all the software packages that have been installed on the same computer before&lt;/em&gt;. Obviously, only one software package can occupy a given filename. Once you have installed a package that uses the file &lt;code&gt;/usr/lib/libm.so&lt;/code&gt;, no other package can occupy the same slot. That makes it impossible to wrap up &amp;ldquo;my program and all the files it requires&amp;rdquo; for installation on some other machine. If package A contains &lt;code&gt;/usr/lib/libm.so&lt;/code&gt; and package B another &lt;code&gt;/usr/lib/libm.so&lt;/code&gt;, even if it is only a slightly older version of the same library, the two packages could not coexist. The only solution is to distribute programs and libraries as building blocks to be added to a growing assembly, whose composition - now called &amp;ldquo;software installation - is left to the system administrator. Each block comes with a list of "required dependencies&amp;rdquo;, whose presence the system administrator must ensure. Moreover, each block occupies certain slots that must be available in the system. In the terminology of formal languages, each new block must conform to a language that its author cannot know in advance, and cannot even fully describe. I have described this error-prone approach in an &lt;a href="http://www.activepapers.org/2014/01/31/Installing-Software.html"&gt;earlier blog post&lt;/a&gt; as the Tetris model of software installation, because of its obvious similarities with the well-known video game. It&amp;rsquo;s the most widely used model in scientific computing today.&lt;/p&gt;

&lt;p&gt;The obvious problems caused by this approach have motivated the development of various tools for the management of software installations. Some are specific to some OS platform (the package managers of Debian, RedHat, BSD, etc.). Others are specific to a programming language, e.g. Python&amp;rsquo;s &lt;code&gt;distutils&lt;/code&gt; system and its derivates. The multitude of software installation managers has created a secondary composition problem: to install a Python package on a Debian system, you must negotiate a compromise between Python&amp;rsquo;s and Debian&amp;rsquo;s views on how software installation should be managed.&lt;/p&gt;

&lt;p&gt;Another approach is to give up on sharing common resources, and provide some way to package programs with all the files they need into a single unit, even if this leads to duplication of data on disk and in memory. This is the idea behind MacOS X application bundles (which go back to &lt;a href="https://en.wikipedia.org/wiki/NeXTSTEP"&gt;NextSTEP&lt;/a&gt;) and also &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; containers. Tools such as Python&amp;rsquo;s &lt;a href="https://pypi.python.org/pypi/virtualenv"&gt;&lt;code&gt;virtualenv&lt;/code&gt;&lt;/a&gt; proceed in a similar way, by isolating a specific composition of building blocks from other potentially conflicting compositions of building blocks on the same computer.&lt;/p&gt;

&lt;p&gt;An ingenious construction that combines the best of both worlds is the approach taken by the &lt;a href="http://nixos.org/"&gt;Nix&lt;/a&gt; package manager and its offshoot &lt;a href="https://www.gnu.org/software/guix/"&gt;Guix&lt;/a&gt;. Instead of having building blocks refer to each other through filenames, they use a hash code computed from the actual contents of the files. This allows the composition of arbitrary building blocks, including pairs that would claim the same filenames in a standard Linux system, but also prevents multiple identical copies of any building block. This idea is known as &lt;a href="https://en.wikipedia.org/wiki/Content-addressable_storage"&gt;content-addressable storage&lt;/a&gt;, and is also used in the popular version control system &lt;a href="https://git-scm.com/"&gt;git&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Up to here, I have described the composition of specific programs with an operating system. But the program that is prepared as a plug-in to an OS is itself already a composition. How it is composed and from which constituents depends on the programming language(s) being used and on the tools that implement them. In Python, for example, a program consists in general of packages which consist of modules which consist of name-value pairs. A C program consists of source code files and header files, which each contain value and function definitions and interact via macro definitions. Like in the case of the &amp;ldquo;OS language&amp;rdquo;, the precise formal language in which each piece is written is not just Python or C. It also includes constraints and extensions coming from other building blocks &amp;mdash; libraries &amp;mdash; that the program refers to, as I have illustrated above for the example of Python plus NumPy.&lt;/p&gt;

&lt;p&gt;Comparing these two situations, we can identify the common culprit: the use of a global namespace for composing building blocks. In the &amp;ldquo;OS language&amp;rdquo; of a typical Linux system, the global namespace is the filesystem. In Python, it&amp;rsquo;s the namespace of top-level module names. In C, it&amp;rsquo;s the namespace of non-static top-level definitions. Composition requires one building block to refer to another building block through a name in that namespace. And that in turn requires each building block to occupy a specific name in that namespace, so that others can refer to it.&lt;/p&gt;

&lt;p&gt;One way to alleviate this problem is encouraging the use of very specific names. That&amp;rsquo;s the approach taken by Java, whose global namespace for packages is supposed to contain &amp;ldquo;reversed domain names&amp;rdquo; such as &lt;code&gt;org.apache.commons.lang3.math&lt;/code&gt;. While such a rule, if respected, indeed reduces the risk of name collisions between unrelated packages to almost zero, the most frequent source of name collisions remains: different versions of a package have the same name and can therefore not be used together in a composition. When composing building blocks into a program, one can argue that mixing different versions is bad practice anyway. But in the Tetris model of a single global software collection per computer, not being able to have several versions of a building block is often a serious restriction.&lt;/p&gt;

&lt;p&gt;A final kind of formal language worth mentioning in this context is languages for defining compositions. This category includes Makefiles, Dockerfiles autoconf configuration files, and of course the package specification files of the various package managers. Their multitude shows the importance of the composition problem, but it also contributes to it. It is not rare to see a specification file for one package manager refer to another package manager. Conversion from one such language to another is nearly impossible, because the precise language for defining a composition depends not only on the package manager, but also on the other existing packages. It&amp;rsquo;s exactly the same situation as with the &amp;ldquo;OS language&amp;rdquo; and programming languages extended by libraries.&lt;/p&gt;

&lt;h3 id="is-there-a-way-out"&gt;Is there a way out?&lt;/h3&gt;

&lt;p&gt;I believe that there is, and I have some ideas about this, but I will leave them for another time as this post is already quite long. I hope that the above analysis contributes to a better understanding of the problems that computational scientists are facing in their daily work, which is the prerequisite to improving the situation.&lt;/p&gt;

&lt;p&gt;As a first step, I encourage everyone to prefer &lt;em&gt;solutions&lt;/em&gt; to &lt;em&gt;workarounds&lt;/em&gt; when faced with composition-related issues. Solutions identify a cause and eliminate it, whereas workarounds merely alleviate the impact of the problem, often re-creating the same problem at another level later on. In the approaches I have discussed above, an example of a solution is content-addressable storage, as used in Nix. In contrast, the traditional Linux package managers are workarounds, because they re-create a composition issue at the package level. Linux distribution authors have done a lot of hard and useful work with these package managers, which I don&amp;rsquo;t want to play down in any way. But the fruit of that work can be carried over to better foundations. The Tetris model of software installation is not sustainable in my opinion. We have to move on.&lt;/p&gt;</description></item>
  <item>
   <title>On HDF5 and the future of data management</title>
   <link>http://blog.khinsen.net/posts/2016/01/07/on-hdf5-and-the-future-of-data-management/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2016-01-07-on-hdf5-and-the-future-of-data-management</guid>
   <pubDate>Thu, 07 Jan 2016 15:09:10 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Yesterday a &lt;a href="http://cyrille.rossant.net/moving-away-hdf5/"&gt;blog post&lt;/a&gt; by Cyrille Rossant entitled &amp;ldquo;Moving away from HDF5&amp;rdquo; caught my eye. My own tendency at the moment is to use HDF5 more and more, so I was interested in why someone else would want to do the opposite. Here is my conclusion after reading his post, plus some ideas about where scientific data management is or should be heading in my opinion.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;Any evaluation of some technology happens in the context of a specific application&amp;rsquo;s requirements, and this is where Cyrille&amp;rsquo;s and my own experience differ in an important point: I have never run into performance problems with HDF5, probably because my jobs do much more computation (relative to I/O) than his. This also makes parallel access less of a problem for me, although I agree that HDF5&amp;rsquo;s parallel support could be better.&lt;/p&gt;

&lt;p&gt;Otherwise, I agree with much of his criticism of HDF5, but I still conclude that its problems are the smallest evil compared to any other technology I know of. The big problem with HDF5 from my point of view is what Cyrille calls &amp;ldquo;opacity&amp;rdquo;: the complexity of the file format which in practice means that the only way to use HDF5 files is via the HDF5 library. Which is, indeed, far from perfect. However, given my requirements, there is pretty much no competition to HDF5. The only alternative would be to roll my own system, which isn&amp;rsquo;t a pleasant idea either.&lt;/p&gt;

&lt;p&gt;The peculiar combination of requirements that to the best of my knowledge only HDF5 fulfills is:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;the hierarchical management of multiple datasets with associated metadata as a single unit for archiving and publishing&lt;/li&gt;
 &lt;li&gt;efficient access to the individual datasets&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;The first requirement rules out the approach of using a directory with lot of individual files. The second requirement rules out container formats such as zip - having to unpack a dataset for processing is too much overhead.&lt;/p&gt;

&lt;p&gt;My first requirement is exactly what Cyrille describes as the &amp;ldquo;HDF5 philosophy&amp;rdquo;, so it&amp;rsquo;s no wonder that HDF5 fits my needs rather well. His question &amp;ldquo;One can wonder why not just use a hierarchy of files within a directory.&amp;rdquo; thus deserves a few comments. I have done that for a while, and many of my colleagues still do it. My experience is that, after copying around the data between different machines a few times, I always ended up losing files or having mismatched versions. Which, of course, raises the questions why I copy around the data.&lt;/p&gt;

&lt;p&gt;Cyrille says that &amp;ldquo;today&amp;rsquo;s datasets are so big that they don&amp;rsquo;t tend to move a lot.&amp;rdquo; Well, first of all, mine are not &lt;em&gt;that&lt;/em&gt; big. My HDF5 files are a few MB to a few GB in size. Individual datasets range from a few hundred bytes to a few GB, and the number of datasets in a HDF5 file ranges from ten to a few thousand. And I copy them around because I handle different tasks in my workflow on different machines. Most data transfers happen between my desktop/laptop and the computing cluster that I use for number crunching. I couldn&amp;rsquo;t do the number crunching on my desk, nor the data inspection and visualization on the cluster in batch mode. Since the two machines have no shared file storage, I can&amp;rsquo;t avoid copying the data back and forth. Moreover, collaborators&amp;rsquo; desktop machines participate in the overall workflow as well.&lt;/p&gt;

&lt;p&gt;For jobs that handle much bigger datasets, copying is indeed not an option, and the usual way to work is to keep the data on a single server-type machine that also handled the computation. I cannot use that kind of setup because I have neither my software nor my computers are made for it. All my software was written with local disk storage in mind - just like HDF5.&lt;/p&gt;

&lt;p&gt;Taking a step back from the technical details, my analysis of the situation is that we are living in a transition period from local to distributed storage of scientific data. Local storage was the only option in the past, before fast networks came along. Distributed storage is what fits today&amp;rsquo;s working patterns best: large data, geographically widespread collaborations, etc. But distributed storage still lacks good infrastructure, and is therefore badly supported by much scientific software.&lt;/p&gt;

&lt;p&gt;The future of scientific data management is, in my opinion, something like &lt;a href="https://ipfs.io/"&gt;IPFS&lt;/a&gt;: a single logical view of data spread out over a vast network of machines. Software accesses the data using a mixture of references (like filenames, URLs, etc.) and content-based addressing (e.g. through hashes). If performance demands local storage, the data is cached by the middleware. The middleware also ensures availability with decent performance and redundant storage to prevent data loss. No data would ever be copied explicitly, but simply retrieved &amp;ldquo;from the cloud&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;In such a world, my HDF5 files would become small datasets containing references to other, potentially big datasets, plus metadata. Content-based addressing plus transparant data movements performed by the middleware would ensure coherence - nothing would be messed up by me shoveling data around with manually typed scp commands. I suspect Cyrille would be happy with this as well. The only problem is that we do not have this infrastructure. Worse, given the cost and building and maintaining such infrastructure, we are not likely to have it for many years to come. So&amp;hellip; after this short dream, it&amp;rsquo;s back to HDF5 for me.&lt;/p&gt;</description></item>
  <item>
   <title>A rant about software deployment in 2015</title>
   <link>http://blog.khinsen.net/posts/2015/11/06/a-rant-about-software-deployment-in-2015/?utm_source=scientific-computing&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2015-11-06-a-rant-about-software-deployment-in-2015</guid>
   <pubDate>Fri, 06 Nov 2015 12:13:32 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;We all know that software deployment in a research environment can be a pain, but knowing this as a fact is not quite the same as experiencing it in reality. Over the last days, I spent way more time that I would have imagined on what sounds like a simple task: installing a scientific application written in Python on a Linux machine for use by a group of students in a training session. Here is an outline of the difficulties, in the hope that it will (1) help others who face similar problems and (2) contributes a little bit to improving the situation.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The software that I installed is &lt;a href="http://dirac.cnrs-orleans.fr/nMOLDYN/"&gt;nMOLDYN&lt;/a&gt;, an analysis tool for Molecular Dynamics trajectories. From a software engineering point of view, this is a rather standard Python program building on &lt;a href="http://numpy.scipy.org"&gt;NumPy&lt;/a&gt; and &lt;a href="http://dirac.cnrs-orleans.fr/MMTK"&gt;MMTK&lt;/a&gt; for its computations and on &lt;a href="https://wiki.python.org/moin/TkInter"&gt;Tkinter&lt;/a&gt; and &lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt; for the graphical user interface. There is no need for anything on the bleeding edge, a decent three-year old installation of the scientific Python stack would support this perfectly well.&lt;/p&gt;

&lt;p&gt;The machine that was set up for the training session is configured much like a typical node in a compute cluster: stable and trusted software installed once and never updated. More specifically, the machine runs &lt;a href="https://www.centos.org/"&gt;CentOS&lt;/a&gt; 6.7. Another feature rather typical of compute nodes is the very restricted network connectivity: users can log in via &lt;code&gt;ssh&lt;/code&gt;, and copy data in and out using &lt;code&gt;scp&lt;/code&gt;. Everything else is blocked, in particular all outgoing network traffic. The idea is that students will work on desktop or laptop machines, from where they have full network access to search for information, and connect to the compute server only for running scientific software. For my own software installation I had to limit myself to a user account, i.e. no administrator rights, although I could ask the systems administrator to install additional RPMs from CentOS.&lt;/p&gt;

&lt;p&gt;A first exploration of the system&amp;rsquo;s Python installation showed a collection of oldies: Python 2.6.6, NumPy 1.4.1, matplotlib 0.99.1.1. That&amp;rsquo;s the state of the art five years ago. I quickly decided not to use it at all, for two reasons. First, I wasn&amp;rsquo;t sure how much of what I had to add would still work with such old versions. All the software was already around five years ago, but I would have had to track down the versions that were current back then. Second, adding modules in a user account to a Python installation at the system level can easily lead to a fragile total. Following Murphy&amp;rsquo;s law such problems would show up during the student sessions. So I decided to start with a fresh install of Python 2.7.&lt;/p&gt;

&lt;p&gt;First surprise: no C compiler. An e-mail to the administrator, and I had gcc. Trying to install Python showed that the Tcl/Tk setup was incomplete: the header files were missing. An another e-mail asking for tcl-devel and tk-devel, and that was settled as well. Python, NumPy, netCDF, ScientificPython, and MMTK were up and running half an hour later. An attempt to install nMOLDYN resulted in the information that I still needed to install Pyro and matplotlib. That can&amp;rsquo;t be so hard, right?&lt;/p&gt;

&lt;p&gt;Pyro was no problem indeed, but matplotlib kept me busy for a few more hours. All I had done in the past was &lt;code&gt;pip install matplotlib&lt;/code&gt;, but &lt;code&gt;pip&lt;/code&gt; is useless without outgoing network connections. I had to track down source tarballs for matplotlib and all its dependencies. There&amp;rsquo;s a &lt;a href="http://matplotlib.org/users/installing.html"&gt;list&lt;/a&gt; of dependencies on the matplotlib Web site, but it&amp;rsquo;s incomplete in two ways: some dependencies are missing (setuptools and six), and others are given by name but without a link. Try googling for &amp;ldquo;cycler&amp;rdquo; - you will learn a lot about celestial mechanics before you find a package with this name on &lt;a href="https://pypi.python.org/pypi"&gt;PyPI&lt;/a&gt;. Of all the matplotlib dependencides, only freetype was already available on my machine, so I had some searching and downloading to do.&lt;/p&gt;

&lt;p&gt;The installation instructions for setuptools clearly do not consider the possibility of not having a network connection. They tell me to download a Python script and execute it to download the real software. Fortunately, there is the &amp;ldquo;advanced&amp;rdquo; installation option via a tarball. Which ends rather quickly with an error message complaining about the absence of the &lt;code&gt;zlib&lt;/code&gt; module.&lt;/p&gt;

&lt;p&gt;That module is part of the Python standard library, but it is compiled only if zlib (the C library) is installed on the machine. It wasn&amp;rsquo;t on mine. This is not particularly difficult to fix, but rather annoying: I had to install zlib, and then run the Python installation once more. Not to forget: I knew &lt;code&gt;zlib&lt;/code&gt; was in the standard library, and I immediately saw why it was missing on my machine, because I have been installing Pythons in lots of environments over twenty years. Someone else might well have spent a few hours figuring out what to do about zlib.&lt;/p&gt;

&lt;p&gt;From then on everything went smoothly, so this is the end of my story. In order to provide something constructive, here is the complete list of matplotlib dependencies with links, and in the order of installation:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="http://www.zlib.net/"&gt;zlib&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://www.python.org/"&gt;Python&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://www.numpy.org/"&gt;numpy&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/setuptools"&gt;setuptools&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/six"&gt;six&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/Cycler"&gt;cycler&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/pyparsing"&gt;pyparsing&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/python-dateutil"&gt;python-dateutil&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://pypi.python.org/pypi/pytz"&gt;pytz&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://www.libpng.org/pub/png/libpng.html"&gt;libpng&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Finally, I will pass on a hint that came in this morning via Twitter:&lt;/p&gt;

&lt;blockquote class="twitter-tweet" lang="de"&gt;
 &lt;p lang="en" dir="ltr"&gt;&lt;a href="https://twitter.com/khinsen"&gt;@khinsen&lt;/a&gt; &lt;a href="https://twitter.com/MrTheodor"&gt;@MrTheodor&lt;/a&gt; pip install âdownload . âno-use-wheel &amp;lt;foobar&amp;gt;&amp;#10;&amp;#10;Wonât work if there are Linux specific dependencies though.&lt;/p&gt;&amp;mdash; Donald Stufft (@dstufft) &lt;a href="https://twitter.com/dstufft/status/662620534010740736"&gt;6. November 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async="async" src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;Using &lt;code&gt;pip install --download . --no-use-wheel matplotlib&lt;/code&gt;, run of course on a machine that has a network connection, you get tarballs for matplotlib and all its dependencies that pip knows about. You still have to add setuptools (which pip doesn&amp;rsquo;t download because it depends on it itself), the C libraries libpng and zlib, and of course Python&amp;rsquo;s standard but not-always-there &lt;code&gt;zlib&lt;/code&gt; module.&lt;/p&gt;

&lt;p&gt;Looking back at my twenty years using Python, I come to the unfortunate conclusion that software installation is much more of a problem today than it was back in 1995. The main reason is of course that Python software has become more feature-rich and complex - in 1995 something like matplotlib was only a dream. But the state of Python packaging tools is also to blame, with three overlapping and partially compatible tools (distutils, setuptools, and distribute) creating a lot of confusion and various distribution formats (tarballs, eggs, wheels) adding another layer of complexity. What is also sorely missing is a straightforward way to package an application program with all its dependencies in such a way that it can be installed with reasonable effort on all common platforms.&lt;/p&gt;</description></item></channel></rss>