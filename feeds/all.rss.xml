<?xml version="1.0" encoding="utf-8"?> 
<rss version="2.0">
 <channel>
  <title>Konrad Hinsen's Blog: Konrad Hinsen's Blog</title>
  <description>Konrad Hinsen's Blog: Konrad Hinsen's Blog</description>
  <link>http://blog.khinsen.net/index.html</link>
  <lastBuildDate>Thu, 10 Jun 2021 03:31:11 UT</lastBuildDate>
  <pubDate>Thu, 10 Jun 2021 03:31:11 UT</pubDate>
  <ttl>1800</ttl>
  <item>
   <title>The dependency hubs in Open Source software</title>
   <link>http://blog.khinsen.net/posts/2021/06/10/the-dependency-hubs-in-open-source-software/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2021-06-10-the-dependency-hubs-in-open-source-software</guid>
   <pubDate>Thu, 10 Jun 2021 03:31:11 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;A few days ago, Google announced its experimental project &lt;a href="https://deps.dev/"&gt;Open Source Insights&lt;/a&gt;, which permits the exploration of the dependency graph of Open Source software. My first look at it ended with a disappointment: in its initial stage, the site considers only the package universes of Java, JavaScript, Go, and Rust. That excludes most of the software I know and use, which tends to be written mainly in C, C++, Fortran, and Python. But I do have a package manager that has all the dependency information for most of the software that I care about: &lt;a href="https://guix.gnu.org/"&gt;Guix&lt;/a&gt;. So I set out to do my own exploration of the Guix dependency graph, with a particular focus: identifying the hubs of the Open Source dependency network.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;This was also a good opportunity to test the practical utility of &lt;a href="https://github.com/khinsen/guix-gtoolkit"&gt;a new GUI for Guix&lt;/a&gt; that I have been working on recently as a side project. In fact, I added this dependency hub analysis to that GUI, so now you can access it with a simple click.&lt;/p&gt;

&lt;p&gt;Software being the complex beast that it is, I have to start by properly defining the subjects of my inquiry. What exactly do I mean by &amp;ldquo;package&amp;rdquo;, &amp;ldquo;dependency&amp;rdquo;, and &amp;ldquo;dependency hub&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;The term &lt;em&gt;package&lt;/em&gt; is widely used to describe a unit of development and distribution in software systems, but every package manager has a slightly different notion of what a package actually is. A package could be &amp;ldquo;Python&amp;rdquo;, or &amp;ldquo;Python 3.8.2&amp;rdquo;, or &amp;ldquo;Python 3.8.2 built with gcc 7.5, version X of dependency Y, &amp;hellip;&amp;rdquo;. Guix adopts the last, most fine-grained, definition. This is a good choice when you want to do reproducible software builds, but it is not very useful for analyzing dependency graphs. So I chose the level of name + version number, meaning that I consider &amp;ldquo;Python 3.8.2&amp;rdquo; a different package from &amp;ldquo;Python 3.8.1&amp;rdquo;. That&amp;rsquo;s of course debatable as well. But in Guix, it is rare to have multiple versions of a piece of software coexist at the same time. When it does happen, there is a good reason, typically a significant evolution in the software that makes different dependents prefer different versions. An example is Python 2 vs. Python 3, or the different major versions of gcc. In those cases, looking at their dependencies and dependents separately does make sense.&lt;/p&gt;

&lt;p&gt;The term &lt;em&gt;dependency&lt;/em&gt; is also widely used with different meanings. The two most common ones are &lt;em&gt;runtime dependency&lt;/em&gt; and &lt;em&gt;build dependency&lt;/em&gt;. A runtime dependency of package X is a package that must be installed on the computer to &lt;em&gt;use&lt;/em&gt; package X. In contrast, a build dependency is a package that is required in order to &lt;em&gt;build&lt;/em&gt; package X, where &lt;em&gt;building&lt;/em&gt; means anything required to turn source code into something executable. Think of it as a generalization of &lt;em&gt;compiling&lt;/em&gt;. Usually the build dependencies are roughly a superset of the runtime dependencies: there are packages you need to build package X, e.g. a compiler, but which are then no longer required for using package X. It&amp;rsquo;s the build dependencies that matter for the evolution of software systems, so that&amp;rsquo;s the definition I used in my analysis.&lt;/p&gt;

&lt;p&gt;Unfortunately, the complexity of defining dependencies doesn&amp;rsquo;t end there. Many packages have &lt;em&gt;optional&lt;/em&gt; dependencies. When they are available, some additional functionality is enabled. Do you count them or not? My pragmatic take is that I trust the Guix developers to have made good choices. So for me, a dependency is whatever it takes to build a package in Guix.&lt;/p&gt;

&lt;p&gt;This leaves the notion of a &lt;em&gt;dependency hub&lt;/em&gt; to be defined. In network science, a hub is a node that has an exceptionally high number of connections to other nodes, such that a large share of the information propagating through the network passes through the hubs. A software dependency graph differs from most networks in that its edges have a direction: A depending on B is not the same as B depending on A. This leads to several &lt;em&gt;a priori&lt;/em&gt; reasonable definitions for hubs: 1. packages that have many dependencies, 2. packages that have many dependents, and 3. packages for which the sum of dependencies plus dependents is high. Let&amp;rsquo;s immediately eliminate the last definition, as I see no interest in it. Definition 1 identifies the packages that are particularly &lt;em&gt;vulnerable&lt;/em&gt; to &lt;a href="https://hal.archives-ouvertes.fr/hal-02117588/document"&gt;software collapse&lt;/a&gt;, definition 2 the packages that can most easily &lt;em&gt;cause&lt;/em&gt; software collapse.&lt;/p&gt;

&lt;p&gt;The latter characteristic corresponds best to the capture of information flow as the defining feature of network hubs, and it also happens to be what I am most interested in. The information that flows in the network is requests for change. Nodes receive such requests from dependents, who are in fact the software&amp;rsquo;s clients or users. They typically ask for improved or extended functionality. Nodes also receive requests from dependencies, when they implement changes that break backward compatibility and then ask &lt;em&gt;their&lt;/em&gt; dependents to adapt to these changes. The nodes that potentially receive and send many requests for change are thus the nodes who have the most dependents. They are the hubs in the dependency network. Note, however, that the asymmetry in the dependency relation still matters. Nodes can ignore requests for change coming from their dependents, but they cannot ignore requests coming from their dependencies. It&amp;rsquo;s called &amp;ldquo;dependency&amp;rdquo; for a reason!&lt;/p&gt;

&lt;p&gt;At this point, I can take a break from theory and show you the results of my analysis. The top twenty hubs in the Guix dependency graph are:&lt;/p&gt;

&lt;table&gt;
 &lt;tr&gt;
  &lt;th&gt;Package&lt;/th&gt; 
  &lt;th&gt;Number of dependents&lt;/th&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;perl 5.30.2&lt;/td&gt; 
  &lt;td&gt;7964&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;pkg-config 0.29.2&lt;/td&gt; 
  &lt;td&gt;7938&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;zlib 1.2.11&lt;/td&gt; 
  &lt;td&gt;7414&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;ncurses 6.2&lt;/td&gt; 
  &lt;td&gt;7337&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libffi 3.3&lt;/td&gt; 
  &lt;td&gt;6687&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;xz 5.2.4&lt;/td&gt; 
  &lt;td&gt;6535&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;readline 8.0&lt;/td&gt; 
  &lt;td&gt;6503&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libxml2 2.9.10&lt;/td&gt; 
  &lt;td&gt;6302&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;expat 2.2.9&lt;/td&gt; 
  &lt;td&gt;6170&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libunistring 0.9.10&lt;/td&gt; 
  &lt;td&gt;6150&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;bzip2 1.0.8&lt;/td&gt; 
  &lt;td&gt;6070&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;tzdata2019c&lt;/td&gt; 
  &lt;td&gt;6068&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;Python 3.8.2&lt;/td&gt; 
  &lt;td&gt;6061&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;bash 5.0&lt;/td&gt; 
  &lt;td&gt;6042&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;gettext 0.20.1&lt;/td&gt; 
  &lt;td&gt;5768&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;m4 1.4.18&lt;/td&gt; 
  &lt;td&gt;5621&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libgpg error-1.37&lt;/td&gt; 
  &lt;td&gt;5518&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libgcrypt 1.8.5&lt;/td&gt; 
  &lt;td&gt;5514&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;libxslt 1.1.34&lt;/td&gt; 
  &lt;td&gt;5479&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;gmp 6.2.0&lt;/td&gt; 
  &lt;td&gt;5363&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;If you want more, &lt;a href="./hubs.json"&gt;here&lt;/a&gt; is the full list as a JSON file, sorted by decreasing number of dependents.&lt;/p&gt;

&lt;p&gt;If you have thought a bit about what to expect before looking at this table, you have probably included programming languages such as 
 &lt;tt&gt;perl&lt;/tt&gt; or 
 &lt;tt&gt;python&lt;/tt&gt; in this list. But perhaps you did not expect to see utilities such as 
 &lt;tt&gt;pkg-config&lt;/tt&gt; or 
 &lt;tt&gt;bzip2&lt;/tt&gt;. Remember these are &lt;em&gt;build&lt;/em&gt; dependencies. The very first step in building a package, &lt;em&gt;any&lt;/em&gt; package, is unpacking its source code. Many of the packages in my top-twenty list represent boring but essential infrastructure software. The software equivalent of the power grid and the road network: stuff that everybody just takes for granted. Such packages rarely get into the news, except when something goes seriously wrong, as in the case of the &lt;a href="https://heartbleed.com/"&gt;Hearbleed bug&lt;/a&gt; affecting OpenSSL. Which, by the way, is at position 634 in my list. It would be much higher up in a network defined by different criteria, of course. There&amp;rsquo;s more to software than build dependencies.&lt;/p&gt;

&lt;p&gt;One motivation for writing this post was pointing point out a common fallacy in reasoning about Open Source software. A popular argument is that Open Source gives you the freedom to change software to fit your needs, by creating and maintaining your own fork. Or paying someone else to do it for you, if you are not an accomplished hacker yourself. The source code is there for anyone to grab, after all, and the license allows modification and redistribution.&lt;/p&gt;

&lt;p&gt;This argument was valid in the 1980s. There were few packages, few dependencies, and a much higher percentage of computer users had programming experience. Today, you can perhaps maintain your own fork of Perl, but you cannot fork its hub position in the network, nor can you reasonably maintain forks of its 7964 dependants. If the Perl maintainers introduce a breaking change, those 7964 dependents will either adapt or disappear. Hypothetically, a large number of them could together envisage maintaining their own fork. But there are no good coordination mechanisms among developers of unrelated Open Source projects, and therefore this doesn&amp;rsquo;t happen in practice.&lt;/p&gt;

&lt;p&gt;In an &lt;a href="https://blog.khinsen.net/posts/2020/02/26/the-rise-of-community-owned-monopolies/"&gt;earlier post&lt;/a&gt;, I have written about community-owned monopolies in the Open Source universe. In that post, I wrote that for software users, there is no practical difference between Microsoft killing Windows 7 and the Python community killing Python 2, even though the former is proprietary and commercial, whereas the latter is Open Source. The reason is that both pieces of software are hubs in dependency networks. Microsoft and the Python developer community are two very different institutions, with very different goals, values, policies, legal status, etc. But that hardly matters for the average software user, whose work depends on a complex web of interacting pieces of software. At the level of that web, it&amp;rsquo;s the information flow patterns that determine evolution. Requests for change, or non-change. Average software users have practically no way to make their needs heard by the people who manage the hubs. Even the best-intentioned altruistic Open Source hub maintainer cannot possibly keep every user&amp;rsquo;s interests in mind, because there is no way to even be aware of them. A web of software is a very different beast than a single project. &lt;a href="http://robotics.cs.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf"&gt;More is different.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the almost 40 years since the beginnings of the Open Source movement, the mode of governance of Open Source projects has evolved significantly. Most importantly, all the people involved have realized that governance matters and must be consciously organized, rather than evolve through cumulative random accidents of history, which almost inevitably leads to a &lt;a href="https://en.wikipedia.org/wiki/The_Tyranny_of_Structurelessness"&gt;tyranny of structurelessness&lt;/a&gt; in the long run. Now we must develop an awareness of similar issues at the level of the &lt;em&gt;web&lt;/em&gt; of Open Source projects, followed by the development and implementation of better information flow and decision structures.&lt;/p&gt;

&lt;p&gt;I will conclude this post with a technical remark. I did my dependency hub analysis using a relatively new tool in the software world, called the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt;, to which I added an &lt;a href="https://github.com/khinsen/guix-gtoolkit"&gt;interface to Guix&lt;/a&gt;. This toolbox significantly lowers the cost of developing new tools. In the screenshot below, you see on the left the user interface of my analysis. It&amp;rsquo;s an additional view on the Guix package catalog, complementing various other views that are already in place. On the right, you see the complete code for this analysis, including the user interface (which also gives access to the list of dependents, not just the number). In contrast to traditional scripts, there is no overhead for reading data or writing out the results. My code works on data structures that are already in place. What is not obvious from the screenshot is that you get the right-hand panel via alt-click from the left-hand one, meaning that users of my little analysis tool always have direct access to the code. It isn&amp;rsquo;t obvious either that modifying the code on the right will immediately update the view on the left, making development highly interactive. If you think notebooks are great, try Glamorous Toolkit. But be warned that you might then realize that notebooks are no longer the state of the art.&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="./guix-gtoolkit-dependency-hubs.png" alt="" width="100%" /&gt; 
 &lt;p class="caption"&gt;&lt;/p&gt;&lt;/div&gt;</description></item>
  <item>
   <title>The structure and interpretation of scientific models, part 2</title>
   <link>http://blog.khinsen.net/posts/2021/01/08/the-structure-and-interpretation-of-scientific-models-part-2/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2021-01-08-the-structure-and-interpretation-of-scientific-models-part-2</guid>
   <pubDate>Fri, 08 Jan 2021 13:07:26 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;In &lt;a href="https://blog.khinsen.net/posts/2020/12/10/the-structure-and-interpretation-of-scientific-models/"&gt;my last post&lt;/a&gt;, I have discussed the two main types of scientific models: empirical models, also called descriptive models, and explanatory models. I have also emphasized the crucial role of equations and specifications in the formulation of explanatory models. But my description of scientific models in that post left aside a very important aspect: on a more fundamental level, all models are stories.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;To illustrate my point, I will take up my running example from part 1: celestial mechanics. Newton&amp;rsquo;s model for our solar system is, as I said, composed of several equations, the most famous of which, &lt;em&gt;F&lt;/em&gt; = &lt;em&gt;m&lt;/em&gt; ⋅ &lt;em&gt;a&lt;/em&gt;, many readers will probably remember from a high-school physics class. But that equation means nothing on its own. It just says that there are three quantities, one of which being the product of the other two.&lt;/p&gt;

&lt;p&gt;The minimal story required to make sense of this equation provides a definition of the three quantities involved. For acceleration (the &lt;em&gt;a&lt;/em&gt;), this may look superficially simple: it&amp;rsquo;s the second derivative of an object&amp;rsquo;s position in time. The concepts of position and time are part of our everyday intuition, so that&amp;rsquo;s the easy part. Velocity is an intuitive everyday concept as well, but its precise relation to position as a time derivative is not. For acceleration, nothing short of calculus will do. In fact, Newton invented calculus along with his physical theory! Defining mass (the &lt;em&gt;m&lt;/em&gt;) and force (the &lt;em&gt;F&lt;/em&gt;) is not a trivial task either. Both concepts are rooted in our everyday intuition about the world, but their role in Newton&amp;rsquo;s law of motion requires a much more precise understanding. If you have doubts about this, try explaining the difference between &lt;em&gt;mass&lt;/em&gt; and &lt;em&gt;weight&lt;/em&gt; to someone who doesn&amp;rsquo;t have a scientific education.&lt;/p&gt;

&lt;p&gt;From this big-picture point of view, equations such as &lt;em&gt;F&lt;/em&gt; = &lt;em&gt;m&lt;/em&gt; ⋅ &lt;em&gt;a&lt;/em&gt; are tiny pieces of our scientific models. They are the tips of icebergs whose massive underwater parts are the stories defining the underlying concepts and linking them to our intuition about the world, often through multiple and increasingly abstract layers. We tend to forget about these stories, because once we have understood them well enough, what we actually work with are the equations. But this works only for the well-established models whose stories are now found in textbooks. New research continuously introduces new models, often as small variants or extensions of existing ones. Their stories are told in scientific publications.&lt;/p&gt;

&lt;p&gt;Historically, &lt;a href="https://en.wikipedia.org/wiki/History_of_mathematical_notation"&gt;mathematical notation&lt;/a&gt; was introduced as a convenient shorthand for use in plain-language stories. The lengthy phrase &amp;ldquo;force equals mass times acceleration&amp;rdquo; thus became &lt;em&gt;F&lt;/em&gt; = &lt;em&gt;m&lt;/em&gt; ⋅ &lt;em&gt;a&lt;/em&gt;. The transition to symbolic equations encouraged the development of formal methods in mathematics, starting with algebraic transformations of simple equations. This approach was so successful that equations became the main focus of interest in science. Later, other formal representations were added for the non-numerical aspects of models, graphs being the prime example. The most recent addition to the collection of formal notations for scientific models is software. Today, scientists spend most of their time working with the formalized parts of scientific models, such as equations or algorithms, to the point of neglecting the stories that give them meaning.&lt;/p&gt;

&lt;p&gt;What happens when people use the equations of scientific models without a proper understanding of their stories is nicely illustrated by the joke about the physics student who combines Einstein&amp;rsquo;s &lt;em&gt;E&lt;/em&gt; = &lt;em&gt;m&lt;/em&gt; ⋅ &lt;em&gt;c²&lt;/em&gt; with Pythagoras&amp;rsquo; &lt;em&gt;a²&lt;/em&gt; + &lt;em&gt;b²&lt;/em&gt; = &lt;em&gt;c²&lt;/em&gt; to deduce &lt;em&gt;E&lt;/em&gt; = &lt;em&gt;m&lt;/em&gt; ⋅ (&lt;em&gt;a²&lt;/em&gt; + &lt;em&gt;b²&lt;/em&gt;). It works as a joke among physicists because in their community, everybody knows the two inputs and the contexts from which they are taken. For other people, there is nothing funny about this reasoning, and it can even look convincing. Such superficial use of scientific models without understanding their context is actually quite common in today&amp;rsquo;s research: the inappropriate use of statistical inference methods is a major cause of the &lt;a href="https://en.wikipedia.org/wiki/Replication_crisis"&gt;reproducibility crisis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Computing technology has played a big role in alienating scientists from their models. Most obviously, computers have made it possible to apply scientific models and methods as black-box tools: in an automated fashion, without understanding them. But the attitudes of the software industry, whose development tools computational science has inherited, have also contributed to this tendency. The focus of the software industry is on professional developers making tools for others that almost magically solve some of their problems. Users then get a manual, or hands-on training, for learning how to use the tool, but the inner workings of the tool are something they shouldn&amp;rsquo;t even have to think about. A good tool is one that minimizes learning requirements. Applied to science, this implies that users shouldn&amp;rsquo;t have to know the stories behind the models. Everyone with a dataset should be able to do statistical inference with a few mouse clicks and get a nice visualization. But without the stories, we can easily draw wrong conclusions from nice graphics.&lt;/p&gt;

&lt;p&gt;After a long period of separation of tools and stories, computational notebooks are now bringing some of the stories back. The enthusiastic adoption of notebooks by computational scientists is perhaps the best evidence for the importance of stories in science. But today&amp;rsquo;s notebooks capture only the surface stories of a research project. It&amp;rsquo;s tips of icebergs again. The typical notebook makes use of a large number of code libraries that are based on non-trivial scientific models, but the reader of the notebook remains completely unaware of them. Ideally, these models, with their stories, should be only a few clicks away.&lt;/p&gt;

&lt;p&gt;So what would an electronic representation of scientific models look like, ideally? It&amp;rsquo;s a collection of cross-referencing stories. In the celestial mechanics example, there&amp;rsquo;s a story about positions, velocities, and accelerations, which refers to a story about time and to a story about derivatives. There is another story that explains mass. The story of Newton&amp;rsquo;s law of motion, which also introduces the concept of force, can then refer to these more fundamental stories. If this description reminds you of Wikipedia, or in fact of any Wiki, you are right. Wikis are also collections of cross-referencing stories. What is missing in Wikis is a machine-readable version of the formalized parts of our models. Which, as I explained in &lt;a href="https://blog.khinsen.net/posts/2020/12/10/the-structure-and-interpretation-of-scientific-models/"&gt;part 1&lt;/a&gt;, needs to allow at least equations, specifications, and algorithms for its ingredients. Another feature that is missing in today&amp;rsquo;s Wikis, although some people are working on it, is the possibility to integrate computational tools in the form of code snippets. Their role would be to give access to visualizations, simulations, and other exploration tools.&lt;/p&gt;

&lt;p&gt;My own experiments in this domain are &lt;a href="https://github.com/khinsen/leibniz/"&gt;Leibniz&lt;/a&gt;, a digital scientific notation for embedding machine-readable formal models into human-readable stories, and the &lt;a href="https://github.com/activepapers/activepapers-pharo"&gt;Pharo edition of ActivePapers&lt;/a&gt;, which integrates datasets and computational tools into a Wiki-like collection of stories. Both ingredients require more work, and then need to be combined. There remains a lot of work to do.&lt;/p&gt;</description></item>
  <item>
   <title>The structure and interpretation of scientific models</title>
   <link>http://blog.khinsen.net/posts/2020/12/10/the-structure-and-interpretation-of-scientific-models/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-12-10-the-structure-and-interpretation-of-scientific-models</guid>
   <pubDate>Thu, 10 Dec 2020 08:36:23 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;It is often said that science rests on two pillars, experiment and theory. Which has lead some to propose &lt;a href="https://physicsworld.com/a/the-third-pillar-of-science/"&gt;one&lt;/a&gt; or &lt;a href="https://www.hpcwire.com/2019/04/18/is-data-science-the-fourth-pillar-of-the-scientific-method/"&gt;two&lt;/a&gt; additional pillars for the computing age: simulation and data analysis. However, the &lt;em&gt;real&lt;/em&gt; two pillars of science are observations and models. Observations are the input to science, in the form of numerous but incomplete and imperfect views on reality. Models are the inner state of science. They represent our current understanding of reality, which is necessarily incomplete and imperfect, but understandable and applicable. Simulation and data analysis are tools for interfacing and thus comparing observations and models. They don&amp;rsquo;t add new pillars, but transforms both of them. In the following, I will look at how computing is transforming scientific models.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;h2 id="empirical-models"&gt;Empirical models&lt;/h2&gt;

&lt;p&gt;The first type of scientific model that people construct when figuring out a new phenomenon is the &lt;em&gt;empirical&lt;/em&gt; or &lt;em&gt;descriptive&lt;/em&gt; model. Its role is to capture observed regularities, and to separate them from noise, the latter being small deviations from the regular behavior that are, at least provisionally, attributed to imprecisions in the observations, or to perturbations to be left for later study. Whenever you fit a straight line to a set of points, for example, you are constructing an empirical model that captures the linear relation between two observables. Empirical models almost always have parameters that must be fitted to observations. Once the parameters have been fitted, the model can be used to &lt;em&gt;predict&lt;/em&gt; future observations, which is a great way to test its generality. Usually, empirical models are constructed from generic building blocks: polynomials and sine waves for constructing mathematical functions, circles, spheres, and triangles for geometric figures, etc.&lt;/p&gt;

&lt;p&gt;The use of empirical models goes back a few thousand years. As I have described in &lt;a href="https://blog.khinsen.net/posts/2017/12/19/data-science-in-ancient-greece/"&gt;an earlier post&lt;/a&gt;, the astronomers of antiquity who constructed a model for the observed motion of the Sun and the planets used the same principles that we still use today. Their generic building blocks were circles, combined in the form of epicycles. The very latest variant of empirical models is machine learning models, where the generic building blocks are, for example, artificial neurons. Impressive success stories of machine learning models have led some enthusiasts to proclaim &lt;a href="https://www.wired.com/2008/06/pb-theory/"&gt;the end of theory&lt;/a&gt;, but I hope to be able to convince you in the following that empirical models of any kind are the beginning, not the end, of constructing scientific theories.&lt;/p&gt;

&lt;p&gt;The main problem with empirical models is that they are not that powerful. They can predict future observations from past observations, but that&amp;rsquo;s all. In particular, they cannot answer what-if questions, i.e. make predictions for systems that have never been observed in the past. The epicycles of Ptolemy&amp;rsquo;s model describing the motion celestial bodies cannot answer the question how the orbit of Mars would be changed by the impact of a huge asteroid, for example. Today&amp;rsquo;s machine learning models are no better. Their latest major success story as I am writing this is the &lt;a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"&gt;AlphaFold predicting protein structures from their sequences&lt;/a&gt;. This is indeed a huge step forward, as it opens the door to completely new ways of studying the folding mechanisms of proteins. It is also likely to become a powerful tool in structural biology, if it is actually made available to biologists. But it is not, as DeepMind&amp;rsquo;s blog post claims, &amp;ldquo;a solution to a 50-year-old grand challenge in biology&amp;rdquo;. We still do not know what the fundamental mechanisms of protein folding are, nor how they play together for each specific protein structure. And that means that we cannot answer what-if questions such as &amp;ldquo;How do changes in a protein&amp;rsquo;s environment influence its fold?&amp;rdquo;&lt;/p&gt;

&lt;h2 id="explanatory-models"&gt;Explanatory models&lt;/h2&gt;

&lt;p&gt;The really big success stories of science are models of a very different kind. &lt;em&gt;Explanatory&lt;/em&gt; models describe the underlying mechanisms that determine the values of observed quantities, rather than extrapolating the quantities themselves. They describe the systems being studied at a more fundamental level, allowing for a wide range of generalizations.&lt;/p&gt;

&lt;p&gt;A simple explanatory model is given by the &lt;a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations"&gt;Lotka-Volterra equations&lt;/a&gt;, also called predator-prey equations. This is a model for the time evolution of the populations of two species in a preditor-prey relation. An example is shown in this plot (Lamiot, CC BY-SA 4.0 &lt;a href="https://creativecommons.org/licenses/by-sa/4.0"&gt;https://creativecommons.org/licenses/by-sa/4.0&lt;/a&gt;, via Wikimedia Commons):&lt;/p&gt;

&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/5/5b/Milliers_fourrures_vendues_en_environ_90_ans_odum_1953_en.jpg" alt="predator-prey" width="600" /&gt;&lt;/p&gt;

&lt;p&gt;An empirical model would capture the oscillations of the two curves and their correlations, for example by describing the populations as superpositions of sine waves. The Lotka-Volterra equations instead describe the interactions between the population numbers: predators and prey are born and die, but in addition predators eat prey, which reduces the number of prey in proportion to the number of predators, and contributes to a future increase in the number of predators because they can better feed their young. With that type of description, one can ask what-if questions: What if hunters shoot lots of predators? What if prey are hit by a famine, i.e. a decrease in their own source of food? In fact, the significant deviations from regular periodic change in the above plot suggests that such &amp;ldquo;outside&amp;rdquo; events are quite important in practice.&lt;/p&gt;

&lt;p&gt;Back to celestial mechanics. The decisive step towards an explanatory model was made by Isaac Newton, after two important preparatory steps by Copernicus and Kepler, who put the Sun at the center, removing the need for epicycles, and described the planets&amp;rsquo; orbits more accurately as ellipses. Newton&amp;rsquo;s laws of motion and gravitation fully explained these elliptical orbits and improved on them. More importantly, they showed that the fundamental laws of physics are the same on Earth and in space, a fact that may seem obvious to us today but wasn&amp;rsquo;t in the 17th century. Finally, Newton&amp;rsquo;s laws have permitted the elaboration of a rich theory, today called &amp;ldquo;classical mechanics&amp;rdquo;, that provides several alternative forms of the basic equations (in particular &lt;a href="https://en.wikipedia.org/wiki/Lagrangian_mechanics"&gt;Lagrangian&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Hamiltonian_mechanics"&gt;Hamiltonian&lt;/a&gt; mechanics), plus derived principles such as the conservation of energy. As for what-if questions, Newton&amp;rsquo;s laws have made it possible to send artefacts to the moon and to the other planets of the solar system, something which would have been unimaginable on the basis of Ptolemy&amp;rsquo;s epicycles.&lt;/p&gt;

&lt;p&gt;So far I have cited two explanatory models that take the form of differential equations, but that is not a requirement. An example from the digital age is given by &lt;a href="https://en.wikipedia.org/wiki/Agent-based_model"&gt;agent-based models&lt;/a&gt;. There is, however, a formal characteristic that is shared by all explanatory models that I know, and that distinguishes them from empirical models: they take the form of specifications.&lt;/p&gt;

&lt;h2 id="specifications-and-equations-vs-algorithms-and-functions"&gt;Specifications and equations vs. algorithms and functions&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s look at a simple problem for illustration: sorting a list of numbers (or anything else with a well-defined order). I have a list &lt;code&gt;L&lt;/code&gt;, with elements &lt;code&gt;L[i]&lt;/code&gt;, &lt;code&gt;i=1..N&lt;/code&gt; where &lt;code&gt;N&lt;/code&gt; is the length of the list &lt;code&gt;L&lt;/code&gt;. What I want is a sorted version which I will call &lt;code&gt;sorted(L)&lt;/code&gt;. The &lt;em&gt;specification&lt;/em&gt; for &lt;code&gt;sorted(L)&lt;/code&gt; is quite simple:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;&lt;code&gt;sorted(L)&lt;/code&gt; is a list of length &lt;code&gt;N&lt;/code&gt;.&lt;/li&gt;
 &lt;li&gt;For all elements of &lt;code&gt;L&lt;/code&gt;, their multiplicities in &lt;code&gt;L&lt;/code&gt; and &lt;code&gt;sorted(L)&lt;/code&gt; are the same.&lt;/li&gt;
 &lt;li&gt;For all &lt;code&gt;i=1..N-1&lt;/code&gt;, &lt;code&gt;sorted(L)[i] ≤ sorted(L)[i+1]&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Less formally: &lt;code&gt;sorted(L)&lt;/code&gt; is a list with the same elements as &lt;code&gt;L&lt;/code&gt;, but in the right order.&lt;/p&gt;

&lt;p&gt;This specification of &lt;code&gt;sorted(L)&lt;/code&gt; is complete in that there is one unique list that satisfies it. However, it does not provide much help for actually constructing that list. That is what a sorting &lt;em&gt;algorithm&lt;/em&gt; provides. There are many known algorithms for sorting, and you can learn about them from &lt;a href="https://en.wikipedia.org/wiki/Sorting_algorithm"&gt;Wikipedia&lt;/a&gt;, for example. What matters for my point is that (1) given the specification, it is not a trivial task to construct an algorithm, (2) given a few algorithms, it is not a trivial task to write down a common specification that they satisfy (assuming of course that it exists). And that means that specifications and algorithms provide complementary pieces of knowledge about the problem.&lt;/p&gt;

&lt;p&gt;In terms of levels of abstraction, specifications are more abstract than algorithms, which in turn are more abstract than implementations. In the example of sorting, the move from specification to algorithm requires technical details to be filled in, in particular the choice of a sorting algorithm. Moving on from the algorithm to a concrete implementation involves even more technical details: the choice of a programming language, the data structures for the list and its elements, etc.&lt;/p&gt;

&lt;p&gt;In the universe of continuous mathematics, the relation between equations (e.g. differential equations) and the functions that satisfy them is exactly the same as the relation between specifications and algorithms in computation. Newton&amp;rsquo;s equations can thus be seen as a specification for the elliptical orbits that Kepler had described a bit earlier. Like in the case of sorting, it is not a trivial task to derive Kepler&amp;rsquo;s elliptical orbits from Newton&amp;rsquo;s equations, nor is it a trivial task to write down Newton&amp;rsquo;s equations as the common specification of all the (approximatively) elliptical orbits in the solar system. The two views of the problem are complementary, one being closer to the observations, the other providing more insight.&lt;/p&gt;

&lt;p&gt;One reason why specifications and equations are more powerful is that they are modular. Two specifications combined make up another, more detailed, specification. Two equations make up a system of equations. An example is given my Newton&amp;rsquo;s very general law of motion, which is extended by his law of gravitation to make a model for celestial mechanics. The same law of motion can be combined with different laws defining forces for different situations, for example the motion of an airplane. In contrast, there is no way to deduce anything about airplanes from Kepler&amp;rsquo;s elliptical planetary orbits. Functions and algorithms satisfy &lt;em&gt;complete&lt;/em&gt; specifications, and conserve little information about the &lt;em&gt;components&lt;/em&gt; from which this complete specification was constructed.&lt;/p&gt;

&lt;h2 id="a-challenge-for-computational-science"&gt;A challenge for computational science&lt;/h2&gt;

&lt;p&gt;Computational science initially used computers as a tool for applying structurally simple but laborious computational algorithms. The focus was on efficient implementations of known algorithms, later also on developing efficient algorithms for solving well-understood equations. The steps from specification to algorithm to implementation were done by hand, with little use of computational tools.&lt;/p&gt;

&lt;p&gt;That was 60 years ago. Today, we have computational models that are completely unrelated to the mathematical models that go back to the 19th century. And when we do use the foundational mathematical models of physics and chemistry, we combine them with concrete systems specifications whose size and complexity requires the use of computational tools. And yet, we still focus on implementations and to a lesser degree on algorithms, neglecting specifications almost completely. For many routinely used computational tools, the implementation is the only publicly accessible artefact. The algorithms they implement are often undocumented or not referenced, and the specifications from which the algorithms were derived are not written down at all. Given how crucial the specification level of scientific models has been in the past, we can expect to gain a lot by introducing it into computational science as well.&lt;/p&gt;

&lt;p&gt;To do so, we first need to develop a new appreciation for &lt;a href="https://f1000research.com/articles/3-101/v2"&gt;scientific models as distinct from the computational tools that implement them&lt;/a&gt;. We then need to think about how we can actually &lt;a href="https://peerj.com/articles/cs-158/"&gt;introduce specification-based models into the workflows of computational science&lt;/a&gt;. This requires designing computational tools that let us move freely between the three levels of specification, algorithm, and implementation. This is in my opinion the main challenge for computational science in the 21st century.&lt;/p&gt;

&lt;h2 id="finally"&gt;Finally&amp;hellip;&lt;/h2&gt;

&lt;p&gt;Some readers may have recognized that the title of this post is a reference to two books, &lt;a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html"&gt;Structure and Interpretation of Computer Programs&lt;/a&gt; (with a &lt;a href="https://sarabander.github.io/sicp/html/index.xhtml"&gt;nice though inofficial online version&lt;/a&gt;) and &lt;a href="https://mitpress.mit.edu/books/structure-and-interpretation-classical-mechanics"&gt;Structure and Interpretation of Classical Mechanics&lt;/a&gt; (also &lt;a href="https://tgvaughan.github.io/sicm/toc.html"&gt;online&lt;/a&gt;). The second one is actually somewhat related to the topic of this post: it is a textbook on classical mechanics that uses computational techniques for clarity of exposition. More importantly, both books focus on inducing a deep understanding of their topics, rather than on teaching superficial technical details. This humble blog post cannot pretend to reach that level, of course, but its goal is to spark developments that will culminate in textbooks of the same quality as its two inspirations.&lt;/p&gt;</description></item>
  <item>
   <title>Some comments on AlphaFold</title>
   <link>http://blog.khinsen.net/posts/2020/12/02/some-comments-on-alphafold/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-12-02-some-comments-on-alphafold</guid>
   <pubDate>Wed, 02 Dec 2020 20:27:36 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Many people are asking for my opinion on the recent &lt;a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"&gt;impressive success of AlphaFold at CASP14&lt;/a&gt;, perhaps incorrectly assuming that I am an expert on protein folding. I have actually never done any research in that field, but it&amp;rsquo;s close enough to my research interests that I have closely followed the progress that has been made over the years. Rather than reply to everyone individually, here is a public version of my comments. They are based on the limited information on AlphaFold that is available today. I may come back to this post later and expand it.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;First of all, the GDT scores obtained by AlphaFold are impressive, which is of course the reason for all the buzz at the moment. The GDT score measures how close a predicted structure is to the experimentally determined one. It is defined on a scale from 0 to 100 and can roughly be interpreted as the percentage of amino acid residues that were placed correctly. For about 2/3 of the proteins in this year&amp;rsquo;s competition, AlphaFold achieved a GDT score in the 90s, whereas in the not so distant past, a score in the 70s was already considered very good. Which exact techniques were used to obtain the predicted structures is not something I can comment on: as far as I know, no technical details have been made public so far. Nor is AlphaFold a publicly available program or service that scientists could explore or apply to their own work. So all we know for now is that DeepMind, the company behind AlphaFold, has figured out a way to obtain good scores at CASP14. In the following I will assume that this is not just good luck, and that the method is applicable to a much larger class of proteins than the CASP candidates.&lt;/p&gt;

&lt;p&gt;The scores obtained by AlphaFold are clearly a sign of significant progress. But does it mean that we have &amp;ldquo;a solution to a 50-year-old grand challenge in biology&amp;rdquo;, as the press release claims? That depends on what exactly one considers that challenge to be.&lt;/p&gt;

&lt;p&gt;If the challenge of protein folding is taken to be a purely pragmatic one, i.e. being able to predict structure from sequence, then AlphaFold is a candidate for a solution. How much of a solution will depend on further evaluations that remain to be done, on a larger range of proteins. CASP is limited to proteins for which experimental structures are (just) available. But some proteins resist experimental structure determination, for example because they have no well-defined structure at all. A robust structure prediction tool would have to identify such cases, rather than predict bogus structures. Allosteric proteins, which are proteins that can take more than one stable structure, provide another set of interesting test cases. A third case of interest is protein pairs that differ minimally in their sequence but importantly in structure. The goal of evaluating the robustness of a tool is to understand how it behaves at best, at worst, and for important edge cases, such that its users can judge the trustworthiness of its results.&lt;/p&gt;

&lt;p&gt;For many scientists, including myself, having a black-box structure prediction tool is not sufficient to declare the protein folding problem solved. A solution requires an in-depth understanding of the mechanisms that determine protein structure. Whether or not AlphaFold can contribute to identifying these mechanisms is a question that scientists can only start to examine, and only if AlphaFold becomes sufficiently accessible and inspectable for critical examination by outside experts. I hope this will happen, and in fact I am optimistic that it will happen: the problem is important enough to deserve a serious effort by everyone involved. AlphaFold is not the end of the quest for a solution of the protein folding problem, but it could well turn out to be the beginning of a new chapter in the story.&lt;/p&gt;</description></item>
  <item>
   <title>The four possibilities of reproducible scientific computations</title>
   <link>http://blog.khinsen.net/posts/2020/11/20/the-four-possibilities-of-reproducible-scientific-computations/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-11-20-the-four-possibilities-of-reproducible-scientific-computations</guid>
   <pubDate>Fri, 20 Nov 2020 16:57:22 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Computational reproducibility has become a topic of much debate in recent years. Often that debate is fueled by misunderstandings between scientists from different disciplines, each having different needs and priorities. Moreover, the debate is often framed in terms of specific tools and techniques, in spite of the fact that tools and techniques in computing are often short-lived. In the following, I propose to approach the question from the scientists&amp;rsquo; point of view rather than from the engineering point of view. My hope is that this point of view will lead to a more constructive discussion, and ultimately to better computational reproducibility.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The format of my proposal is inspired by the well-known &lt;a href="https://www.gnu.org/philosophy/free-sw.en.html"&gt;&amp;ldquo;four freedoms&amp;rdquo; that define Free Software&lt;/a&gt;. The focus of reproducibility is not on legal aspects, but on technical ones, and therefore my proposal is framed in terms of &lt;em&gt;possibilities&lt;/em&gt; rather than freedoms.&lt;/p&gt;

&lt;h2 id="the-four-essential-possibilities"&gt;The four essential possibilities&lt;/h2&gt;

&lt;p&gt;A computation is reproducible if it offers the four essential possibilities:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;The possibility to inspect all the input data and all the source code that can possibly have an impact on the results.&lt;/li&gt;
 &lt;li&gt;The possibility to run the code on a suitable computer of one&amp;rsquo;s own choice in order to verify that it indeed produces the claimed results.&lt;/li&gt;
 &lt;li&gt;The possibility to explore the behavior of the code, by inspecting intermediate results, by running the code with small modifications, or by subjecting it to code analysis tools.&lt;/li&gt;
 &lt;li&gt;The possibility to verify that published executable versions of the computation, proposed as binary files or as services, do indeed correspond to the available source code.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;All of these possibilities come in degrees, measured in terms of the effort required to actually do what is supposed to be possible. For example, inspecting the source code of a computation is much easier for a notebook containing the top-level code, with links to repositories of all dependencies, than for a script available from the authors on request. Moreover, the degree to which each possibility exists can strongly vary over time. A piece of software made available on an institutional Web site is easily inspectable while that site exists, but inspectability drops to zero if the Web site closes down.&lt;/p&gt;

&lt;p&gt;The reproducibility profile of a computation therefore consists of four time series, each representing one of the possibilities expressed on a suitable scale with its estimated time evolution. The minimum requirement for the label &amp;ldquo;reproducible&amp;rdquo; is a non-zero degree for all four possibilities for an estimated duration of a few months, the time it takes for new work to be carefully examined by peers.&lt;/p&gt;

&lt;h2 id="rationale"&gt;Rationale&lt;/h2&gt;

&lt;p&gt;The possibility to inspect all the source code is required to allow independent verification of the software&amp;rsquo;s correctness, and in particular to check that it does what its documentation claims it does.&lt;/p&gt;

&lt;p&gt;The possibility to run the code is required to allow independent verification of the results.&lt;/p&gt;

&lt;p&gt;The possibility to explore the behavior of the code is a &lt;em&gt;de facto&lt;/em&gt; requirement to fully accomplish the goals of the first possibility. For all but the most trivial pieces of software, inspection of the source code is not enough to convince oneself that it does what it is claimed to do.&lt;/p&gt;

&lt;p&gt;The possibility of verifying the correspondence of source code and executable versions is motivated by the complexity of today&amp;rsquo;s software build procedures. Mistakes can as easily be introduced in the build process as in the source code itself. This point is well made by Ken Thompson&amp;rsquo;s Turing Award speech &lt;a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf"&gt;Reflections on Trusting Trust&lt;/a&gt;, if you replace mischief by mistake in his arguments.&lt;/p&gt;

&lt;h2 id="discussion-in-the-context-of-the-state-of-the-art"&gt;Discussion in the context of the state of the art&lt;/h2&gt;

&lt;p&gt;The possibility to inspect all the source code is a criterion that is in principle widely accepted, although many people fail to realize its wide-ranging consequences. &amp;ldquo;All the source code that can possibly have an impact on the results&amp;rdquo; actually means a &lt;em&gt;lot&lt;/em&gt; of software. It includes many libraries, but also language implementations such as compilers and interpreters. Moreover, inspecting a dependency first of all requires precisely identifying it. This remains a difficult task today, and therefore most published computations today do not offer the first essential possibility, no matter how much effort a reader is willing to invest.&lt;/p&gt;

&lt;p&gt;It is tempting to introduce another degree of compliance by requiring that only the most relevant parts of the total source code be inspectable. However, that defies the whole purpose of independent verification. Who decides what it relevant? Usually the author of the computation. But if the code declared to be irrelevant by the author is not inspectable, we have to take the author&amp;rsquo;s word for its irrelevance.&lt;/p&gt;

&lt;p&gt;The possibility to run the code is also a widely accepted criterion, though not everyone accepts the additional requirement of executability &amp;ldquo;on a suitable computer of one&amp;rsquo;s own choice&amp;rdquo;. Software made available as a service (e.g. in the cloud) is considered sufficient for reproducibility by some researchers. Executability is much more susceptible to decay over time than inspectability of the source code, and this is one of the main topics of debate today. Is long-term reproducibility needed? Is it achievable? The answers vary across disciplines. There is unfortunately a strong tendency to auto-censoring here: many scientists believe that long-term reproducibility is not realistic and &lt;em&gt;therefore&lt;/em&gt; should not be asked for. This is definitely not true and it is better to frame the question as a trade-off: what is a reasonable price to pay for long-term reproducibility, in a given discipline?&lt;/p&gt;

&lt;p&gt;The possibility to explore the behavior of the code is rarely mentioned in discussions of reproducibility. And in fact, exploring the behavior of non-trivial code written by someone else is such a difficult task that many scientists prefer not to require anyone to do it. I am not aware of any scientific journal that expects reviewers of submitted work to check the code of any computation for correctness or at least plausible correctness, which in practice requires examining its behavior. And yet, the scientific method requires &lt;em&gt;everything&lt;/em&gt; to be inquirable. It may not be a realistic expectation today, but it should at least be a goal for the future.&lt;/p&gt;

&lt;p&gt;Since code explorability is rarely required or even discussed, there is no clear profile of practical implementations either. It&amp;rsquo;s a criterion that requires expert judgement, the expert being a fellow researcher from the same discipline as the author of a computation. It is the software analog of a &amp;ldquo;well-written&amp;rdquo; paper, which is a paper that a reader can easily &amp;ldquo;get into&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The possibility of verifying the correspondence of source code and executable versions is also rarely mentioned. It is also the least fundamental one of the four essential possibilities, because in principle it can be abandoned if a computation is fully reproducible from source code. In practice, however, that is rarely a realistic option. The size and complexity of today&amp;rsquo;s software assemblies makes it impractical to re-build everything from source code, a process that can take many hours. Nearly all software assemblies we run in scientific computing contain some components obtained in pre-built binary form. While it is perfectly OK for most people, most of the time, to use such pre-built binaries, inquirability requires the possibility to check that these binaries really correspond to the source code that the authors of a computation claim to have used. This is a possibility where a low degree can be quite acceptable.&lt;/p&gt;

&lt;h2 id="please-comment"&gt;Please comment!&lt;/h2&gt;

&lt;p&gt;As I said, the goal of this blog post is to start a discussion. Your comments are valuable, possibly more so than the post itself. How important are the four possibilities in your own discipline? How well can they be realized within the current state of the art? Are there additional possibilities you consider important for reproducibility?&lt;/p&gt;

&lt;p&gt;Check also the comments on Twitter by exploring the replies to &lt;a href="https://twitter.com/khinsen/status/1329832546474061824"&gt;this tweet&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="notes-added-after-publication"&gt;Notes added after publication&lt;/h2&gt;

&lt;h3 id="20201122"&gt;2020&amp;ndash;11&amp;ndash;22&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jermdemo/status/1329866889867059200"&gt;Jeremy Leipzig&lt;/a&gt; points out  &lt;a href="https://icerm.brown.edu/topical_workshops/tw12-5-rcem/icerm_report.pdf"&gt;the 2012 ICERM workshop document&lt;/a&gt;, whose appendix A discusses several levels of reproducibility. Its last level (&amp;ldquo;open or reproducible research&amp;rdquo;) covers in a general way the four possibilities I discuss above. The lower levels describe research output in which at least one of the four possibilities is not provided.&lt;/p&gt;

&lt;h3 id="20201123"&gt;2020&amp;ndash;11&amp;ndash;23&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/ivotron/status/1329873600472621057"&gt;Ivo Jimenez&lt;/a&gt; refers to &lt;a href="https://www.niso.org/standards-committees/reproducibility-badging"&gt;ongoing work&lt;/a&gt; at NISO (National Information Standards Organization, USA) to define recommended practices, and &lt;a href="https://twitter.com/npch/status/1330453823568171008"&gt;Neil Chue Hong&lt;/a&gt; says they will be out soon.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/ivotron/status/1330612647763570690"&gt;Ivo Jimenez&lt;/a&gt; also mentions an interesting collection of &lt;a href="https://sysartifacts.github.io/"&gt;resources on artifact evaluation for computer systems conferences&lt;/a&gt;.&lt;/p&gt;</description></item>
  <item>
   <title>The landscapes of digital scientific knowledge</title>
   <link>http://blog.khinsen.net/posts/2020/07/08/the-landscapes-of-digital-scientific-knowledge/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-07-08-the-landscapes-of-digital-scientific-knowledge</guid>
   <pubDate>Wed, 08 Jul 2020 14:09:46 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Over the last years, an interesting metaphor for information and knowledge curation is beginning to take root. It compares knowledge to a landscape in which it identifies in particular two key elements: streams and gardens. The first use of this metaphor that I am aware of is &lt;a href="https://hapgood.us/2015/10/17/the-garden-and-the-stream-a-technopastoral/"&gt;this essay by Mike Caulfield&lt;/a&gt;, which I strongly recommend you to read first. In the following, I will apply this metaphor specifically to scientific knowledge and its possible evolution in the digital era.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;In the landscape metaphor, streams are timelines of information parcels. News, RSS feeds, Twitter, Facebook, but also scientific journals, are stream media. Gardens are continuously evolving information assemblies that are actively curated by their authors. Encyclopedias and dictionaries are perhaps the oldest examples. In the printed paper era, updating an information collection was expensive because everything had to be reprinted and redistributed. As a consequence, garden-type resources were rare. Digital gardens have no such overhead, and almost no cost other than the work of their curators. More and more people are setting up their own digital gardens as an alternative or complement to the personal stream, better known as a blog. Click &lt;a href="https://joelhooks.com/digital-garden"&gt;here&lt;/a&gt;, &lt;a href="https://tomcritchlow.com/blogchains/digital-gardens/"&gt;here&lt;/a&gt;, and &lt;a href="https://www.christopherbiscardi.com/what-is-a-digital-garden"&gt;here&lt;/a&gt; to see a few examples of personal digital gardens. Like blogs, digital gardens can also be collective efforts, run by a company, a research group, or a larger community. The most widespread tool for digital gardening is the Wiki, but there are also more recent developments in this space, such as &lt;a href="https://www.notion.so/"&gt;Notion&lt;/a&gt; or &lt;a href="https://roamresearch.com/"&gt;Roam&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One distinction that I haven&amp;rsquo;t seen mentioned yet in this context is the one between a garden and a park. Both are curated and thus continuously evolving. But whereas gardens are set up and maintained for the benefit and enjoyment of their owners, parks are created and maintained for the benefit and enjoyment of the public. The difference can be subtle, as digital gardens are often visible to the public as well. But they are more like the unwalled garden on the roadside that you can admire passing by than like the park in which you can take a walk and sit down reading a book. A good example of a digital park is &lt;a href="https://www.wikipedia.org/"&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Science is all about acquiring information about our world and distilling it into knowledge, and therefore requires a fair bit of gardening. In its early days, it was managed as a garden by and for a small community of people who were motivated by curiosity and relied on personal wealth or on sponsors for doing their work. Universities employed scientists more for teaching than for doing research. Research was done by individuals or small teams, and presented at conferences or in journal articles, much like today. Unlike today, most scientists were up to date on everything that was happening in their field, and had personal exchanges with almost everyone else, in face-to-face meetings or by correspondence. Conferences were events in which conflicting results and different points of views were actively debated, enabling the formation of consensus. The streams of papers and conference contributions thus watered the garden of scientific knowledge.&lt;/p&gt;

&lt;p&gt;All that changed after World War II, when science underwent rapid growth as states injected a lot of money while at the same time expecting the scientific community to cultivate a park rather than a garden, contributing to the common good. Keeping up to date with everybody else&amp;rsquo;s work became more and more difficult, slowly eroding the possibility of consensus formation through live debate at conferences. Productivity metrics focusing on what is easiest to quantify ended up rewarding scientists for contributing to the stream of journal articles, but not for contributing to the cultivation of the park of scientific knowledge. Today, the streams of journal articles have become torrents whose distillation into knowledge is becoming ever more difficult. A good illustration is the (serious) &lt;a href="https://science.sciencemag.org/content/368/6494/924.full"&gt;proposal to use machine learning tools&lt;/a&gt; to make sense of the &amp;ldquo;tsunami&amp;rdquo; of articles resulting from the intense research on the Covid&amp;ndash;19 pandemic.&lt;/p&gt;

&lt;p&gt;The design and implementation of new mechanisms for knowledge distillation and consensus formation is thus a major challenge for science today, and even though machine learning techniques may prove to be helpful, I expect this to remain a fundamentally human task for a long time to come. These new mechanisms must combine technological aspects (good tools for working towards these goals) and social aspects (incentives for scientists to participate in this work). As always, the social aspects are the harder problem. As a first step and as a source for inspiration, let&amp;rsquo;s look at similar existing mechanisms in science and elsewhere. Which digital parks exist? How do they work? Can their mechanisms be adapted to other applications?&lt;/p&gt;

&lt;p&gt;I have already cited Wikipedia as a prime example of a digital park. I had expected to see Wikis more widely used as a platform for collective information curation in science, be it as gardens or parks, but when I searched for examples I found surprisingly few, e.g. &lt;a href="http://www.tricki.org/"&gt;Tricki&lt;/a&gt; (for mathematical problem-solving techniques) or the &lt;a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo"&gt;Complexity Zoo&lt;/a&gt; (on classes of computational complexity). One problematic aspects of Wikis is that they present only a single view to the outside world. They are better suited for presenting an established consensus than for supporting the process of consensus formation in rapidly evolving fields. One of the rare cases of a Wiki used for coordinating collaborative research, rather than for summarizing the state of the art, is the &lt;a href="https://asone.ai/polymath/index.php"&gt;Polymath project&lt;/a&gt;. It is probably not a coincidence that this has happened in mathematics, a domain whose working habits remain close to those of the early scientific community, with individuals having more agency than in disciplines that are more dependent on material resources.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://fed.wiki.org/"&gt;Federated Wiki&lt;/a&gt; is an interesting evolution of the Wiki concept (initiated by the original inventor of the Wiki, &lt;a href="https://twitter.com/WardCunningham"&gt;Ward Cunningham&lt;/a&gt;) that allows individual contributors to maintain and publish their own view while at the same time encouraging reciprocal borrowing of content. &lt;a href="https://www.youtube.com/watch?time_continue=111&amp;amp;v=2Gi9SRsRrE4"&gt;This video&lt;/a&gt; illustrates the process nicely. Whereas federated Wiki looks like a promising approach to consensus formation, the technical obstacles to setting up a federated Wiki are significant (contributors must manage personal Web servers and domains) and make it difficult to evaluate it in practice.&lt;/p&gt;

&lt;p&gt;Perhaps the most frequent kind of digital park in science today is the collaborative software development project, hosted on platforms such as &lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gitlab.com/"&gt;GitLab&lt;/a&gt;, or similar platforms operated by research institutions. Ignoring the differences resulting from the focus on code rather than prose, the main differences between platforms and Wikis are (1) a stronger emphasis on discussion (&amp;ldquo;issues&amp;rdquo;) and (2) the co-existence of multiple branches representing different public or private views of a common project, with one branch (conventionally named &amp;ldquo;master&amp;rdquo; or &amp;ldquo;main&amp;rdquo;) representing the current consensus.&lt;/p&gt;

&lt;p&gt;Collaborative software projects are an interesting case study also for the question of incentives. The lack of recognition of software development as a research activity has been deplored for a long time. It is usually attributed to the relative novelty of software as a form of research output. But I suspect that the park nature of software, as opposed to the stream nature of journals, is also an important factor, because it makes it more difficult to evaluate an individual&amp;rsquo;s contributions based on purely formal (and thus easily measurable) criteria. On the other hand, today&amp;rsquo;s collaborative platforms make such an evaluation technically feasible, by counting for example the number of commits made by an individual, or the number of lines changed by those commits. Everybody involved in software development will probably agree that this is a stupid metric, but it&amp;rsquo;s no more stupid than counting publications weighted by journal impact factor.&lt;/p&gt;

&lt;p&gt;Another social aspect that is well illustrated by software is the difficulty of the transition from gardens to parks. Projects usually start out as gardens, with a small team developing software for its own use. Then early users start to join, who by necessity have to figure out for themselves how to adapt the software to their needs, and are thus likely to become contributors. With an increasing user base, developers have an interest to work on more robust code and better documentation, in order to reduce the effort of technical support. At that stage, the software becomes attractive to less technically minded users who see no need to ever get in touch with the development community. These users consider the software a park, even if its developers still consider it a garden, leading to contradictory tacit expectations on both sides about the priorities for future maintenance, which I have described &lt;a href="https://blog.khinsen.net/posts/2020/02/26/the-rise-of-community-owned-monopolies/"&gt;in an earlier post&lt;/a&gt;. Developers tend to contribute to this confusion by advertising their project as a park while maintaining it as a garden.&lt;/p&gt;

&lt;p&gt;The above examples illustrate that the technical challenges of digital gardens and parks are somewhat understood and partially solved. Collaborative software development platforms in particular have proven very effective. Adapting their concepts to different use cases and different users looks definitely possible, although the effort required should not be underestimated, in particular for developing appropriate user interfaces. But the real challenge is creating incentives for collaboration, in a universe currently dominated by competition for limited resources.&lt;/p&gt;</description></item>
  <item>
   <title>An open letter to software engineers criticizing Neil Ferguson's epidemics simulation code</title>
   <link>http://blog.khinsen.net/posts/2020/05/18/an-open-letter-to-software-engineers-criticizing-neil-ferguson-s-epidemics-simulation-code/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-05-18-an-open-letter-to-software-engineers-criticizing-neil-ferguson-s-epidemics-simulation-code</guid>
   <pubDate>Mon, 18 May 2020 08:54:19 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Dear software engineers,&lt;/p&gt;

&lt;p&gt;&lt;a href="https://lockdownsceptics.org/code-review-of-fergusons-model/"&gt;Many&lt;/a&gt; &lt;a href="https://www.telegraph.co.uk/technology/2020/05/16/coding-led-lockdown-totally-unreliable-buggy-mess-say-experts/"&gt;of you&lt;/a&gt; &lt;a href="https://chrisvoncsefalvay.com/2020/05/09/imperial-covid-model/"&gt;were&lt;/a&gt; &lt;a href="https://github.com/mrc-ide/covid-sim/issues"&gt;horrified&lt;/a&gt; at the sight of &lt;a href="https://github.com/mrc-ide/covid-sim"&gt;the C++ code that Neil Ferguson and his team wrote to simulate the spread of epidemics&lt;/a&gt;. I feel with you. The only reason why I am less horrified than you is that I have seen a lot of similar-looking code before. It is in fact quite common in scientific computing, in particular in research projects that have been running for many years. But like you, I don&amp;rsquo;t have much trust in that code being a faithful and trustworthy implementation of the epidemiological models that it is supposed to implement, and I don&amp;rsquo;t want to defend bad code in science.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;However, many of your specific criticisms show a lack of familiarity with today&amp;rsquo;s academic research. This code is not the sole result of 13 years of tax-payer-funded research. The core of that research is building and applying the model it implemented by the code, the code itself is merely a means to this end. The scientists who wrote this horrible code most probably had no training in software engineering, and no funding to hire software engineers. And the senior or former scientists who decided to give tax-payer money to this research group are probably even more ignorant of the importance of code for science. Otherwise they would surely have attributed money for software development, and verified the application of best practices.&lt;/p&gt;

&lt;p&gt;But the main message of this letter is something different: it&amp;rsquo;s about &lt;em&gt;your&lt;/em&gt; role in this story. That&amp;rsquo;s of course a collective you, not you the individual reading this letter. It&amp;rsquo;s you, the software engineering community, that is responsible for tools like C++ that look as if they were designed for shooting yourself in the foot. It&amp;rsquo;s also you, the software engineering community, that has made no effort to warn the non-expert public of the dangers of these tools. Sure, you have been discussing these dangers internally, even a lot. But to outsiders, such as computational scientists looking for implementation tools for their models, these discussions are hard to find and hard to understand. There are lots of tutorials teaching C++ to novices, but I have yet to see a single one that starts with a clear warning about the dangers. You know, the kind of warning that every instruction manual for a microwave oven starts with: don&amp;rsquo;t use this to dry your dog after a bath. A clear message saying &amp;ldquo;Unless you are willing to train for many years to become a software engineer yourself, this tool is &lt;em&gt;not&lt;/em&gt; for you.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;As a famous member of your community famously said, &lt;a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/"&gt;software is eating the world&lt;/a&gt;. That gives you, dear software engineers, a lot of power in modern society. But power comes with responsibility. If you want scientists to construct reliable implementations of models that matter for public health decisions, the best you can do is make good tools for that task, but the very least you must do is put clear warning signs on tools that you do &lt;em&gt;not&lt;/em&gt; want scientists to use - always keeping in mind that scientists are not software engineers, and have neither the time nor the motivation to become software engineers.&lt;/p&gt;

&lt;p&gt;Consider what you, as a client, expect from engineers in other domains. You expect cars to be safe to use by anyone with a driver&amp;rsquo;s license. You expect household appliances to be safe to use for anyone after a cursory glance at the instruction manuals. It is reasonable then to expect &lt;em&gt;your&lt;/em&gt; clients to become proficient in &lt;em&gt;your&lt;/em&gt; work just to be able to use your products responsibly? Worse, is it reasonable to make that expectation tacitly?&lt;/p&gt;

&lt;p&gt;Some of you have helped with a first round of code cleanup, which I think is the most constructive attitude you can adopt in the short term. But this is not a sustainable approach for the future. We can&amp;rsquo;t ask software experts for a code review every time we do something important. We computational scientists need you software engineers to help us build a better future for computer-aided research. Which means pretty much all research, because software has been eating science as well for a while. Can we count on your help?&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;PS added 2020&amp;ndash;05&amp;ndash;19T10:30:&lt;/em&gt; This post has provoked a lively discussion not only in the comments below but also &lt;a href="https://twitter.com/khinsen/status/1262307434632282112"&gt;on Twitter&lt;/a&gt;. There are way too many comments for me to reply to each one individually, so I decided to address recurrent topics in this follow-up.&lt;/p&gt;

&lt;p&gt;Many people seem to have read my post as putting the main responsibility for the problems related to the cited simulation code on software engineers. This was most certainly not my intention. Scientists, policy makers, and journalists have all contributed to a less than satisfactory outcome. My open letter is clearly addressed at a particular group of people (software engineers criticizing the Imperial College Covid&amp;ndash;19 simulations on the basis of code quality) and clearly states its focus on the role of software technology, which is what the target audience seems to overlook. A focus is always an arbitrary choice of an author for the sake of brevity or clarity. A glance at the rest of my blog should suffice to show that I do consider computational scientists responsible for their technological choices and their consequences. However, my main intention was not assigning blame for events in the past, but outline what needs to change to prevent similar events in the future.&lt;/p&gt;

&lt;p&gt;The car analogy was another frequent target of critical comments. Cars are a mature technology, in which many professions (engineers, workers, mechanics, driving instructors, drivers, etc.) have well-defined roles and everyone involved has a general understanding of the role of everyone else. Software is an immature technology in which roles remain fuzzy and everyone has an even fuzzier view of which other roles exist and who fills them. The discussion of my open letter has provided ample evidence for this all-encompassing fuzziness.  What we collectively need to work on is turning software into a mature technology. That requires all stakeholders to make their own role views explicit and then negotiate shared role definitions with everyone else. Several commenters have pointed out the emergence of research software engineers (RSEs) as a sign for progress, and I completely agree. But even the role of RSEs remains fuzzy at this time. Should they work a collaborators on research projects, with a particular specialization? Or as occasional consultants or service providers to researchers? Their interaction with the software engineering universe is even less clear. For now it is mostly one-way in that RSEs bring software technology from the outside into research labs. What my letter argues for is an action in the opposite direction: make software technology evolve to adapt to the specific needs of scientists. A big problem is culture clash. In academia, scientists are traditionally on top of the power pyramid and are used to everyone else working for them (even though the top position is now held by managers, but that&amp;rsquo;s a different story). In the tech world, it&amp;rsquo;s software engineers who are kings and used to everyone else, including their clients, obeying their directives. In the worst case, RSEs might find themselves trapped in the valley between two power pyramids. In the ideal case (from my point of view), they will be diplomats working towards a merger of the two kingdoms, with a simultaneous transformation into a democracy.&lt;/p&gt;</description></item>
  <item>
   <title>Wanted: a hierarchically modular software architecture</title>
   <link>http://blog.khinsen.net/posts/2020/05/05/wanted-a-hierarchically-modular-software-architecture/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-05-05-wanted-a-hierarchically-modular-software-architecture</guid>
   <pubDate>Tue, 05 May 2020 12:59:25 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;In his 1962 classic &lt;a href="https://www.jstor.org/stable/985254"&gt;&amp;ldquo;The Architecture of Complexity&amp;rdquo;&lt;/a&gt;, Herbert Simon described the hierarchical structure found in many complex systems, both natural and human-made. But even though complexity is recognized as a major issue in software development today, the architecture described by Simon is not common in software, and in fact seems unsupported by today&amp;rsquo;s software development and deployment tools.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The prime characteristic that Simon identifies in most complex systems is a hierarchical structure. Systems consist of subsystems, which consist of sub-sub-systems, etc. Simon describes the subsystems at each level as &amp;ldquo;nearly decomposable&amp;rdquo;, meaning that the interactions between subsystems are much less important than the interactions between the parts inside a subsystem. I prefer the shorter term &amp;ldquo;modular&amp;rdquo; for this feature, and thus end up with &amp;ldquo;hierarchically modular&amp;rdquo; as my label for the architecture that Simon describes in much detail. I won&amp;rsquo;t repeat his arguments for the ubiquity of such systems, so please read the paper - it&amp;rsquo;s definitely worth it, and it&amp;rsquo;s very clearly written.&lt;/p&gt;

&lt;p&gt;It may seem as if many of today&amp;rsquo;s programming languages propose exactly this kind of architecture for designing software systems, but a critical inspection shows that they don&amp;rsquo;t. To explain where the problem is, I will use Python as an example because it is widely known, but the arguments apply with some modifications to most other languages as well.&lt;/p&gt;

&lt;p&gt;Python&amp;rsquo;s module system is basically a hierarchy of namespaces, with namespaces containing mainly function and class definitions, but also variables referring to arbitrary data objects. Since namespaces are independent, and can contain sub-namespaces, this looks like a perfect match for a hierarchically modular architecture.&lt;/p&gt;

&lt;p&gt;One obstacle is that there is no way to combine independently designed modules into a larger hierarchy. Suppose I want to create a software component called &lt;code&gt;ode_solver&lt;/code&gt; that uses the popular packages &lt;a href="http://numpy.org/"&gt;NumPy&lt;/a&gt; and &lt;a href="http://scipy.org/"&gt;SciPy&lt;/a&gt;. In a hierarchically modular architecture, implementation details of a component, such as the names of the packages it uses, would be hidden from outside view. The packages would become &lt;code&gt;ode_solver.numpy&lt;/code&gt; and &lt;code&gt;ode_solver.scipy&lt;/code&gt;. In real Python, they can only remain &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;scipy&lt;/code&gt;, as their authors decided to call them. Independently written software components in Python always live in the globally shared top-level namespace. And since developers are free to modify their packages as they like, this makes the top-level namespace an instance of &lt;a href="https://www.qwant.com/?q=shared%20mutable%20state"&gt;shared mutable state&lt;/a&gt;, universally recognized as problematic in software engineering.&lt;/p&gt;

&lt;p&gt;The shared top-level namespace creates a strong interaction between all components at all levels. Suppose I have another component called &lt;code&gt;visualizer&lt;/code&gt; that also uses NumPy and SciPy, but requires different versions. That component becomes impossible to combine with my &lt;code&gt;ode_solver&lt;/code&gt; because of conflicting version requirements - the well known &lt;a href="https://en.wikipedia.org/wiki/Dependency_hell"&gt;dependency hell&lt;/a&gt;. Another way to look at this is to consider each package&amp;rsquo;s detailed dependency list, with version requirements, as part of its interface.&lt;/p&gt;

&lt;p&gt;The second obstacle is that the full specification of a module&amp;rsquo;s interface (something that&amp;rsquo;s never ever written down in Python) in general includes classes defined by its dependencies. My &lt;code&gt;ode_solver&lt;/code&gt; could, for example, return some value as a NumPy array. That would make NumPy not only a run-time dependency of the code, but also a specification dependency for the interface. If &lt;code&gt;visualizer&lt;/code&gt; expects a NumPy array as the input to one of its functions, I&amp;rsquo;d be in trouble again as the class definition in the two different versions of NumPy might not be the same. And that trouble would not go away if I could migrate NumPy and SciPy inside my component&amp;rsquo;s namespace as suggested above.&lt;/p&gt;

&lt;p&gt;Some readers&amp;rsquo; first reaction is likely to be &amp;ldquo;that&amp;rsquo;s a symptom of bad specifications&amp;rdquo; or &amp;ldquo;that&amp;rsquo;s the trouble you deserve for using a dynamically typed language&amp;rdquo;. However, static typing doesn&amp;rsquo;t solve the problem, it merely shifts it from run time to compile time. It&amp;rsquo;s the types introduced by dependencies that end up in the static interface of a component. The impact on component compatibility is the same. And if that&amp;rsquo;s a symptom of bad design, then good design is not only rare but also actively discouraged by today&amp;rsquo;s software development tools. The only way out I can see is to create wrapper types and wrapper functions in the component that hide the implementation in terms of dependencies. Hands up if you find that idea appealing!&lt;/p&gt;

&lt;p&gt;The only programming language I know of that does not suffer from this problem is &lt;a href="https://www.unisonweb.org/"&gt;Unison&lt;/a&gt;, which refers to functions and data types &lt;a href="https://www.unisonweb.org/2020/04/10/reducing-churn/"&gt;via hashes rather than names&lt;/a&gt;. It&amp;rsquo;s a very young language, so it&amp;rsquo;s too early to say how this feature will change software architecture on a larger scale.&lt;/p&gt;

&lt;p&gt;Programming languages are not the only realm in which we can try to construct hierarchically modular software. It would in fact be preferable to do so at a language-neutral level, to escape from the silos that languages tend to represent. I&amp;rsquo;d love to be able to combine a component written in Python with a component written in R! So maybe we should try to make hierarchically modular assemblies at the level of compiled binaries.&lt;/p&gt;

&lt;p&gt;One candidate would then be Linux&amp;rsquo; &lt;a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format"&gt;Executable and Linkable Format&lt;/a&gt; (ELF), which covers several types of binary files: executables, object files, shared libraries, and more. But there is no kind of ELF file that could represent hierarchically composable modules, as far as I can see. There&amp;rsquo;s no way to combine two shared libraries into a bigger shared library, nor two executables into a larger executable, and moreover every executable has a global namespace that would create the same issues that I outlined above for Python. You can&amp;rsquo;t have an executable that includes or refers to two different versions of the &lt;a href="https://zlib.net/"&gt;zlib library&lt;/a&gt;, for example.&lt;/p&gt;

&lt;p&gt;The only approach that looks doable in the Unix world is working at the process level. A software component is then a process based on an executable, and data between processes is exchanged via files or sockets. Choosing a clever hash-based naming scheme (as done by &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt; and &lt;a href="https://guix.gnu.org/"&gt;Guix&lt;/a&gt;) makes it possible to keep any combination of versions accessible in parallel. Several processes could be managed as child processes by a superprocess, which would thus represent a component one level up in the hierarchy. In the Web world, a very similar setup could be constructed by making each component a Web service. There isn&amp;rsquo;t much tool support for such techniques, but perhaps the most important obstacle is efficiency issues in the communication between components, which would require serialization and either file storage or network communication.&lt;/p&gt;

&lt;p&gt;The main merit of the two approaches I have outlined in the last paragraph is that they can accommodate legacy code and systems, unlike the starting-from-scratch approach of Unison. With a bit of luck, improved tooling and optimization could turn the process/service-based approach into a viable technique for some types of real-life application, while Unison and perhaps others introduce the same basic idea at the programming language end of the scale of software component technologies. And then, if the concept turns out to be successful for taming software complexity, it might become the norm after a few decades. So far for my daily dose of wishful thinking!&lt;/p&gt;

&lt;p&gt;Finally, let me reveal my motivation for writing this post: I hope that someone will prove me wrong. I&amp;rsquo;d love to see a comment pointing out that I am simply not aware of the right tools and techniques. And you get bonus points for references to actual hierarchically modular software systems that work!&lt;/p&gt;</description></item>
  <item>
   <title>Emacs as a malleable system</title>
   <link>http://blog.khinsen.net/posts/2020/04/03/emacs-as-a-malleable-system/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-04-03-emacs-as-a-malleable-system</guid>
   <pubDate>Fri, 03 Apr 2020 13:56:04 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Malleable systems are software systems that are designed to be modified and extended by their users, eliminating the usually strict borderline between developers and users. Making scientific software more malleable is a goal that I have been pursuing for 25 years, starting with a shift from Fortran to Python as my main programming language, and a simultaneous shift from writing programs to writing toolkits, such as my &lt;a href="http://dirac.cnrs-orleans.fr/MMTK/"&gt;Molecular Modelling Toolkit&lt;/a&gt; first published in 1997. Therefore I was pleased to discover the &lt;a href="https://malleable.systems/"&gt;Malleable Systems Collective&lt;/a&gt;, which has just published a &lt;a href="https://malleable.systems/blog/2020/04/01/the-most-successful-malleable-system-in-history/"&gt;post&lt;/a&gt; in which I examine what is probably the most successful malleable system in the history of software: Emacs. If you care about users having more influence on their software, check out their site!&lt;/p&gt;</description></item>
  <item>
   <title>The rise of community-owned monopolies</title>
   <link>http://blog.khinsen.net/posts/2020/02/26/the-rise-of-community-owned-monopolies/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2020-02-26-the-rise-of-community-owned-monopolies</guid>
   <pubDate>Wed, 26 Feb 2020 15:04:54 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;One question I have been thinking about in the context of reproducible research is this: Why is all stable software technology old, and all recent technology fragile? Why is it easier to run 40-year-old Fortran code than ten-year-old Python code? A hypothesis that comes to mind immediately is growing code complexity, but I&amp;rsquo;d expect this to be an amplifier rather than a cause. In this pose, I will look at another candidate: the dominance of Open Source communities in the development of scientific software.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;h2 id="from-markets-to-monopolies"&gt;From markets to monopolies&lt;/h2&gt;

&lt;p&gt;In the 1990s, when I was working on my thesis, the world of scientific computing was very different from what it is now. Innovation was driven by hardware. Processor speeds kept increasing, and new processor architectures appeared on the market in rapid succession. In the course of the 1990s, I did most of my work on Unix workstations based on variety of architectures: &lt;a href="https://en.wikipedia.org/wiki/PA-RISC"&gt;PA-RISC&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/MIPS_architecture"&gt;MIPS&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/PowerPC"&gt;PowerPC&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/DEC_Alpha"&gt;DEC Alpha&lt;/a&gt;. I also worked on mainframe computers made by IBM, Fujitsu, and Cray, all using proprietary processors. Each manufacturer sold a package of hardware, operating system, and development tools such as compilers. Compilers implemented standardized programming languages, mainly Fortran and C, with manufacturer-specific extensions that most people stayed away from because they expected to be using different machines a few years later. The computing platforms that everybody was developing for were not processors nor operating systems, but Fortran~77 and ANSI-C, each of which had developed its ecosystem of scientific libraries. For an interactive development platform, add Unix and X11. Mixing Fortran and C was somewhat platform-specific, but very doable as well. Every time I changed labs and computers during my postdoc years, I had to spend a day or two to reinstall everything I needed, but I never suffered &lt;a href="https://hal.archives-ouvertes.fr/hal-02117588"&gt;software collapse&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Today, hardware innovation in mainstream computing has almost come to a halt. All the processor architectures listed above are gone. The x86 architecture, implemented in chips from Intel and AMD, dominates scientific computing, and in fact all of computing except for mobile devices. Hardware manufacturers therefore no longer supply compilers. For everyday work, most people use the free &lt;a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection"&gt;GNU Compiler Collection&lt;/a&gt; or the equally free &lt;a href="https://en.wikipedia.org/wiki/Clang"&gt;Clang&lt;/a&gt; compiler. For performance-critical work, commercial compilers from companies such as &lt;a href="https://www.nag.com/"&gt;NAG&lt;/a&gt;, &lt;a href="https://www.pgroup.com/index.htm"&gt;PGI&lt;/a&gt;, or &lt;a href="https://software.intel.com/en-us/compilers"&gt;Intel&lt;/a&gt; offer better performance and libraries fine-tuned for high-performance computing. The standards defining Fortran and C have evolved, but have maintained strict backwards compatibility.&lt;/p&gt;

&lt;p&gt;However, in the everyday life of computational scientists, these traditional platforms have lost importance. A new breed of languages and scientific ecosystems, such as &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt;, &lt;a href="https://www.r-project.org/"&gt;R&lt;/a&gt;, and &lt;a href="https://julialang.org/"&gt;Julia&lt;/a&gt;, have become the dominant support for scientific software in many (though not all) domains of research. Their rise has gone hand in hand with software collapse becoming so common that many consider it normal or even inevitable. Scientists are starting to adopt heavy technology with large overheads in terms of complexity and invested effort to work around the problem (if you didn&amp;rsquo;t guess yet, I am referring to containers). I waste a lot more time today with configuration and setup work (including configuration debugging) than I did in the 1990s. How did we get into this sad state of affairs? Is there any hope for getting out of it again?&lt;/p&gt;

&lt;p&gt;One reason that immediately comes to mind is increasing software complexity. But that&amp;rsquo;s more of a symptom than a cause. A better explanation would be an increased &lt;em&gt;problem&lt;/em&gt; complexity that would then &lt;em&gt;require&lt;/em&gt; more complex software. Problem complexity is much harder to measure, but I don&amp;rsquo;t see much evidence supporting this hypothesis. We certainly do bigger computations, on larger datasets, but if I look at today&amp;rsquo;s commonly used models and methods in computational science, they don&amp;rsquo;t look more complex than what I saw in the 1990s. What has increased, however, is variety. Today&amp;rsquo;s science relies on &lt;em&gt;more&lt;/em&gt; computational models than it did 30 years ago, and I believe that this contributes to the fragility issue, as I will explain later.&lt;/p&gt;

&lt;p&gt;There is another reason that I haven&amp;rsquo;t heard anyone mention so far: the disappearance of technology markets in favor of monopolist players who can count on customer lock-in. This description will probably make you think of Microsoft&amp;rsquo;s grip on the Windows user base, or the &amp;ldquo;walled gardens&amp;rdquo; that Google and Apple have created around their mobile platforms. But there is another category of monopoly owner in the tech world that is hardly recognized as such: Open Source communities.&lt;/p&gt;

&lt;h2 id="open-source-monopolists"&gt;Open Source monopolists&lt;/h2&gt;

&lt;p&gt;Consider two recent events: Microsoft killing Windows 7, and the Python community killing Python 2. The story is essentially the same in both cases: the creator of a piece of infrastructure software ends support for an old but still widely used version, forcing its users to move on to a later but not fully backwards compatible version. In both cases, a significant part of the user community would have preferred to stick to the older version, as has been nicely &lt;a href="https://xkcd.com/2224/"&gt;illustrated by xkcd&lt;/a&gt;. In both cases, the end-of-support decision is a rational one for the producer because supporting old versions is costly. And in both cases, the abandoned users have no other supplier they can turn to, because the producer holds a monopoly on the technology.&lt;/p&gt;

&lt;p&gt;Compare this to the diverse market of the 1990s. Producers of infrastructure software could add new functionality and try to win new clients with such improvements, but they could not afford to cause damage to their existing user base because users would simply turn to a competitor. There are many sources for standards-conforming Fortran compilers, but there is only one source for Windows or Python.&lt;/p&gt;

&lt;p&gt;I suspect some readers will feel anger at this point. How dare you compare a monopolist business to a community of unpaid volunteers offering their work to the world for free? The crucial point is that I am comparing them as seen from the outside. There is a wide gap between the self-image that Open Source communities have of themselves and the image that they present to the outside world, and I believe that this is a big part of the problem.&lt;/p&gt;

&lt;p&gt;Open Source communities tend to see themselves as communities of like-minded people that get organized to work together towards shared objectives. They see themselves much like a sports club that organizes practice sessions for its members, or like a village community that collectively plans its road infrastructure. But this is not at all how Open Source communities present themselves to the outside world. The Web site of a sports club says something like &amp;ldquo;We are a bunch of people enthusiastic about playing football. If you are as well, come and join us.&amp;rdquo; Now look at the &lt;a href="https://www.python.org/"&gt;Python Web site&lt;/a&gt;. Its first statement, in big letters, is &amp;ldquo;Python is a programming language that lets you work quickly and integrate systems more effectively.&amp;rdquo; The site is about a product. Its goal is to convince people to use Python, not to join a community. It is more similar to &lt;a href="https://www.microsoft.com/fr-fr/windows/"&gt;Microsoft&amp;rsquo;s Windows site&lt;/a&gt; than to the site of a sports club.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;But&amp;hellip;&amp;rdquo; I hear you say. Open Source. Free Software, as in &amp;ldquo;free beer&amp;rdquo; &lt;em&gt;and&lt;/em&gt; in &amp;ldquo;free speech&amp;rdquo;. And everybody can join in, the community is so welcoming! Fine, but that&amp;rsquo;s again the insiders&amp;rsquo; view, just slightly enlarged to the circle of people whose engagement with the technology is sufficiently deep that they consider joining the community. I suspect that most people who download and install Python the product will never know anything about the community, and many will even use Python without being aware of it at all. What they are aware of is an application or utility written in Python, e.g. &lt;a href="https://calibre-ebook.com/"&gt;Calibre&lt;/a&gt; for managing their e-books, or &lt;a href="https://www.offlineimap.org/"&gt;offlineimap&lt;/a&gt; for downloading e-mail. In contrast, a true community-oriented piece of software would have a splash screen saying &amp;ldquo;Welcome to the Python community! Before using this software, please become familiar wit how our community works&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Sports clubs and village communities focus on their members&amp;rsquo; needs, interacting with the outside world by necessity, but only as a side effect. Most Open Source communities are more like political parties or non-government organizations in that they &lt;em&gt;want&lt;/em&gt; to have an impact on the outside world. They care about the popularity of their products, and make efforts to increase their mind share. The reward they get in return is not money, but that&amp;rsquo;s the only difference from how a company works. Both Open Source communities and software companies have an interest in attracting new clients and keeping existing ones. Both can retain clients more efficiently by generating lock-in, and so they do.&lt;/p&gt;

&lt;p&gt;Note that I am not saying that either one creates lock-in intentionally. For Open Source communities such as Python, which I know sufficiently well, I am convinced there is no such intention. For companies such as Microsoft or Google, I can&amp;rsquo;t know for sure. But from the clients&amp;rsquo; perspective, it doesn&amp;rsquo;t matter if lock-in is intentional or a side effect.&lt;/p&gt;

&lt;p&gt;One particularity about computing technology is that lock-in happens by default. It takes a conscious effort (and thus an incentive) to &lt;em&gt;avoid&lt;/em&gt; lock-in. The reason is the fine-grained complexity of software interfaces coupled with the near-zero cost of modifying them. There are so many details that re-implementing an existing interface exactly requires a precise documentation of that interface, a perfectionist attitude, and a lot of time. The markets of the 1990s were made possible only by lengthy and costly standardization processes. Which in turn the participants accepted only because without the markets defined by those standards, none of them could continue to innovate in the field of processor architectures.&lt;/p&gt;

&lt;h2 id="lock-in-favors-software-collapse"&gt;Lock-in favors software collapse&lt;/h2&gt;

&lt;p&gt;So far for communities as monopoly holders. Back to my original question: how did software collapse become normal? I believe that this is a near-automatic consequence of infrastructure software being managed by monopoly holders. The monopoly situation prevents existing users from moving elsewhere, significantly reducing the effort that needs to be made to keep them. All effort can thus be concentrated on gaining new users, which leads to the paradoxical situation that the needs of non-users have a larger weight in strategic decisions than the needs of the user base. With backwards compatibility being costly, boring, and irrelevant to the non-users that matter for the future, why care about it? That is, in my opinion, what happened to the Scientific Python ecosystem starting in the 2010s: adoption by the explosively growing data science community drowned the existing user base. The best strategy for SciPy was then to focus on the needs of the data science people, which also became the primary source for recruiting developers and maintainers.&lt;/p&gt;

&lt;p&gt;Which brings me back to what I said earlier: the diversification of techniques in computational science is part of the problem. While the various subdomains of computational science have overlapping requirements, they also have divergent needs. The longevity of code is one aspect whose importance varies a lot, but there are others: the size of a typical computational task, the size of the datasets being processed, the nature of the algorithms being applied, the hardware platforms that matter most, and many more. While in theory Open Source is good for supporting diversity (&amp;ldquo;just fork the code and adapt it to your needs&amp;rdquo;), the reality of today&amp;rsquo;s major Open Source communities is exactly the opposite: a focus on &amp;ldquo;let&amp;rsquo;s all work together&amp;rdquo;. Combine this with the chronic lack of funding, and thus also a lack of incentives for developing the structured governance that would administrate funding and create activity reports, and you end up with large number of users depending on the work of a small number of inexperienced developers in precarious positions who cannot reasonably be expected to make an effort to even understand the needs of the user base at large. In a way, software collapse is a consequence of &lt;a href="https://en.wikipedia.org/wiki/Conway's_law"&gt;Conway&amp;rsquo;s law&lt;/a&gt; applied to Open Source communities.&lt;/p&gt;

&lt;h2 id="can-we-do-better"&gt;Can we do better?&lt;/h2&gt;

&lt;p&gt;Given that today&amp;rsquo;s tech world is dominated by software and Open Source communities, rather than by hardware-producing companies, is it possible to return to a market situation with no or weak lock-in? I don&amp;rsquo;t think so. Standards-based markets can only form when there are multiple competing producers right from the start. In contrast, Open Source communities start out small and adventurous, with a few growing big and becoming infrastructure suppliers. In the beginning, they have no competition, and when they are big, new communities cannot possibly start to compete with them in the mindshare market. Which leaves two possibilities: Open Source communities could become more user-oriented, or the maintenance of infrastructure software could be ensured by other types of organizations. Let&amp;rsquo;s start by looking at the first possibility.&lt;/p&gt;

&lt;p&gt;An important first step would be Open Source communities recognizing that they are developing and selling products to a user base that extends far beyond the circle of potential community members. A good time for that would be just now. Many Open Source communities have recently realized that the shared idealistic goal of an Open Source world is not sufficient for ensuring respectful collaboration, and have reacted by introducing codes of conduct. What I am suggesting here is a similar approach for making the relation with the user base more explicit. The absence of a legal contract between developers and users is one of the core principles of Open Source, but that doesn&amp;rsquo;t imply the absence of moral obligations. Any organization that wants to have an impact on the outside world must consider how this impact affects the life and work of other people. It should then define moral commitments, in written, even if the license prevents them from being legally enforced. A nice example are the &lt;a href="http://big-data-biology.org/software/commitments/"&gt;Big Data Biology Lab Software Tool Commitments&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Open Source communities could also more actively solicit feedback from the outside. Getting useful feedback from low-engagement users is difficult, but there are proxies, for example the people who package software for various distributions.&lt;/p&gt;

&lt;p&gt;But perhaps Open Source communities are just not the right form of organization for infrastructure software. There are other entities that create Open Source software, such as the &lt;a href="https://www.mozilla.org/"&gt;Mozilla&lt;/a&gt; and &lt;a href="https://apache.org/"&gt;Apache&lt;/a&gt; foundations, or hybrids such as the &lt;a href="https://pharo.org/community"&gt;Pharo community&lt;/a&gt; with the &lt;a href="https://consortium.pharo.org/"&gt;Pharo consortium&lt;/a&gt; and the &lt;a href="https://association.pharo.org/"&gt;Pharo User Association&lt;/a&gt; providing channels for users to influence development. It seems probable that more useful organizational forms are waiting to be discovered. In fact, a good guess is that software should best be managed much like other scientific infrastructure: by specific institutions that ensure long-term funding and provide software as a service to research communities.&lt;/p&gt;</description></item>
  <item>
   <title>Pharo year one</title>
   <link>http://blog.khinsen.net/posts/2019/12/31/pharo-year-one/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-12-31-pharo-year-one</guid>
   <pubDate>Tue, 31 Dec 2019 14:40:33 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;It&amp;rsquo;s the season when everyone writes about the past year, or even the past decade for a year number ending in 9. I&amp;rsquo;ll make a modest contribution by summarizing my experience with Pharo after one year of using it for projects of my own.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;My first contact with Pharo happened a bit more than one year ago, when I signed up for the &lt;a href="http://mooc.pharo.org/"&gt;Pharo MOOC&lt;/a&gt; in October 2018. But following a MOOC means working on exercice problems defined by someone else. Getting a real feeling for a programming system requires moving on to problems you actually care about. That&amp;rsquo;s why I started three Pharo-based projects in 2019. The main one is the &lt;a href="https://www.activepapers.org/pharo-edition/"&gt;Pharo edition of ActivePapers&lt;/a&gt;, the other ones are &lt;a href="https://github.com/khinsen/ipfs-pharo/"&gt;an exploration&lt;/a&gt; of the &lt;a href="https://ipfs.io"&gt;Interplanetary File System (IPFS)&lt;/a&gt; and a &lt;a href="https://github.com/khinsen/leibniz-pharo/"&gt;second implementation of my digital scientific notation Leibniz&lt;/a&gt;. In all these projects, the user interface is an important aspect, because that&amp;rsquo;s one of my major motivations for using Pharo. However, instead of the standard Pharo user interface framework, which is an evolution of the original Smalltalk user interface of the 1980s, I used the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt;, a complete redesign with many interesting new ideas. Perhaps the most significant innovation in the Glamorous Toolkit from my perspective is the introduction of a computational document. It resembles the fashionable computational notebooks in many ways, but differs in being an integral part of a live programming system.&lt;/p&gt;

&lt;p&gt;As I wrote in my &lt;a href="https://blog.khinsen.net/posts/2018/12/19/exploring-pharo/"&gt;initial blog post&lt;/a&gt; on Pharo, I started out by exploring the system using the tools it provides for that purpose. In retrospect, this is clearly the strongest aspect of Pharo. The combination of code browsers, code search, object inspection, and execution inspection (via a tool misleadingly called a debugger) is an extremely powerful way to understand complex software systems. The best evidence is that I was able to write useful and non-trivial extensions to the Glamorous Toolkit, which still is rapidly evolving alpha-stage software and, judged by standard metrics such as lines of documentation per line of code, badly documented. But such metrics make no sense in a system in which searching the code base is faster than documentation lookup in standard environments. Going back to such environments after working with Pharo is a very frustrating experience.&lt;/p&gt;

&lt;p&gt;Note that I am not saying that the Pharo environment is perfect. For my taste it requires way too much mouse use. I am still much more productive in Emacs than in Pharo for tasks supported by both, mainly because I can keep my hands on the keyboard. I also find the standard code browser in Pharo too limiting in only showing one method at a time. The Glamorous Toolkit is a clear improvement in that respect. But all the criticism I can come up with is about details that can be fixed, whereas the main defects that I now see in almost every other software development environment is much more fundamental: they suffer from a barrier that separates development tools on one side from the code under development on the other side.&lt;/p&gt;

&lt;p&gt;Similar remarks apply to the Smalltalk language on which Pharo is built. It&amp;rsquo;s a minimal programming language that puts its object system in center stage and pushes as many features as possible into its libraries. That&amp;rsquo;s certainly an interesting point in design space to explore, but I&amp;rsquo;d personally prefer to have a couple of important concepts (for example immutable objects) as language features, rather than as implementation details of class hierarchies. But then, no language is perfect, and Smalltalk is certainly good enough for my needs.&lt;/p&gt;

&lt;p&gt;The most serious problem that I have with Pharo is that I don&amp;rsquo;t see how I could use it productively for my own research in computational biophysics in the near future. There is a small computational science community around Pharo (see e.g. &lt;a href="https://github.com/pharo-open-documentation/awesome-pharo#scientific-libraries"&gt;this list&lt;/a&gt; of scientific libraries), but most of the infrastructure code that I&amp;rsquo;d need is missing. Moreover, Pharo evolves too rapidly for the kind of computational research that I do (see &lt;a href="https://blog.khinsen.net/posts/2017/11/16/a-plea-for-stability-in-the-scipy-ecosystem/"&gt;my critique of the SciPy ecosystem&lt;/a&gt; for some background information). Finally, reproducible computations remain a challenge because there isn&amp;rsquo;t much of a support infrastructure for reproduciblity in Pharo so far, although the recent &lt;a href="https://github.com/guillep/PharoBootstrap"&gt;work on bootstrapping&lt;/a&gt; is an important first step.&lt;/p&gt;

&lt;p&gt;On a longer time scale, I can imagine Pharo replacing Emacs as my main user interface to computing, with the hard-core science written in different languages but interfaced to Pharo. I expect IPFS to play an important role at the cross-language interface, for various reasons that deserve an entire blog post on their own. However, it takes a lot of not-yet-written code to get there. Too much to define this as a realistic goal for myself. This means that my future use of Pharo mainly depends on the directions taken by the Pharo community over the coming years. I am pretty sure that Pharo will remain an important tool in my toolbox, I just don&amp;rsquo;t know what its exact role will be.&lt;/p&gt;</description></item>
  <item>
   <title>Industrialization of scientific software: a case study</title>
   <link>http://blog.khinsen.net/posts/2019/11/12/industrialization-of-scientific-software-a-case-study/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-11-12-industrialization-of-scientific-software-a-case-study</guid>
   <pubDate>Tue, 12 Nov 2019 09:46:08 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;A coffee break conversion at a scientific conference last week provided an excellent illustration for the industrialization of scientific research that I wrote about in a &lt;a href="https://blog.khinsen.net/posts/2019/10/29/the-industrialization-of-scientific-research/"&gt;recent blog post&lt;/a&gt;. It has provoked some discussion &lt;a href="https://twitter.com/khinsen/status/1191673813626499072"&gt;on Twitter&lt;/a&gt; that deserves being recorded and commented on a more permanent medium. Which is here.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;I was chatting with a colleague who I have been meeting at such occasions for about 15 years. He asked me if I was still developing my &lt;a href="http://dirac.cnrs-orleans.fr/MMTK"&gt;Molecular Modelling Toolkit&lt;/a&gt;. I replied that I had stopped working on it because the &lt;a href="https://www.python.org/doc/sunset-python-2/"&gt;end of support for Python 2 in 2020&lt;/a&gt; would quickly make it too hard to use for most of its intended audience, and that I didn&amp;rsquo;t have the means nor the motivation to port it to Python 3. He was quite surprised by my explanations, since he had never heard of the end of support for Python 2, though he did know that there was also a version 3 that was a bit different. His own data analysis scripts were still Python 2 because he had never seen a good reason to even look at Python 3 - never break a working system! But he was alarmed by my prediction that Python 2 would soon disappear from Linux distributions, as he relied on Ubuntu (regularly updated by his lab&amp;rsquo;s systems administrator) to provide him with Python 2 and the few libraries he used.&lt;/p&gt;

&lt;p&gt;I was not surprised, as I have had similar conversations with various colleagues over the last years. In particular when someone contacts me with a Python question, which happens quite frequently as I have the reputation of being a Python expert in my little corner of science. The typical profile of these people is experimentalists who write and use small data analysis scripts, but for whom computation is not the central part of their research. They picked up Python from a colleague or a student, or perhaps through attending a short introductory course (such as a &lt;a href="https://software-carpentry.org"&gt;Software Carpentry&lt;/a&gt; workshop). They have a Python installation on their machine, which is managed by someone else. For them, Python is &amp;ldquo;just there&amp;rdquo;, exactly like other Unix basics such as &lt;code&gt;sh&lt;/code&gt;, or &lt;code&gt;grep&lt;/code&gt;. Moreover, Python has been part of their computing life for many years, often for their entire scientific career, and it has never caused them any trouble.&lt;/p&gt;

&lt;p&gt;When I mentioned my coffee break conversation &lt;a href="https://twitter.com/khinsen/status/1191673813626499072"&gt;on Twitter&lt;/a&gt;, Greg Landrum &lt;a href="https://twitter.com/dr_greg_landrum/status/1192446793612705792"&gt;commented&lt;/a&gt; that he would expect every Python user to make an effort to stay informed about important Python news, so everyone should by now have heard of the end-of-life decision for Python 2. This reminded me of an earlier &lt;a href="https://twitter.com/zacchiro/status/1123168548929536000"&gt;Twitter conversation with Stefano Zacchiroli&lt;/a&gt;, who expressed similar views. As did other actors of the FOSS universe in various real-life discussions. There seems to be a widely shared expectation among FOSS developers that users should follow news about the software they use and take the required steps to adapt to &amp;ldquo;mandatory changes&amp;rdquo;, as Stefano put it. My story illustrates that this is not happening. There is a category of users who (1) don&amp;rsquo;t follow development news and (2) expect the software they use to stay around forever without major breaking changes.&lt;/p&gt;

&lt;p&gt;This is exactly the phenomenon that I call the industrialization of scientific software. Some software packages, such as the core of the Scientific Python ecosystem, become so popular beyond their core community that for an important part of their users they are industrial products, something they obtain once and then use without thinking much about its origins or possible evolution. One sign of a piece software becoming an industrial product is its inclusion in standard Linux distributions, where it is just one package out of many that users can choose from. Linux distributions take the role that department stores have for material goods, providing a platform for window-shopping and acquisition via a standardized procedure. For users who get their software from a Linux distribution, all software looks a bit alike. They have no reason to be more careful about Python than about &lt;code&gt;sh&lt;/code&gt; or &lt;code&gt;grep&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Just like material goods industries, the developers of industrial software, FOSS or not, have no easy way to communicate with their clients. If such communication becomes inevitable, as for example in the case of a product recall for safety reasons, an enormous effort must be deployed to ensure that the message reaches most of its audience. &lt;a href="https://twitter.com/pdebuyl/status/1192410647784574976"&gt;Pierre de Buyl made a suggestion along these lines&lt;/a&gt;, proposing to put up posters with an explanation of the Python 2-&amp;gt;3 transition in every research lab. Asking research funders to support such an action would be an interesting experiment.&lt;/p&gt;

&lt;p&gt;Is there anything that FOSS communities can do to prevent such miscommunication in the future? A look at industrial material goods may provide inspiration. Every non-trivial technical product comes with a user manual, which typically starts with pointing out safety precautions that users are expected to be aware of. Do this, don&amp;rsquo;t do that, watch out for exceptional situations. The documentation of software packages could do the same, and tutorials could then emphasize the message when explaining the product to potential future customers. Here is what such a warning could look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This software package is developed for cutting-edge scientific
research. Our priority in development is to improve the software
and to adapt it for the needs of future applications. As a consequence,
we cannot maintain client code compatibility indefinitely.
Users of this package are expected to check the release notes
(available at http://...) at least once per year, and to adapt
their code to changes in the interfaces explained there.&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I would expect such a notice in the &lt;a href="https://scipy-lectures.org/intro/intro.html"&gt;introduction to the SciPy Lecture Notes&lt;/a&gt;, for example. It describes the SciPy ecosystem, comparing it to alternative choices, but says no word about what users need to do to safely use this ecosystem in their research work. As I said in my &lt;a href="https://blog.khinsen.net/posts/2019/10/29/the-industrialization-of-scientific-research/"&gt;previous post&lt;/a&gt;, the FOSS community has largely been blind to the consequences of software industrialization, maintaining the outdated view that developers and users form a single community. It&amp;rsquo;s time for an upgrade.&lt;/p&gt;

&lt;p&gt;Note added after the initial publication: Dan Katz commented &lt;a href="https://twitter.com/danielskatz/status/1194203819271491586"&gt;on Twitter&lt;/a&gt; with a reference to this very clear &lt;a href="https://collegeville.github.io/CW3S19/WorkshopResources/WhitePapers/quillenCW3S19.pdf"&gt;statement on the development priorities for Matlab&lt;/a&gt;. It would be very helpful if FOSS communities published similar statements about their products.&lt;/p&gt;</description></item>
  <item>
   <title>The industrialization of scientific research</title>
   <link>http://blog.khinsen.net/posts/2019/10/29/the-industrialization-of-scientific-research/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-10-29-the-industrialization-of-scientific-research</guid>
   <pubDate>Tue, 29 Oct 2019 08:52:19 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Over the last few years, I have spent a lot of time thinking, speaking, and discussing about the reproducibility crisis in scientific research. An obvious but hard to answer question is: Why has reproducibility become such a major problem, in so many disciplines? And why now? In this post, I will make an attempt at formulating an hypothesis: the underlying cause for the reproducibility crisis is the ongoing industrialization of scientific research.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;First of all, let me explain what I mean by industrialization. In the production of material goods, this term stands for a transition to high-volume production in large sites (factories), profiting from economies of scale. This doesn&amp;rsquo;t directly carry over to immaterial goods such as information and knowledge, which can be copied at near-zero cost. There are, however, aspects of industrialization that do make sense for immaterial goods. The main one is a clear separation of producers, who design and make products for an anonymous group of potential clients, and consumers who choose from pre-existing products on the market. This stands in contrast to 1) producing for one&amp;rsquo;s own consumption, and 2) commissioning someone else (e.g. a craftsman) to make a personalized product. Both of these approaches lead to products optimized for a specific consumer&amp;rsquo;s need, whereas industrial products are made for a large and anonymous market.&lt;/p&gt;

&lt;p&gt;In scientific research, immaterial industrial products are a recent phenomenon. The ones that I will concentrate on are software and datasets that are publicly available and used by scientists outside of any collaboration with their authors. Twenty years ago, this would have been a rare event. Most software was written for in-lab use, and not even made available to others. Only a small number of basic, standardized, and widely used tools, such as compilers, were already industrial products. Most data were likewise not shared outside the research group that collected them. The resulting non-verifiability of scientific findings was an obvious problem, and led ultimately to today&amp;rsquo;s growing Open Science movement. However, the Open Science movement goes well beyond asking for the transparency that is fundamentally required by the scientific method. It wants software and data to be &lt;em&gt;reusable&lt;/em&gt; by other scientists and for different purposes. This is stated most explicitly by the &lt;a href="https://www.go-fair.org/fair-principles/"&gt;FAIR data&lt;/a&gt; label, in which the R stands for reusability. Open Science thus turns software and datasets into industrial commodities.&lt;/p&gt;

&lt;h2 id="the-knowledge-gap"&gt;The knowledge gap&lt;/h2&gt;

&lt;p&gt;A characteristic feature of industrial products is that consumers know much less about them than producers. Consumers cannot ask for personalized explanations either, unlike in the case of a product tailor-made by a craftsman. For material goods, this has led to a wide range of professions, institutions, and regulations designed to help consumers choose suitable products and to protect them against producers&amp;rsquo; abuse of their superior knowledge. Examples are consumer protection agencies, independent experts, technical norms, quality labels, etc. For the industrial products in scientific research, we have no established equivalents yet, and it is not even clear if can ever have them. And that is, in my opinion, a major cause of the reproducibility crisis.&lt;/p&gt;

&lt;p&gt;One piece of evidence is the nature of the cases discussed in the context of the crisis. Reproducibility has been an issue with experiments since the dawn of science, and yet experimental non-reproducibility never shows up in the examples cited. This is not because it is unimportant, but because it is well understood. Experimentalists of all disciplines know what ought to be reproducible in their field, and to which degree, and even the most theoretically minded theoreticians understand that experiments necessarily come with uncertainties. The issues that do show up in the catalogs of non-reproducible results are related to two specific research tools: statistics and computers. Both are recent, and both are routinely used by scientists who do not fully understand them. In other words, their users are consumers of industrial products who lack guidance in their choice of tools and methods.&lt;/p&gt;

&lt;p&gt;Side note: I can almost hear some readers complain that statistics are nothing recent, going back to Arab mathematicians who lived 1000 years ago. You are right. What is recent is the widespread &lt;em&gt;use&lt;/em&gt; of statistics in science. Before computers, statistical methods had to be applied manually, keeping them simple and the datasets small. The kind of statistical inference whose results turn out to be non-reproducible, e.g. in psychology, would not have been possible without computers.&lt;/p&gt;

&lt;p&gt;As an illustration, consider the common use of &lt;em&gt;p&lt;/em&gt;-value thresholds for deciding on significance. Anyone who understands the statistical framework to which &lt;em&gt;p&lt;/em&gt;-values belong (hypothesis testing) agrees that most uses of such thresholds in the scientific literature make no sense. The fact that they are widely used nevertheless thus shows that most people who deal with them, as authors or as reviewers, do not understand the statistical hypothesis testing sufficiently well. And since the abuse of &lt;em&gt;p&lt;/em&gt;-values has been going on for a while, it has now become a de-facto accepted practice, to the point that the people who do understand its absurdity have a hard time being heard. The same can be said about the abuse of journal impact factors for judging the authors of scientific articles, which are a sign of CVs and publication lists becoming industrial products as well.&lt;/p&gt;

&lt;p&gt;The root cause of computational non-reproducibility is an even better illustration of software becoming an industrial product. I noticed that many scientists who have never experienced reproducibility issues themselves find it hard to imagine that they can exist. After all, 2 + 2 is 4, today and tomorrow. What happens when two people obtain different results from &amp;ldquo;the same&amp;rdquo; computation is that they performed in fact different computations (using different software) without being aware of the difference. Software has become ever more complex over the last decades, but software developers have also made an effort to hide this complexity from users - with great success. Most scientists are surprised to learn that when they run that little script sent by a colleague, they are really using hundreds of software packages written (and modified frequently) by hundreds of people over many years with only loose coordination. It&amp;rsquo;s not only those hundreds of packages that are industrial commodities, but even the assembly of all those pieces, for example a Linux distribution.&lt;/p&gt;

&lt;h2 id="what-can-we-do"&gt;What can we do?&lt;/h2&gt;

&lt;p&gt;We can look at the much better understood industrial production of material goods for inspiration for possible solutions. A complex industrial product, such as a car or a television set, comes with a user manual and perhaps an obligation for user training, such as obtaining a driver&amp;rsquo;s license. Moreover, technical norms impose precautions on producers to make their products safe to use by non-experts. Independent experts evaluate products and publish reports that guide consumers in their choice. These approaches can be adapted to scientific software and statistical methods, but that work remains to be done.&lt;/p&gt;

&lt;p&gt;I expect reproducibility to play a major role in this, as a quality label. A reproducible result can still be wrong, but nevertheless reproducibility guarantees the absence of some kinds of common problems. We need additional, complementary quality labels of course, and in fact we have a few, such as the presence of test suites for scientific software, or the existence of provenance metadata for datasets. But this is only the beginning. We do not yet know how to make data and code an industrial product that is safe to use by others, nor do we know how to prepare scientists for working in such an ecosystem. Best practices, even good enough practices, remain to be established.&lt;/p&gt;

&lt;p&gt;Experts will likely be another ingredient of a solution. I suspect that most statistics-related problems could be solved by requiring that every publication making a claim based on statistical significance be validated by a trained statistician. We will have to figure out how to organize this validation. One possibility is to create independent certification agencies, similar to &lt;a href="https://www.cascad.tech/"&gt;cascad&lt;/a&gt; for computational reproducibility, that employ qualified statisticians and deliver validation certificates that will figure prominently in a paper.&lt;/p&gt;

&lt;h2 id="its-not-just-software-and-data"&gt;It&amp;rsquo;s not just software and data&lt;/h2&gt;

&lt;p&gt;As I said above, I have focused on data and code because the computational aspects of science are what I am most familiar with. But industrialization isn&amp;rsquo;t limited to computing. Even the good old journal article is slowly turning into an industrial product. With approaches such as meta-analyses or content mining, scientific papers are being used by people who are not part of the community that their authors belong to, and may thus not have the tacit knowledge shared by that community which might well be necessary to fully appreciate the published results. Interdisciplinary research is also a source of potential misunderstandings due to unshared tacit knowledge.&lt;/p&gt;

&lt;p&gt;We can also see industrialization in the management of science. In fact, the term &amp;ldquo;management&amp;rdquo; in itself implies some form of industrialization. Unfortunately, management principles from the material goods and service industries are being applied uncritically to scientific research, leading to phenomena such as the abuse of the journal impact factor to measure an individual&amp;rsquo;s productivity, or the attribution of budgets based on multiple-year predictions of research outcomes (called &amp;ldquo;grant proposals&amp;rdquo;) that lack any credibility. This suggests that the people who design these management practices consider science itself a commodity, as an industry that can be run just like any other industry. There is, however, a crucial difference: whereas the production of material goods is by necessity based on well-known technologies and processes (otherwise their deployment at scale would be bound to fail), research is all about the unknown. Scientists can describe directions they want to take, but not promise to reach specific goals in the future. Science is intrinsically a bottom-up process, whereas management is about top-down organization.&lt;/p&gt;

&lt;h2 id="open-source-and-open-science"&gt;Open Source and Open Science&lt;/h2&gt;

&lt;p&gt;Back to software, there is one aspect that deserves further discussion: the role of the FOSS (free/open source software) approach that has been gaining traction in research over the last decade, and that has furthermore inspired much of the Open Science movement. The origin of the FOSS movement can be seen as a rebellion against the industrialization of software, which made it difficult to impossible for users to adapt it to their needs. The widely shared story of Richard Stallman&amp;rsquo;s fight against a proprietary printer driver (see &lt;a href="https://poynder.blogspot.com/2006/03/interview-with-richard-stallman.html"&gt;here&lt;/a&gt; for example) is a nice illustration. Initially, the FOSS movement focused on establishing legal means (licenses) to protect software from becoming proprietary. More slowly, and less explicitly, it worked towards a view of software development as something a community does for its own needs, with the ideal that anyone sufficiently motivated should be able to join such a community and participate in the development process. This was a reasonable proposal in the 1980s, when software was simpler and most computer users had by necessity some programming experience.&lt;/p&gt;

&lt;p&gt;Today&amp;rsquo;s situation is very different. Most software has the status of an industrial product for most of its users, whether it&amp;rsquo;s FOSS or not. In theory, anyone can learn anything about FOSS and participate in its evolution at all levels. In practice, the effort is prohibitive for most, and nobody today can envisage understanding all the software they depend on, let alone contributing to its development. As I explained above, it has even become close to impossible to just keep track of which software one depends on. From a user&amp;rsquo;s perspective, the development communities of FOSS projects are industrial software producers just like commercial companies. In a way, FOSS users even have less power because the developer communities have no legal or moral obligations toward their users at all. There are a few cases of institutions that permit users to influence and support the development of FOSS, for example the &lt;a href="http://consortium.pharo.org/"&gt;Pharo consortium&lt;/a&gt; or the &lt;a href="https://www.fondation-inria.fr/"&gt;Inria foundation&lt;/a&gt;, but they are the exception rather than the rule.&lt;/p&gt;

&lt;p&gt;In science, the FOSS ideal of communities producing software for their own use works very well for domain-specific software packages, whose developers are a representative subset of a well-defined scientific community. But infrastructure software that is used across many scientific disciplines will invariably end up being an industrial product for most of its users. This is true for most of the Scientific Python ecosystem, for example, and also for the statistical software universe that has grown around the R language. Note that I am not saying that the FOSS approach has no advantages there. Open source code is very important to ensure the transparency required for making science verifiable. What I am saying is that openness is not enough to ensure that software is a safe-to-use industrial product, nor does it provide a mechanism for keeping a product&amp;rsquo;s evolution in sync with the needs of its user base.&lt;/p&gt;

&lt;p&gt;Whereas the FOSS community has largely remained blind to this issue, the Open Science movement seems to be more aware of the pitfalls of &amp;ldquo;just&amp;rdquo; being open, at least for data. The I and R (interoperability, reusability) in FAIR are the best evidence for this. For now, they remain ideals for which practically usable implementations remain to be defined. Perhaps this will lead to a more careful consideration of reusability for software as well. As with the material goods industries, the key is to recognize users and educators as stakeholders and ensure that their needs are taken into account by producers. Open source communities working on widely used infrastructure software could, for example, adopt a governance model that includes representative non-developing users. Funders of such communities could make such a governance model a condition for funding. But the very first step is creating an awareness of the problem. Development communities should openly state their ambition. It&amp;rsquo;s OK to develop software for use inside a delimited community, but then don&amp;rsquo;t advertise it as easy to use for everyone. It&amp;rsquo;s also OK to aim high and work on general-purpose infrastructure software, but then explain how users can make themselves heard without having to become contributors themselves. Being &amp;ldquo;open&amp;rdquo; is not enough.&lt;/p&gt;</description></item>
  <item>
   <title>The computational notebook of the future (part 2)</title>
   <link>http://blog.khinsen.net/posts/2019/05/09/the-computational-notebook-of-the-future-part-2/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-05-09-the-computational-notebook-of-the-future-part-2</guid>
   <pubDate>Thu, 09 May 2019 12:07:39 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;A while ago I &lt;a href="http://blog.khinsen.net/posts/2019/02/11/the-computational-notebook-of-the-future/"&gt;wrote about my ideas for a successor of today&amp;rsquo;s computational notebooks.&lt;/a&gt; Since then I have made some progress on a prototype implementation, which is the topic of this post. Again I have made a companion &lt;a href="https://vimeo.com/339361206"&gt;screencast&lt;/a&gt; so that you can get a better idea of how all this works in practice.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;As a reminder, the two aspects of today&amp;rsquo;s notebooks (&lt;a href="https://www.wolfram.com/mathematica/"&gt;Mathematica&lt;/a&gt;, &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt;, &lt;a href="https://rmarkdown.rstudio.com/"&gt;R markdown&lt;/a&gt;, &lt;a href="https://orgmode.org/worg/org-contrib/babel/"&gt;Emacs/OrgMode&lt;/a&gt;) that I consider harmful for scientific communication are:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;
  &lt;p&gt;The linear structure of a notebook that forces the narrative to  follow the order of the computation.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;The impossibility to refer to data and code in a notebook from the  outside, and in particular from another notebook, making reuse of  code and data impossible.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Like the demo that I made last time, and which is best qualified as a quick hack, the computational document that I am presenting today is implemented in &lt;a href="https://pharo.org/"&gt;Pharo&lt;/a&gt; and builds on the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt;, which is an innovative development environment designed around the notion of &amp;ldquo;moldable development&amp;rdquo;, which means that developers should be able to adapt their tools to their specific needs with little effort. This is precisely what I have done. The code is &lt;a href="https://github.com/activepapers/activepapers-pharo"&gt;on GitHub&lt;/a&gt; and includes the example document from the demo.&lt;/p&gt;

&lt;p&gt;Contrary to today&amp;rsquo;s notebooks, my computational documents consist of two distinct layers, which I show for an example in the screencast. A &lt;em&gt;workflow layer&lt;/em&gt; consists of &lt;em&gt;scripts&lt;/em&gt; (short pieces of code) that compute &lt;em&gt;datasets&lt;/em&gt; keep track of the data dependencies. The workflow layer can be visualized as a graph. Scripts and datasets make up a standard Pharo object that can be used as a building block in subsequent work, unlike the code and data in today&amp;rsquo;s notebooks. For example, the Pharo expression &lt;code&gt;InfluenzaLikeIllnessInFrance data
absoluteIncidence&lt;/code&gt; yields one of the data frames from my example document and can be used in any type of Pharo code, including code in another document.&lt;/p&gt;

&lt;p&gt;On top of that workflow layer, there is a documentation layer consisting of a Wiki-style multi-page document in which each page can contain code snippets. These code snippets are intended for data presentation (plotting etc.) and for demonstrations (examples, verifications, etc.) They are not accessible from outside their pages, and they cannot change the datasets computed by the workflow. The documentation pages can refer to and include the datasets, the scripts, but also arbitrary other Pharo code. In particular, this allows including library code used by the workflow scripts in the documentation layer, as opposed to today&amp;rsquo;s notebooks for which library code is undocumentable black-box code.&lt;/p&gt;

&lt;p&gt;A third essential element is the &lt;em&gt;playground&lt;/em&gt; attached to the workflow. This is where interactive exploration takes place. Code snippets in the playground can access datasets just like scripts, but they cannot modify them. The playground is meant both for authors and for readers. Authors develop scripts incrementally in the playground, and turn them into scripts (at the click of a button) when they are satisfied. Readers can write code snippets for exploring the data in more detail.&lt;/p&gt;

&lt;p&gt;The code is currently &amp;ldquo;demo quality&amp;rdquo;, so please don&amp;rsquo;t rely on it for your own research. Even the underlying GToolkit library is still advertised as alpha level. There is a reason for calling this the future rather than the present! However, there are a few conclusions that I am already willing to draw from this work:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;
  &lt;p&gt;An authoring environment for computational documents should also  be a more general software development environment. If you have  to change tools for switching from library code to a computational  document or back, you have a technological barrier to overcome  that creates a mental separation between &amp;ldquo;inside&amp;rdquo; and &amp;ldquo;outside&amp;rdquo;,  whereas the science that you want to communicate is on both sides  of your barrier.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;The emphasis on making all code and data explorable that has been  part of Smalltalk culture from the start is highly beneficial for  computational science as well. Notebook environments such as  Jupyter or RStudio feel extremely limited compared to the standard  Pharo environment, let alone the more advanced GToolkit.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;Decomposing the computation into smaller independent scripts  with well-defined interfaces makes it more understandable.  In the traditional linear notebooks, you never know how far  further down a temporary variable will be used. You must  read the code from top to bottom to be sure not to miss  something. Likewise, separating &amp;ldquo;essential&amp;rdquo; computations  on the data from &amp;ldquo;superficial&amp;rdquo; computations such as plotting  makes the overall scientific logic stand out better.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;A good authoring environment must support the full lifecycle of  computer-aided research, starting with interactive exploration and  iterating towards a computational document optimized for the  reader rather than the author. Today&amp;rsquo;s notebooks do not provide  this support by sticking to a linear structure that is  satisfactory only in the initial stages of the lifecycle.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</description></item>
  <item>
   <title>Is reproducibility good for scientific progress? (a paper review)</title>
   <link>http://blog.khinsen.net/posts/2019/04/23/is-reproducibility-good-for-scientific-progress-a-paper-review/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-04-23-is-reproducibility-good-for-scientific-progress-a-paper-review</guid>
   <pubDate>Tue, 23 Apr 2019 12:47:50 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;A few days ago, a discussion in my Twitter timeline caught my attention. It was about a very high-level model for the process of scientific research whose conclusions included the affirmation that reproducibility does not improve the convergence of the research process towards truth. The Twitter discussion set off some alarm bells for me, in particular the use of the term &amp;ldquo;reproducibility&amp;rdquo; in the abstract, without specifying which of its many interpretations and application contexts everybody referred. But that&amp;rsquo;s just the Twitter discussion, let&amp;rsquo;s turn to the more relevant question of what to think of the paper itself (&lt;a href="https://arxiv.org/abs/1803.10118"&gt;preprint on arXiv&lt;/a&gt;).&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The core of the work presented in that paper is a stochastic model for the process of scientific research. There is some phenomenon described by a &amp;ldquo;true&amp;rdquo; mathematical model. Scientists do not know this model, but can obtain data points from it. This is how experiments are described. Scientists do have full access to their own models for reality. At each time step, a scientist generates a new model according to some strategy and evaluates the quality of that model to see if it is &amp;ldquo;better&amp;rdquo; (in a well-defined sense) than the current concensus model of the community. One of the strategies is replication of prior work.&lt;/p&gt;

&lt;p&gt;Such highly simplified high-level models are easy to criticize because of the huge number of simplifying assumptions. And yet, in other branches of science (such as physics), simple toy models have proven to be very useful. In particular, they can help identify mechanisms that are also present in more realistic (and thus more complex) descriptions of the same phenomena. However, toy models require reality checks as well, in the form of validation, even if validation is qualitative rather than quantitative. This is in my opinion one of the weak spots of this paper: validation is limited to a few basic sanity checks. Given the scarcity of empirical data on the scientific process, this isn&amp;rsquo;t really surprising.&lt;/p&gt;

&lt;p&gt;As for the specific issue of reproducibility, the model presented in the paper has a major weakness in that it completely ignores the issues that motivate reproducibility checks and replication studies in real life. Scientists, like all humans, are prone to mistakes and biases. The collective process of scientific research therefore includes verification steps that reduce the impact of mistakes and bias. Peer review is probably the best known one, but reproducibility checks and replication studies fall into this category as well. It is then not surprising that a model without mistakes and bias predicts little utility for verification measures.&lt;/p&gt;

&lt;p&gt;However, this is merely a criticism of the current proposed model. It should be possible to include mistakes and bias without profound changes to the basic idea of modelling scientific research by a stochastic process. Confirmation bias is perhaps the simplest case: Let authors of original research overestimate the benefit of their work (as part of the evaluation criterion S in the paper) and replicators underestimate it. As for mistakes, a crude technique would be to let some percentage of scientists generate two new models, evaluate the first one, but report the second one as having been tested. Mistakes detected in a replication study would then lead to erasure of the replicated study from the process of concensus formation.&lt;/p&gt;</description></item>
  <item>
   <title>The computational notebook of the future</title>
   <link>http://blog.khinsen.net/posts/2019/02/11/the-computational-notebook-of-the-future/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2019-02-11-the-computational-notebook-of-the-future</guid>
   <pubDate>Mon, 11 Feb 2019 13:29:24 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Regular readers of this blog may have noticed that I am not very happy with today&amp;rsquo;s state of computational notebooks, such as they were pioneered by Mathematica and popularized by more recent free incarnations such as &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt;, &lt;a href="https://rmarkdown.rstudio.com/"&gt;R markdown&lt;/a&gt;, or &lt;a href="https://orgmode.org/worg/org-contrib/babel/"&gt;Emacs/OrgMode&lt;/a&gt;. In this post and the &lt;a href="https://peervideo.net/videos/watch/9ed70819-6271-439f-b392-54f34b73c124"&gt;accompanying screencast&lt;/a&gt; (my first one!), I will explain what I dislike about today&amp;rsquo;s notebooks, and how I think we can do better.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;There are two aspects of notebooks that I consider harmful for scientific communication:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;The linear structure of a notebook that forces the narrative to follow the order of the computation.&lt;/li&gt;
 &lt;li&gt;The impossibility to refer to data and code in a notebook from the outside, and in particular from another notebook, making reuse of code and data impossible.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;If you look at a traditional scientific article, or technical report, you will notice that its narrative is structured according to a high-level view of the work. It starts by describing the context of the work, then its goals and a very brief summary of the methods, and right after that it presents results and discusses them. Technical details are only discussed afterwards, once the reader understands why they actually matter. With today&amp;rsquo;s notebooks, the technical details come first: a typical data analysis starts with cleanup and preprocessing steps, and therefore they also come first in the narrative.&lt;/p&gt;

&lt;p&gt;An unpleasant side effect of the &amp;ldquo;narrative follows computation&amp;rdquo; principle is that some technical details actually cannot be discussed adequately. Scientific methods implemented in software libraries can be summarized in plain English, but the code is elsewhere, managed by a different toolset, and cannot be shown to the reader.&lt;/p&gt;

&lt;p&gt;This makes the transition to the second problematic aspect: there is no way to refer to or reuse any specific part of a notebook. Neither the code nor the computed results are accessible from the outside. And that also makes it impossible to build up useful libraries from notebooks.&lt;/p&gt;

&lt;p&gt;So far for the criticism - now let&amp;rsquo;s make it constructive. At this point, you should watch the &lt;a href="https://peervideo.net/videos/watch/9ed70819-6271-439f-b392-54f34b73c124"&gt;screencast&lt;/a&gt; before reading on. In the screencast, I show a simple data analysis both as a Jupyter notebook and as a demo prototype for what I consider the notebook of the future. This prototype is built using the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt;, a very innovative software development environment for &lt;a href="https://pharo.org/"&gt;Pharo&lt;/a&gt;, which is a modern descendant of &lt;a href="https://en.wikipedia.org/wiki/Smalltalk"&gt;Smalltalk&lt;/a&gt;. If you want to play with this yourself, the code is &lt;a href="https://github.com/khinsen/computational-documents-with-gtoolkit/"&gt;on GitHub&lt;/a&gt;. It&amp;rsquo;s really just a demo, because the simplistic approach to organizing the computation that I have used there would not scale to real-life computations (it does a lot of needless recomputation). My plan is to implement the &lt;a href="https://www.activepapers.org/"&gt;ActivePapers&lt;/a&gt; approach for managing the computations. GToolkit is alpha software as well. So none of this is ready for prime time, but it does show that better notebooks are possible.&lt;/p&gt;

&lt;p&gt;Unlike today&amp;rsquo;s notebooks, which are a sequence of code snippets and documentation paragraphs, the computational documents of my demo are &lt;em&gt;objects&lt;/em&gt; in the sense of object-oriented programming. Each document contains code, input data, and computed data, which can be accessed from the outside and thus reused in client code. The narrative is merely an additional view into these items, which can present and discuss them in any order that seems suitable for explaining the work. Like with scientific articles, the narrative is typically written in the final stages of the work, once the basic code skeleton is working. In the case of my demo, I started out writing the two Pharo classes, before even installing GToolkit which was a bit unstable at the time.&lt;/p&gt;

&lt;p&gt;Note that this &amp;ldquo;one job, one object, one narrative&amp;rdquo; approach has a beneficial side effect in encouraging people to do each job well, rather than just well enough for going on with the next job. My Jupyter/Python version of the data analysis only extracts the minimum information required from the input dataset, without even mentioning what else is in there. The GToolkit/Pharo version provides a complete description of the dataset, including the data that is not used at all in the second document that describes the analysis.&lt;/p&gt;

&lt;p&gt;Finally, there are other interesting aspects of GToolkit (and Pharo) for computational science, but I will leave them for future posts. I will just mention that the &amp;ldquo;inspectors&amp;rdquo; (a term familiar to every Smalltalk developer but probably unknown to anyone else) are easily extensible. Adding a pane that provides yet another view of the document is a matter of writing a couple of lines of Pharo code. It&amp;rsquo;s as if you could implement a new widget for Jupyter in a few lines of Python code right in your notebook.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: There&amp;rsquo;s a workaround for embedding figures (thanks to Tudor Gîrba for the hint!), which you can find in the current code version on GitHub.&lt;/p&gt;</description></item>
  <item>
   <title>Exploring Pharo</title>
   <link>http://blog.khinsen.net/posts/2018/12/19/exploring-pharo/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2018-12-19-exploring-pharo</guid>
   <pubDate>Wed, 19 Dec 2018 05:26:08 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;One of the more interesting things I have been playing with recently is &lt;a href="http://www.pharo.org/"&gt;Pharo&lt;/a&gt;, a modern descendent of Smalltalk. This is a summary of my first impressions after using it on a &lt;a href="https://github.com/khinsen/leibniz-pharo/"&gt;small (and unfinished) project&lt;/a&gt;, for which it might actually turn out to be very helpful.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The first time I read about Smalltalk was in the &lt;a href="https://archive.org/details/byte-magazine-1981-08"&gt;August 1981 issue of Byte magazine&lt;/a&gt;. Back then, I was a high school student and I had just invested my savings into my first home computer with characteristics typical for the time: Z80 processor, 16 KB of memory, Microsoft Basic, data storage on cassette tapes. From that perspective, Smalltalk was a utopia. The revolutionary aspect of Smalltalk was its design as an integrated computing system that combined a language, a huge standard library, a development environment, and perhaps most of all a graphical user interface (GUI), which in fact was the ancestor of all of today&amp;rsquo;s desktop-style GUIs. As a consequence, it required a high-quality graphics display, a mouse, and plenty of CPU power. None of that was available in commodity hardware.&lt;/p&gt;

&lt;p&gt;In 1995, a friend passed me a floppy disk with Smalltalk&amp;ndash;80 for the Atari ST family, and I could finally lay my hands on a working Smalltalk system. By then I had an Atari TT with the awesome big high-resolution black-and-white screen that was available for it. Just perfect for Smalltalk. I was very impressed by the system, which in many respects was superior to the Atari&amp;rsquo;s native TOS/GEM combo, and even to the Unix workstations I had in the lab. But I couldn&amp;rsquo;t actually use it for anything productive, because Smalltalk lived in a separate universe, unable to access any file on my hard disk. It wasn&amp;rsquo;t more than an impressive demo of what computing could be like.&lt;/p&gt;

&lt;p&gt;I have faint memories of playing with &lt;a href="http://www.squeak.org/"&gt;Squeak&lt;/a&gt; a couple of years later, but I found its flashy colors and toy-inspired aesthetics so unpleasant that I didn&amp;rsquo;t go very far. Pharo is actually a fork of Squeak that evolved into a different direction, with a more sober design that is much more to my liking. More importantly, some of the on-going developments in the Pharo community (in particular the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt;) are much in line with my recent interest in the &lt;a href="https://peerj.com/articles/cs-158/"&gt;human-computer interface of computational science&lt;/a&gt;. The 2018 session of the &lt;a href="https://mooc.pharo.org/"&gt;Pharo MOOC&lt;/a&gt; was thus a good occasion to take a more serious look at this up-to-date incarnation of Smalltalk. The MOOC does a pretty good job at introducing Pharo to people with various interests, and it even includes some explanations of the internal workings of Pharo (look for the &amp;ldquo;black magic&amp;rdquo; label).&lt;/p&gt;

&lt;p&gt;As a language, Smalltalk was revolutionary in the 1980s, but no longer today because many now better known languages have drawn on it for inspiration. If you know Python, for example, then Pharo won&amp;rsquo;t surprise you much beyond the obvious and important syntactical differences. On the plus side, that means it is not much effort to do a first project in Pharo when coming from a Python background. But it also means that there isn&amp;rsquo;t much to be gained from learning Pharo if you look at it as just another programming language. The really interesting part is not the language, but the user interface of Pharo the computing platform.&lt;/p&gt;

&lt;p&gt;Pharo belongs to a rare species of computing environments that I think is best described by the label &amp;ldquo;explorable&amp;rdquo;. All of Pharo is implemented in Pharo itself, and all the source code is there for you to inspect and modify. But it&amp;rsquo;s not just the code that is inspectable, it&amp;rsquo;s all the objects that exist in memory. You can, for example, evaluate &lt;code&gt;Array instanceCount&lt;/code&gt; to find out how many arrays exist at the moment (213464 when I tried). You can then obtain an arbitrarily chosen instance with &lt;code&gt;Array someInstance&lt;/code&gt; and open a graphical inspector using &lt;code&gt;Array someInstance inspect&lt;/code&gt;. You can also modify that array, without any idea of where it is used and for what, and thus wreak havoc with your system. For a more thorough approach to breaking Pharo, one of my favorites is &lt;code&gt;true become: false&lt;/code&gt;, which replaces &lt;code&gt;true&lt;/code&gt; by &lt;code&gt;false&lt;/code&gt; and vice versa everywhere in the system. Pharo reacts much like I&amp;rsquo;d expect a human logician to react: it freezes instantly.&lt;/p&gt;

&lt;p&gt;The complete state of a Pharo system, including all code and all objects, and thus even GUI elements such as open windows, can be saved with a click in what is called an image. This is obviously very convenient, but should not be used as the only strategy for storing code because images are fragile, as my example above illustrates. Consider an image your development environment rather than your code repository. In fact, Pharo supports and encourages storing code in Git repositories.&lt;/p&gt;

&lt;p&gt;It is important to understand that explorability is not an accidental feature of Pharo (and other Smalltalk derivates), but has been a design goal from the start. Those interested in the history of this idea should look at &lt;a href="https://en.wikipedia.org/wiki/Dynabook"&gt;Alan Kay&amp;rsquo;s Dynabook concept&lt;/a&gt; and then take another step back in history to &lt;a href="http://thedemo.org/"&gt;Doug Englebart&amp;rsquo;s &amp;ldquo;Mother of all Demos&amp;rdquo;&lt;/a&gt;. The motivation behind all these developments is to make computing a tool not for performing tasks, but for augmenting human intellectual abilities. That goal is, unfortunately, very rare. In fact, the only other system I know of that was designed to be explorable is &lt;a href="http://www.emacs.org/"&gt;Emacs&lt;/a&gt;, also with the goal of maximally empowering users. Once you look beyond superficialities, Pharo and Emacs are actually quite similar. Both are built around a high-level programming language with a rich library, a user-interface framework, and development tools with inspection capabilities. Emacs then comes with a text editor as the default application at startup. Pharo has no such default application, meaning that it is pretty useless before you write some code of your own. That is probably the main reason why Emacs became so much more popular - people use it as a text editor and only later, if ever, discover its empowering features.&lt;/p&gt;

&lt;p&gt;Explorability is what interests me most in Pharo, because I believe that computational science sorely needs it, and that existing interactive interfaces such as REPLs or notebooks are far from sufficient. They impose a linear thread of exploration, whereas I want to be able to go off on a tangent, dig in deeper into a model, compare two datasets side-by-side, etc. Notebooks are also rigid exploration environments which can be extended only with major effort, if at all. Pharo offers a much richer exploration environment, and makes it easy to adapt to problem-specific needs (another reference to the &lt;a href="https://gtoolkit.com/"&gt;Glamorous Toolkit&lt;/a&gt; is compulsory here). The snag is that Pharo doesn&amp;rsquo;t offer much support for working with scientific data or scientific models (though I must admit that I haven&amp;rsquo;t checked out &lt;a href="https://github.com/PolyMathOrg/PolyMath"&gt;PolyMath&lt;/a&gt; yet). There are people who use Pharo for computational science (see e.g. &lt;a href="https://github.com/UMMISCO/kendrick"&gt;this epidemiology simulation platform&lt;/a&gt;), so I suppose that there are useful tools I simply haven&amp;rsquo;t looked at yet.&lt;/p&gt;

&lt;p&gt;One power tool that I have already discovered (and explored interactively in Pharo) is the visualization library &lt;a href="http://agilevisualization.com/"&gt;Roassal&lt;/a&gt;. It may superficially resemble various visualization libraries for JavaScript, but the big difference is that it integrates with the Pharo development and exploration tools. It is very easy to add a visualization pane to Pharo&amp;rsquo;s object inspector and get a graphical view on your objects in addition to the standard browser-type interface for accessing an object&amp;rsquo;s internals. And that means that you can easily use visualization as a tool in designing, implementing, and debugging code. It also helps a lot that the visualizations are themselves interactive. You can make them react to clicks, drags, and other events, and thus turn them into a user interface to your classes. For those familiar with Jupyter notebooks, it&amp;rsquo;s as if you could implement interactive widgets in a few lines of Python code stored in your notebook.&lt;/p&gt;

&lt;p&gt;I should perhaps say something about Pharo as a software development environment, but that aspect has been covered before by others in much more depth than I would do it myself. The demos in the Pharo MOOC are a good introduction, but for an overview of the possibilities, nothing beats &lt;a href="https://www.youtube.com/watch?v=baxtyeFVn3w"&gt;Aditya Siram&amp;rsquo;s recent demo&lt;/a&gt; aimed at adepts of functional programming languages.&lt;/p&gt;

&lt;p&gt;After all that praise, I have to add some caveats. First of all, the Pharo community is tiny compared to, say, Python&amp;rsquo;s, and therefore the choice in domain-specific libraries is rather small. Next, Pharo development moves on at a rapid pace, with the main consequence that nearly all available documentation is outdated, and what&amp;rsquo;s left is often an update for insiders rather than an introduction for newcomers. No matter how explorable a system is, you need some higher-level information to use it productively, if only to know the jargon that permits you to start searching for stuff. As an example, when I tried to figure out how package dependency management works, I had to ask on the &lt;a href="http://lists.pharo.org/mailman/listinfo/pharo-users_lists.pharo.org"&gt;Pharo user mailing list&lt;/a&gt; to learn that the keyword to look for is &amp;ldquo;baseline&amp;rdquo;. The three books &lt;a href="http://books.pharo.org/updated-pharo-by-example/"&gt;Pharo by Example&lt;/a&gt;, &lt;a href="http://deepintopharo.com/"&gt;Deep into Pharo&lt;/a&gt;, and &lt;a href="http://books.pharo.org/enterprise-pharo/"&gt;Enterprise Pharo&lt;/a&gt; are probably the best place to start looking for introductory essays, but even they are two versions behind the current one.&lt;/p&gt;

&lt;p&gt;Finally, let me anticipate a reaction that I expect regular readers of this blog to have. How is it possible for someone who underlines the importance of reproducibility in every second post to say something positive about a system that relies on persistent state to the point that it cannot even be bootstrapped from its own source code? There are a couple of replies. Most importantly, reproducibility is not what I am looking for in Pharo. Every system has its good and bad sides, and I am turning to Pharo for its good sides, explorability and user interfaces. Second, the Pharo developers are working on this. And finally, decades of dealing with persistent yet fragile system images have lead the Smalltalk community to figure out ways to cope with the resulting problems (e.g. changesets) that may be worth studying for inspiration. Computational science suffers from a fundamental tension between the short-term need for interactivity and the long-term need for reproducibility. So far, no one has found a satisfying answer, so it&amp;rsquo;s worth looking for inspiration in unusual places.&lt;/p&gt;</description></item>
  <item>
   <title>Knowledge distillation in computer-aided research</title>
   <link>http://blog.khinsen.net/posts/2018/10/21/knowledge-distillation-in-computer-aided-research/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2018-10-21-knowledge-distillation-in-computer-aided-research</guid>
   <pubDate>Sun, 21 Oct 2018 16:28:39 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;There is an important and ubiquitous process in scientific research that scientists never seem to talk about. There isn&amp;rsquo;t even a word for it, as far as I now, so I&amp;rsquo;ll introduce my own: I&amp;rsquo;ll call it &lt;em&gt;knowledge distillation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In today&amp;rsquo;s scientific practice, there are two main variants of this process, one for individual research studies and one for managing the collective knowledge of a discipline. I&amp;rsquo;ll briefly present both of them, before coming to the main point of this post, which is the integration of &lt;em&gt;digital&lt;/em&gt; knowledge, and in particular software, into the knowledge distillation process.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The first variant is performed by individual researchers or closely collaborating teams who, starting from the raw information of their lab notebooks, describing methods applied and results obtained, write a journal article summarizing all of this information into an illustrated narrative that is much easier to digest for their fellow scientists. This narrative contains what the authors consider the essence of their work, leaving out what they consider technical details. Moreover, the narrative places the work into its wider scientific context. In a second step, the authors condense the article into an even smaller abstract, supposed to tell readers at a glance if the article is of interest to them without going into any details. This process can be illustrated as a pyramid:&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="./knowledge-pyramid-1.svg" alt="" /&gt;
 &lt;p class="caption"&gt;&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;At the bottom we have all the gory details, one level up the distilled version for communication, and at the top the minimal summary for first contact with a potential reader. It is not uncommon to have an additional layer between the bottom two, often published as &amp;ldquo;supplementary material&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Whereas authors work from the bottom to the top of this pyramid, readers work down from the top, gaining a more detailed understanding at each step. Until not so long ago, this was a two-step process: after the abstract, they could move on to the paper, but after that they had to contact the authors for obtaining more details, and the authors might well not care to reply. The Open Science movement has made some progress in pushing for more transparency by making deeper information layers available for critical inspection, in particular raw datasets and the source code for the software used to process them. The situation is very much in flux as various scientific disciplines are working out which information can and should be shared, and how. The maximal level of openness is known as &lt;a href="https://en.wikipedia.org/wiki/Open-notebook_science"&gt;Open Notebook science&lt;/a&gt;, which basically means making the whole pyramid public. Note, however, that giving access to the base of pyramid does not make the knowledge distillation steps superfluous. Readers would succumb to information overload if exposed to all the details without a proper introduction in the form of distilled knowledge. In fact, &lt;em&gt;most&lt;/em&gt; readers don&amp;rsquo;t want to anything else than the distilled version.&lt;/p&gt;

&lt;p&gt;The second variant of knowledge distillation is performed collectively by domain experts who summarize the literature of their field into review articles and then into monographs or textbooks for students. The pyramid diagram is very similar to the first variant&amp;rsquo;s:&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="./knowledge-pyramid-2.svg" alt="" /&gt;
 &lt;p class="caption"&gt;&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;It&amp;rsquo;s really just the same process at another scale: knowledge transfer about a discipline, rather than about a specific study.&lt;/p&gt;

&lt;p&gt;So far for good old science - let&amp;rsquo;s move to the digital age. The base of our first pyramid now contains code and digital datasets. Some of the code was written by the authors of the study for this specific project and typically takes the form of scripts, workflows, or notebooks. This is complemented by the dependencies of this project-specific code - see my &lt;a href="http://blog.khinsen.net/posts/2017/01/13/sustainable-software-and-reproducible-research-dealing-with-software-collapse/"&gt;post on software collapse&lt;/a&gt; for an analysis of the full software stack. Full openness requires making all of this public, with computational reproducibility serving as a success indicator. If other researchers can re-run the software and get the same results, they possess all the information one could possibly ask for, from a computational point of view.&lt;/p&gt;

&lt;p&gt;But as with Open Notebook science, making all the details open is not sufficient. Readers will again succumb to information overload when exposed to a complex software stack and digital datasets whose precise role in the study is not clear. Information overload is even a much more serious problem with software because the amount of detail that software source code contains is orders of magnitude bigger than what can be written down in a lab notebook.&lt;/p&gt;

&lt;p&gt;So how do we distill the scientific knowledge embedded in software? The bad news is that we don&amp;rsquo;t yet have any good techniques. What we find in journal articles when it comes to describing computational methods is very brief summaries in plain English, closer to the abstract level than to the journal article level. As a consequence, computational methods remain impenetrable to the reader who does not have prior experience with the software that has been applied. There is no way to work down the pyramid, readers have to acquire the base level skills on their own. Worse, there is no way to stop at the middle level of the pyramid and yet have a clear understanding of what is going on.&lt;/p&gt;

&lt;p&gt;The recent years have seen a flurry of research and development concerning the publication of software and computations. One main focus has been the reproducibility of results, another the sustainability of scientific software development, and a third one the readability of computational analyses. This last focus has most notably led to the development of computational notebooks (such as Jupyter, Rmarkdown, Emacs/Org-mode and many more), which embed code and results in a narrative providing context and explanations. Notebooks are occasionally put forward as &amp;ldquo;the paper of the future&amp;rdquo;, but in view of the knowledge pyramid, that&amp;rsquo;s not what they are. They are closer to the digital age equivalent of lab notebooks, especially when combined with version control to capture the time evolution of their contents. The real paper of the future must contain a &lt;em&gt;distilled&lt;/em&gt; version of the source code.&lt;/p&gt;

&lt;p&gt;It is interesting to examine why notebooks have been so successful in some scientific domains. First of all, they are a much better human-readable presentation of source code than anything we had before, with the exception of the related idea of literate programming which I expect to see a come-back as well. Next, in domains where computational studies tend to be linear sequences of well-known standard operations, such as statistical analyses, the notebook is very similar to a distilled computational protocol, because the technical details are mostly hidden in libraries. These libraries also contain significant scientific knowledge, but because these methods are well-known, they have in a way been distilled in the form of textbooks.&lt;/p&gt;

&lt;p&gt;More generally, though, notebooks contain both too little and too much information to qualify as distilled descriptions of computational studies. Too little because much scientific knowledge is hidden in the notebook&amp;rsquo;s dependencies, which are not documented at the same level of readability (which is why I believe that literate programming has a future). Too much because they still expose technical details to the reader that is more a hindrance than a help for understanding.&lt;/p&gt;

&lt;p&gt;How, then, should the paper of the future present distilled computational knowledge? I see three main requirements:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;It must be possible to explain and discuss individual models, approximations, or algorithms without the constraints of an efficient working implementation.&lt;/li&gt;
 &lt;li&gt;These models, approximations, and algorithms must be presented in a sufficiently precise form that automatic verification procedures can ensure that the source code at the base level of the pyramid actually implements them.&lt;/li&gt;
 &lt;li&gt;Suitable user interfaces must allow a reader to explore these models, approximations, and algorithms through concrete examples.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;The first requirement says that clarity of exposition must take absolute precedence over any technical considerations of software technology. The intrinsic complexity of computational methods makes understanding hard enough, so everything possible must be done to keep accidental complexity out of the way.&lt;/p&gt;

&lt;p&gt;The second requirement ensures that the conformity between the distilled and the detailed representations of a computational protocol can be verified by computers rather than by humans. Humans aren&amp;rsquo;t very good at checking that two complex artifacts are equivalent.&lt;/p&gt;

&lt;p&gt;The third requirement is motivated by the observation that a real understanding of a computational method, which is usually too lengthy to be actually performed manually, requires both reading code and observing how it processes simple test cases. Observation is not limited to the final outcome, it may well be necessary to provide access to intermediate results.&lt;/p&gt;

&lt;p&gt;To get an idea of what &amp;ldquo;suitable user interfaces&amp;rdquo; might look like, it&amp;rsquo;s worth looking at the &lt;a href="https://explorabl.es/"&gt;explorable explanations&lt;/a&gt; and the &lt;a href="http://www.complexity-explorables.org/"&gt;Complexity Explorables&lt;/a&gt; Web sites. Note, however, that none of these exploration user interfaces provide easy access to a precise formulation of the underlying models or algorithm. They exist in the form of JavaScript source code embedded in the Web site, but that&amp;rsquo;s not exactly a reader-friendly medium of expression. Another interesting line of development is happening in the &lt;a href="https://pharo.org/"&gt;Pharo&lt;/a&gt; community (Pharo being a modern descendent of Smalltalk), e.g. the idea of &lt;a href="http://scg.unibe.ch/research/moldableinspector"&gt;moldable inspectors&lt;/a&gt;, which are user interfaces specifically designed to explore a particular kind of object, which in the O-O tradition combines code and data.&lt;/p&gt;

&lt;p&gt;Back to requirements 1 and 2: we want a precise and easily inspectable description that can be embedded into an explanatory narrative. We also want to be sure that it actually corresponds to what the user interface lets us explore, and to what the software implementation applies efficiently to real-world problems. I am not aware of any existing technology that can fulfill this role, although there many that were designed with somewhat different goals in mind that can serve as guidelines, in particular the various &lt;a href="https://en.wikipedia.org/wiki/Modeling_language"&gt;modeling&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Specification_language"&gt;specification languages&lt;/a&gt;.&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="./knowledge-pyramid-3.svg" alt="" /&gt;
 &lt;p class="caption"&gt;&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;My own research into this problem had led to the concept of &lt;a href="http://sjscience.org/article?id=527"&gt;digital scientific notations&lt;/a&gt;, and I am currently designing such a notation for physics and chemistry, called &lt;a href="https://github.com/khinsen/leibniz"&gt;Leibniz&lt;/a&gt;. A &lt;a href="https://peerj.com/articles/cs-158/"&gt;first report&lt;/a&gt; on this research has been published earlier this year. Leibniz is mainly inspired by traditional mathematical notation concerning the way it is embedded into a narrative, and from specification languages in terms of semantics. Some relevant features of Leibniz for expressing distilled knowledge are&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;
  &lt;p&gt;Its highly declarative nature. Leibniz code consists of short declarations that can be written down in (nearly) arbitrary order, making them easy to embed into a narrative, much like mathematical expressions and equations.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;Its foundation in term rewriting (the same foundation adopted by most computer algebra systems). Among other advantages, this allows Leibniz code to concentrate on one aspect of a model or algorithm while leaving other aspects unspecified.&lt;/p&gt;&lt;/li&gt;
 &lt;li&gt;
  &lt;p&gt;Its restriction to a single universal (but often inefficient) data structure.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;These features mainly address requirement 1. As for requirement 2, Leibniz uses XML for its syntax and has very simple semantics, making it easy to write libraries that read and execute Leibniz code which in turn make it easy to integrate Leibniz into scientific software of all kinds. Only Leibniz development environments have to deal with the more complex user-facing syntax requiring a specific parser.&lt;/p&gt;

&lt;p&gt;Leibniz does not try to address requirement 3, but since it meets requirement 2, it doesn&amp;rsquo;t get in the way of people wishing to build exploration and inspection user interfaces for Leibniz-based models and algorithms.&lt;/p&gt;

&lt;p&gt;Leibniz is still very much experimental, and I am not at all sure that it will turn out to be useful in its current form. In fact, I am almost certain that it will require modification to be of practical use. If that doesn&amp;rsquo;t scare you off, have a look at the &lt;a href="http://khinsen.net/leibniz-examples/"&gt;example collection&lt;/a&gt; to get an idea of what Leibniz can do and what it looks like. Feedback of any kind is more than welcome!&lt;/p&gt;</description></item>
  <item>
   <title>Literate computational science</title>
   <link>http://blog.khinsen.net/posts/2018/07/26/literate-computational-science/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2018-07-26-literate-computational-science</guid>
   <pubDate>Thu, 26 Jul 2018 14:44:31 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;Since the dawn of computer programming, software developers have been aware of the rapidly growing complexity of code as its size increases. Keeping in mind all the details in a few hundred lines of code is not trivial, and understanding someone else&amp;rsquo;s code is even more difficult because many higher-level decisions about algorithms and data structures are not visible unless the authors have carefully documented them and keep those comments up to date.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;The main angle of attack to keep software source code manageable has been the development of ever more sophisticated programming languages and development paradigms, but it is not the only one. Another approach was initiated by Donald Knuth&amp;rsquo;s invention of &lt;a href="http://literateprogramming.com/"&gt;literate programming&lt;/a&gt;. Its basic idea is to invert the roles of code and documentation. Rather than adding doxumentation as annotations to the code, literate programming puts an explanatory narrative about the software at the center of the software author&amp;rsquo;s attention. Code snippets are embedded into this narrative, much like mathematical formulas are embedded into scientific articles and textbooks.&lt;/p&gt;

&lt;p&gt;Literate programming never gained much popularity, for reasons that, to the best of my knowledge, have never been explored systematically. Insufficient tool support is often cited as an obstacle, but I suspect that the mismatch between the structure of the narrative and the language-imposed structure of the code is equally problematic. Programmers need to name code blocks and then assemble them into valid source code by hand. My own experience is that it&amp;rsquo;s usually easier to write and test the code first and then re-create it as a literate program, but this doesn&amp;rsquo;t lead to code that naturally fits the narrative.&lt;/p&gt;

&lt;p&gt;The main argument in support of this suspicion is the much higher popularity of a variant of literate programming that both adds and removes features compared to Knuth&amp;rsquo;s original system. Computational notebooks (implemented e.g. by &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt;) document a computation rather than a piece of software. In addition to code, they embed input data and results into the narrative, but they also restrict code to a linear assembly of code cells executed in sequence. This limitation removes the need to name and assemble code blocks.&lt;/p&gt;

&lt;p&gt;An idea I have been exploring recently is to take another step towards letting the explanatory narrative take center stage, by designing a formal language specifically for embedding into such a narrative. However, my language called &lt;a href="https://github.com/khinsen/leibniz"&gt;Leibniz&lt;/a&gt; is not a programming language. I call it a digital scientific notation to emphasize its intended use in the documentation of scientific models and methods, but in terms of computer science terminology it is a &lt;a href="https://en.wikipedia.org/wiki/Specification_language"&gt;specification language&lt;/a&gt; designed for models expressed in terms of equations and algorithms. Leibniz code &lt;em&gt;must&lt;/em&gt; be embedded into a narrative, although the Leibniz authoring environment also extracts a machine-readable version as an XML file for easy processing by scientific software.&lt;/p&gt;

&lt;p&gt;For getting an overview of Leibniz, I suggest to look first at a &lt;a href="http://khinsen.net/leibniz-examples/examples/leibniz-by-example.html"&gt;simple example&lt;/a&gt;, and then read my &lt;a href="https://peerj.com/articles/cs-158/"&gt;paper&lt;/a&gt; describing Leibniz and the problems it is designed to solve, which just appeared in PeerJ CompSci (Open Access like all of PeerJ). The explanations in the paper should prepare you for a look at the currently &lt;a href="http://khinsen.net/leibniz-examples/examples/mass-on-a-spring.html"&gt;most extensive example&lt;/a&gt;, which documents, for a toy problem, the full path of assumptions and approximations that lead from a theoretical framework (Newton&amp;rsquo;s equations of motion) to a numerical algorithm, with all models along the way being machine-readable.&lt;/p&gt;

&lt;p&gt;As the paper explains, Leibniz is best described as a research prototype at the current stage. It has known limitations that make its application to complex real-world problems a bit challenging. However, I am confident that these limitations can be overcome, and that Leibniz will be suitable for a wide range of scientific models and methods, starting with mathematical equations and ending with literate workflows. As Silicon Valley startups would say, make sure you won&amp;rsquo;t be left behind by the Leibniz revolution!&lt;/p&gt;</description></item>
  <item>
   <title>Scientific software is different from lab equipment</title>
   <link>http://blog.khinsen.net/posts/2018/05/07/scientific-software-is-different-from-lab-equipment/?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-blog-khinsen-net:-posts-2018-05-07-scientific-software-is-different-from-lab-equipment</guid>
   <pubDate>Mon, 07 May 2018 07:40:35 UT</pubDate>
   <author>Konrad Hinsen</author>
   <description>
&lt;p&gt;My most recent paper submission (&lt;a href="https://peerj.com/preprints/26633/"&gt;preprint&lt;/a&gt; available) is about improving the verifiability of computer-aided research, and contains many references to the related subject of reproducibility. A reviewer asked the same question about all these references: isn&amp;rsquo;t this the same as for experiments done with lab equipment? Is software worse? I think the answers are of general interest, so here they are.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;First of all, an inevitable remark about terminology, which is still far from standardized (see &lt;a href="https://arxiv.org/abs/1802.03311"&gt;this preprint&lt;/a&gt; and &lt;a href="https://doi.org/10.3389%2Ffninf.2017.00076"&gt;this article&lt;/a&gt; for two recent contributions to the controversy). I will use the term &amp;ldquo;computational reproducibility&amp;rdquo; in its historically first sense introduced by Claerbout in 1992, because it seems to me that this is currently the dominant usage. &lt;em&gt;Reproducing&lt;/em&gt; a computation thus means running the same software on the same data, though it&amp;rsquo;s usually done by a different person using a different computer. In contrast, &lt;em&gt;replication&lt;/em&gt; refers to solving the same problem using different software. This terminological subtlety matters for the following discussion, because experimental reproducibility is actually more similar to replicability, rather than reproducibility, in the computational case.&lt;/p&gt;

&lt;p&gt;There are two aspects in which I think scientific software differs significantly from lab equipment:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;Its characteristics as a human-made artifact&lt;/li&gt;
 &lt;li&gt;Its role in the process of doing science.&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id="software-is-more-complex-and-less-robust-than-lab-equipment"&gt;Software is more complex and less robust than lab equipment&lt;/h2&gt;

&lt;p&gt;The first point I raised in my paper is the epistemic opacity of automated computation. Quote:&lt;/p&gt;

&lt;blockquote&gt;
 &lt;p&gt;The overarching issue is that performing a computation by hand, step by step, on concrete data, yields a level of understanding and awareness of potential pitfalls that cannot be achieved by reasoning more abstractly about algorithms. As one moves up the ladder of abstraction from manual computation via writing code from scratch, writing code that relies on libraries, and running code written by others, to having code run by a graduate student, more and more aspects of the computation fade from a researcher&amp;rsquo;s attention. While a certain level of epistemic opacity is inevitable if we want to delegate computations to a machine, there are also many sources of accidental epistemic opacity that can and should be eliminated in order to make scientific results as understandable as possible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The reviewer asks: isn&amp;rsquo;t this the same as when doing experiments using lab equipment constructed by somebody else? My answer is no.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do a little thought experiment, introducing Alice and Bob as virtual guinea pigs. Alice is an experienced microscopist, Bob is an experienced computational scientist. We give Alice a microscope she hasn&amp;rsquo;t seen before, and ask her to evaluate if it is suitable for her research. We give Bob a simulation program (with source code and documentation) that he hasn&amp;rsquo;t seen before, and ask him the same question.&lt;/p&gt;

&lt;p&gt;My expectation is that Alice will go off an do some tests with samples that she knows well, and perhaps do some measurements on the microscope. After that, she will tell us for which aspects of her work she can use this new microscope. Meanwhile, Bob will be scratching his head while trying to figure out how to deal with our question.&lt;/p&gt;

&lt;p&gt;One reason for the difference is that a microscope is a much simpler artifact than a simulation program. While it is certainly difficult to design and produce a good microscope, from a user&amp;rsquo;s perspective its characteristics can be described by a handful of parameters, and its quality can be evaluated by a series of test observations. Software, on the contrary, can do almost anything. A typical simulation program has lots of options, whose precise meaning isn&amp;rsquo;t always obvious from its documentation. More importantly, no two simulation programs have identical options. Even the most experienced user of simulation software A falls back to near-novice status when given simulation software B.&lt;/p&gt;

&lt;p&gt;A more subtle difference is that microscopes, and lab equipment in general, are designed to be robust against small production defects and small variations of environmental conditions. Such small variations cause only small changes in the generated images. With software, on the other hands, all bets are off. A one-character mistake in the source code can cause the program to crash, but also to produce arbitrarily different numbers. In fact, there is no notion of similarity and thus of small variations for software. For a more detailed discussion, see my &lt;a href="http://doi.ieeecomputersociety.org/10.1109/MCSE.2016.67"&gt;CiSE article&lt;/a&gt; on this topic. This is why you can evaluate the quality of a microscope using a few judiciously chosen samples, whereas no amount of test runs can assure you that a piece of software is free of bugs. Unless you can afford to test &lt;em&gt;all possible&lt;/em&gt; inputs, of course, but then you don&amp;rsquo;t really need the software.&lt;/p&gt;

&lt;p&gt;These two differences explain why Alice knows how to evaluate the microscope, whereas Bob doesn&amp;rsquo;t know where to start. He might look at the documentation and the test cases to see if the program is meant to be used for the kind of work he does. But the documentation almost certainly lacks some important details of the approximations that are made in the code and that matter for Bob&amp;rsquo;s work. Moreover, he would still have to check that the software has no serious bugs related to the functionality he plans to use. Without knowing the implemented algorithms in detail, he cannot even anticipate what bugs to watch out for.&lt;/p&gt;

&lt;p&gt;Bob could also choose a very different approach and judge the software by quality standards from software engineering. Is the code well structured? Does it have unit and integration tests? These are the criteria that software journal ask their reviewers to evaluate (e.g. the &lt;a href="http://dx.doi.org/10.6084/m9.figshare.795303"&gt;Journal of Open Research Software&lt;/a&gt; or the &lt;a href="http://joss.theoj.org/about#reviewer_guidelines"&gt;Journal of Open Source Software&lt;/a&gt;). Statistically, they are probably related to the risk of encountering bugs (if anyone knows about research into this question, please leave a comment!). But even the most meticulous developers make mistakes, and, more importantly, may have different applications in mind than those that Bob cares about.&lt;/p&gt;

&lt;p&gt;Finally, Bob could do what in my experience (and also according to &lt;a href="https://arxiv.org/abs/1605.02265v1"&gt;this study&lt;/a&gt; ) most scientists do in choosing research software: they use what their colleagues use. Bob would then send a few emails asking if anyone he knows uses this software and is happy with it. This is a reasonable approach if you can assume that your colleagues, or at least a sizable fraction of them, are in a better position to judge the suitability of a piece of software than yourself. But if everyone adopts this approach, it becomes a popularity contest with little intrinsic value (see &lt;a href="https://doi.org/10.1126%2Fscience.1231535"&gt;this paper&lt;/a&gt; for a detailed example). In any case, it is not a way to actually answer our question.&lt;/p&gt;

&lt;p&gt;In the end, if you really want to know if your software does what you expect it to do, you have to go through every line of the source code until you understand what it does. You are then at the minimal level of epistemic opacity that you can attain without actually doing the computations by hand. Unfortunately, in the case of complex wide-spectrum software, this is likely to be much more effort than writing your own special-purpose software.&lt;/p&gt;

&lt;p&gt;The solution I propose in my paper is to use human-readable formal specifications as a form of documentation that is rigorous and complete, and can be used as a reference to verify the software against. The idea is to have a statement of the implemented algorithms that is precise and complete but as simple as possible, without being encumbered by considerations such as performance. Note that I don&amp;rsquo;t know if this will turn out to be possible - my work is merely a first step into that direction that, to the best of my knowledge, has not been explored until now.&lt;/p&gt;

&lt;h2 id="software-is-about-models-lab-equipment-is-about-observations"&gt;Software is about models, lab equipment is about observations&lt;/h2&gt;

&lt;p&gt;A popular meme in explaining science describes it as founded on two pillars, experiment and theory. Some people propose to add computation and/or simulation as a third pillar, and data mining as a fourth, although these additions remain controversial. In my opinion, they are misguided by a bad identification of the initial pillars. They are not experiment and theory, but observations and models. We often speak of computational experiments when doing simulations, and there are good reasons for the analogy, but it is important to keep in mind that these are experiments on models, not on natural phenomena.&lt;/p&gt;

&lt;p&gt;Observations provide us with information about nature, and models allow us to organize and generalize this information. In this picture, computation has two roles: evaluating the consequences of a model, and comparing them to observations. Simulation is an example for the first role, data mining for the second. Both of these roles predate electronic computers, they simply received more modest labels such as &amp;ldquo;solving differential equations&amp;rdquo; or &amp;ldquo;fitting parameters&amp;rdquo; in the past.&lt;/p&gt;

&lt;p&gt;In the context of reproducibility and verifiability, it is important to realize that there is no symmetry between these two pillars. Nature is the big unknown that we probe through observations. To do this, we use lab equipment that can never be perfect, for two reasons: first, it is constructed on the basis of our imperfect understanding of nature, and second, our control of matter is limited, so we cannot produce equipment that behaves precisely as we imagine it. Models, on the other hand, are symbolic artifacts that are under our precise control. We can formulate and communicate them without any ambiguity, if only we are careful enough.&lt;/p&gt;

&lt;p&gt;Because of these very different roles of observations and models, computational reproducibility has no analogue in the universe of observations. It is almost exclusively a communication issue, the one exception being the non-determinism in parallel computing that we accept in exchange for getting results faster. Non-determinism aside, if Alice cannot reproduce Bob&amp;rsquo;s computations, that simply means that Bob has not been able or willing to describe his work in enough detail for Alice to re-do it identically. There is no fundamental obstacle to such a description, because models and software are symbolic artifacts. We actually know how to achieve computational reproducibility, but we still need to make it straightforward in practice.&lt;/p&gt;

&lt;p&gt;Similarly, if Alice cannot verify that Bob&amp;rsquo;s computation solves the problem he claims them to solve, this means that Bob has not succeeded in explaining his work clearly enough for Alice to understand what is going on. An unverifiable computation is thus very similar to a badly written article. The big difference in practice is that centuries of experience with writing have lead to accepted and documented standards of good writing style, whereas after a few decades of scientific computing, we still do not know how to expose complex algorithms to human readers in the most understandable way. My paper is a first small step towards developing appropriate techniques.&lt;/p&gt;

&lt;p&gt;Experimental reproducibility, on the other hand, is an ideal that can never be achieved perfectly, because no two setups are strictly the same. Verifiability is equally limited because observations can never be repeated identically, even when done with the same equipment. Reproducibility is a quality attribute much like accuracy, precision, or cost. Tradeoffs between these attributes are inevitable, and have to be made by each scientific discipline as a function of what its main obstacles to progress are.&lt;/p&gt;

&lt;p&gt;Science has been adjusting to the inevitable limits of observations since its beginnings, whereas the issue of incomplete model descriptions has come up only with the introduction of computers permitting to work with complex models. We don&amp;rsquo;t know how yet if non-verifiable models are a real problem or not. However, as a theoretician I am not comfortable with the current situation. Models can be simple or complex, good or bad, grounded in solid theory or ad-hoc, but they should not be fuzzy. In particular not for complex systems, where it is very hard to foresee the consequences of minor changes.&lt;/p&gt;</description></item></channel></rss>